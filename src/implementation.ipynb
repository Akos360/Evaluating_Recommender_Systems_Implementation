{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4da85cb-f96a-4395-9fa1-ad39bc3ace16",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e0bb1",
   "metadata": {},
   "source": [
    "## Prepare the Dataset from Digital Library and save to Dataframe and .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea0405e",
   "metadata": {},
   "source": [
    "### PARAGRAPHS - PAGES - SENTENCES --- from JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4464ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 1253570\n",
      "Paragraphs: 181843\n",
      "Pages: 100020\n",
      "Average paragraph word count: 63.725251516279194\n",
      "Average paragraph character count: 413.47675147384297\n",
      "Shortest paragraph word count: 1\n",
      "Longest paragraph word count: 2016\n",
      "Shortest paragraph character count: 3\n",
      "Longest paragraph character count: 7759\n",
      "Paragraphs quarter: 45461\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "folder_path = os.path.abspath(os.path.join(current_dir, \"..\", \"..\", \"output\"))\n",
    "\n",
    "min_sentence_length = 30\n",
    "min_paragraph_length = 200\n",
    "min_page_length = 200\n",
    "\n",
    "\n",
    "unique_sentences = set()\n",
    "unique_paragraphs = set()\n",
    "unique_pages = set()\n",
    "\n",
    "data_sentences = []\n",
    "data_paragraphs = []\n",
    "data_pages = []\n",
    "\n",
    "paragraph_word_counts = []\n",
    "paragraph_char_counts = []\n",
    "\n",
    "shortest_paragraph_word_count = float('inf')\n",
    "longest_paragraph_word_count = 0\n",
    "shortest_paragraph_char_count = float('inf')\n",
    "longest_paragraph_char_count = 0\n",
    "shortest_paragraph = \"\"\n",
    "longest_paragraph = \"\"\n",
    "\n",
    "# Load book titles mapping from a separate JSON file\n",
    "with open(\"documents.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    book_titles = json.load(f)\n",
    "\n",
    "# Create a mapping of book IDs to their respective titles\n",
    "pk_to_title = {entry[\"pk\"]: entry[\"title\"] for entry in book_titles}\n",
    "\n",
    "# Track book index (ensures books are uniquely indexed)\n",
    "book_index_map = {}  # {book_id: book_index}\n",
    "book_counter = 0\n",
    "\n",
    "# Process all JSON files in the directory\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            json_content = json.load(f)\n",
    "\n",
    "        book_id = file_name.split(\".\")[0]\n",
    "        book_title = pk_to_title.get(book_id, \"Unknown Title\")\n",
    "\n",
    "        # Assign a unique book index\n",
    "        if book_id not in book_index_map:\n",
    "            book_index_map[book_id] = book_counter\n",
    "            book_counter += 1\n",
    "\n",
    "        book_index = book_index_map[book_id]  \n",
    "\n",
    "        # Store sentences (skip duplicates)\n",
    "        sentences = json_content.get(\"sentences\", [])\n",
    "        for sentence_index, sentence in enumerate(sentences):\n",
    "            if len(sentence) >= min_sentence_length and sentence not in unique_sentences:\n",
    "                unique_sentences.add(sentence)\n",
    "                data_sentences.append({\n",
    "                    \"book_index\": book_index,\n",
    "                    \"book_id\": book_id,\n",
    "                    \"book_title\": book_title,\n",
    "                    \"sentence_index\": sentence_index,\n",
    "                    \"text\": sentence\n",
    "                })\n",
    "\n",
    "        # Store paragraphs with paragraph index relative to the book (skip duplicates)\n",
    "        paragraphs = json_content.get(\"paragraphs\", [])\n",
    "        paragraph_index = 0  \n",
    "        for paragraph in paragraphs:\n",
    "            word_count = len(paragraph.split())\n",
    "            char_count = len(paragraph)\n",
    "            \n",
    "            # Tracking word and character count statistics\n",
    "            paragraph_word_counts.append(word_count)\n",
    "            paragraph_char_counts.append(char_count)\n",
    "\n",
    "            # Update the shortest and longest paragraphs\n",
    "            if word_count < shortest_paragraph_word_count:\n",
    "                shortest_paragraph_word_count = word_count\n",
    "                shortest_paragraph = paragraph\n",
    "            if word_count > longest_paragraph_word_count:\n",
    "                longest_paragraph_word_count = word_count\n",
    "                longest_paragraph = paragraph\n",
    "                \n",
    "            if char_count < shortest_paragraph_char_count:\n",
    "                shortest_paragraph_char_count = char_count\n",
    "            if char_count > longest_paragraph_char_count:\n",
    "                longest_paragraph_char_count = char_count\n",
    "\n",
    "            if len(paragraph) >= min_paragraph_length and paragraph not in unique_paragraphs:\n",
    "                unique_paragraphs.add(paragraph)\n",
    "                data_paragraphs.append({\n",
    "                    \"book_index\": book_index,\n",
    "                    \"book_id\": book_id,\n",
    "                    \"book_title\": book_title,\n",
    "                    \"paragraph_index\": paragraph_index,\n",
    "                    \"text\": paragraph,\n",
    "                    \"word_count\": word_count,\n",
    "                    \"char_count\": char_count\n",
    "                })\n",
    "                paragraph_index += 1  \n",
    "\n",
    "        # Store pages (skip duplicates)\n",
    "        pages = json_content.get(\"pages\", [])\n",
    "        page_index = 0  \n",
    "        for page in pages:\n",
    "            if len(page) >= min_page_length and page not in unique_pages:\n",
    "                unique_pages.add(page)\n",
    "                data_pages.append({\n",
    "                    \"book_index\": book_index,\n",
    "                    \"book_id\": book_id,\n",
    "                    \"book_title\": book_title,\n",
    "                    \"page_index\": page_index,\n",
    "                    \"text\": page\n",
    "                })\n",
    "                page_index += 1  \n",
    "\n",
    "# Convert data into DataFrame\n",
    "df_sentences = pd.DataFrame(data_sentences)\n",
    "df_paragraphs = pd.DataFrame(data_paragraphs)\n",
    "df_pages = pd.DataFrame(data_pages)\n",
    "\n",
    "# Average word and character count for paragraphs\n",
    "avg_paragraph_word_count = sum(paragraph_word_counts) / len(paragraph_word_counts) if paragraph_word_counts else 0\n",
    "avg_paragraph_char_count = sum(paragraph_char_counts) / len(paragraph_char_counts) if paragraph_char_counts else 0\n",
    "\n",
    "# Display the paragraph statistics\n",
    "print(f\"Sentences: {len(df_sentences)}\\nParagraphs: {len(df_paragraphs)}\\nPages: {len(df_pages)}\")\n",
    "print(f\"Average paragraph word count: {avg_paragraph_word_count}\")\n",
    "print(f\"Average paragraph character count: {avg_paragraph_char_count}\")\n",
    "print(f\"Shortest paragraph word count: {shortest_paragraph_word_count}\")\n",
    "print(f\"Longest paragraph word count: {longest_paragraph_word_count}\")\n",
    "print(f\"Shortest paragraph character count: {shortest_paragraph_char_count}\")\n",
    "print(f\"Longest paragraph character count: {longest_paragraph_char_count}\")\n",
    "\n",
    "# Saving the data to CSV files\n",
    "df_paragraphs_half = df_paragraphs.sample(frac=0.5, random_state=42)\n",
    "df_paragraphs_quarter = df_paragraphs.sample(frac=0.25, random_state=42)\n",
    "\n",
    "print(f\"Paragraphs quarter: {len(df_paragraphs_quarter)}\")\n",
    "\n",
    "df_sentences.to_csv(f\"books_to_csv/sentences_limited_to_{min_sentence_length}.csv\", index=False)\n",
    "df_paragraphs.to_csv(f\"books_to_csv/paragraphs_limited_to_{min_paragraph_length}.csv\", index=False)\n",
    "df_pages.to_csv(f\"books_to_csv/pages_limited_to_{min_page_length}.csv\", index=False)\n",
    "df_paragraphs_half.to_csv(f\"books_to_csv/paragraphs_limited_to_{min_paragraph_length}_half.csv\", index=False)\n",
    "df_paragraphs_quarter.to_csv(f\"books_to_csv/paragraphs_limited_to_{min_paragraph_length}_quarter.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9df89c",
   "metadata": {},
   "source": [
    "### Paragraphs - min 200 characters \n",
    "- quarter sample of whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fa1ce49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "book_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "paragraph_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "char_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5ae084e8-4a8a-422c-a52f-103cf77b8d6e",
       "rows": [
        [
         "0",
         "70",
         "3937721e-6e30-4bd1-8e04-50b05100bf28",
         "Optics in Our Time",
         "1001",
         "Although we have learned a lot we still lack the full picture. In particular, there is still no unique answer to the long-standing question: âWhat is a photon?â In the present essay we of course do not answer this deep question either but illuminate one important aspect of the photon that on ï¬rst sight looks very strange that is the wave-particle dualism. Indeed, according to the quantum theory of radiation the photon is a wave and a particle at the same time and their respective distinct features manifest themselves in countless phenomena. The double-slit experiment with individual photons is one of them. The ultimate goal of our article is to discuss a rather special double-slit experiment based on two entangled photons which seems to show simultaneously the wave and the particle nature of light. Such a behavior which is strictly forbidden by quantum theory and, in particular, by the principle of complementarity makes the photon even stranger. However, a closer look at the details of the light generation reveals that there is no violation of quantum mechanics, and in the words of G. Stein: â. . .suddenly it doesnât look strange at all.â",
         "193",
         "1156"
        ],
        [
         "1",
         "231",
         "97718729-2637-4aa2-8f86-026f7ce9722e",
         "North Sea Region Climate Change Assessment",
         "1560",
         "1980â2005: c multi-model-mean in the CMIP5 experiment, d difference between multi-model mean and precipitation analyses from the Global Precipitation Climatology Project (Adler et al. 2003). Note the different scales for the respective mean and bias maps (Flato et al 2013: Figs. 9.2 and 9.4, panels (a) and (b). Abridged caption)",
         "50",
         "330"
        ],
        [
         "2",
         "179",
         "7a007b86-f839-46d7-be69-cc38ecf001b8",
         "Habitats and Biota of the Gulf of Mexico: Before the Deepwater Horizon Oil Spill: Volume 1: Water Quality, Sediments, Sediment Contaminants, Oil and Gas Seeps, Coastal Habitats, Offshore Plankton and Benthos, and Shellfish",
         "141",
         "stable or increasing. Large numbers of leatherback sea turtles are captured each year in the Gulf as bycatch in pelagic longline fisheries. Hawksbills are the rarest of the five species of sea turtle that occur in the Gulf of Mexico, and their current abundance is only a fraction of historical levels because millions were killed for tortoiseshell (jewelry, combs, brushes, buttons, etc.) during the past 100 years. Significant threats to hawksbills include destruction of nesting habitat, their dependence on coral reefs (one of the worldâs most endangered ecosystems) for food and shelter, and the continued trade in hawksbill products. Impacts from bycatch in Gulf fisheries to hawksbill sea turtles are minimal. In summary, because sea turtles are difficult to study and since some species have been studied more than others, there are significant gaps in the data available by species, as well as by life stage. However, despite the data gaps and limitations associated with selected data sets",
         "158",
         "999"
        ],
        [
         "3",
         "337",
         "d9f69fee-936a-472a-983b-f760acabf8e4",
         "Understanding Society and Natural Resources : Forging New Strands of Integration Across the Social Sciences",
         "24",
         "science during environmental crises through two case studies â the Deepwater Horizon oil spill and Hurricane Sandy. Machlis et al. suggest that a research agenda which includes integration efforts needs to be developed for understanding and improving science during crisis. Friedrichs (Chap. 4) makes the case for modified Malthusian theories to ground the study of resource management through science integration. He contends that the main impediment to integration both between various social scientific disciplines and between the social and the physical sciences is a refusal of social scientists to appreciate how deeply the societal sphere is embedded in wider biophysical and social-ecological systems. The chapter begins with a classical Malthusian framework and gradually adds complexity to it, showing how its logical structure is reproduced by simple neo-Malthusian theories that have been developed to account for contemporary global challenges. He demonstrates the potential of more sophisticated neo-Malthusian models and modified Malthusian theories contributing to better science integration. Finucane et al. (Chap. 5) present a conceptual framework for analyzing socialecological models of emerging infectious diseases. Specifically they examine whether risks, and perceptions of risk, associated with highly pathogenic avian influenza (HPAI) caused by the H5N1 virus can be associated with anthropogenic environmental changes produced by urbanization, agricultural change, and natural habitat alterations in the context of Vietnam. To address multi-scale issues within the framework, they draw upon multiple social science theories and methods. Finucane et al. conclude that no single theory or method is sufficient to explain complex phenomena such as emerging infectious disease and the relationships between factors influencing disease outbreaks. Thus, they argue that integrated approaches are the best way to provide an in-depth description and analysis of a complex problem. Esptein et al. (Chap. 6) use the social-ecological systems (SES) framework to study power. They explore the long-standing divide among social scientists regarding power and its effects on the sustainability of social-ecological systems. They argue that there has been little constructive interaction between power-centered and institution-centered approaches. The authors use the SES framework as a tool to confront interdisciplinary puzzles that bridges the gap between social and ecological research. The chapter outlines a systematic approach for integrating diverse conceptualizations of power with the SES framework and then applies this approach to study the relationship between power and social-ecological outcomes. The analysis suggests that the SES framework is a promising tool for social science integration, but also that important questions remain concerning the validity of classifications, measurement, and statistical tests. Manfredo et al. (Chap. 7) conclude Part II by making the case that increased integration of the human individual into dynamic, multi-level models is essential to understanding agency, innovation, and adaptation in social-ecological systems. They use the social-ecological systems framework introduced in the previous chapter as a starting point to examine how conservation science with a focus on the human individual â particularly the tradition of social science research known",
         "480",
         "3420"
        ],
        [
         "4",
         "264",
         "ada20eed-7aaf-467c-a8c8-1706a97bb5e1",
         "Proceedings of The 13Th international Congress On Mathematical Education : Icme-13",
         "64",
         "arriving on surf beaches come from more than one storm, and if we add two similar sine functions we get a curve with three peaks. Everyone has their own examplesâICMIâs Klein Project is a multilingual collection of contemporary mathematics written for teachers. It would be nice if the pleasure that we get from mathematics imbued the whole of mathematics education, but we know it does not. Why not? How do we manage to take the pleasure out of mathematics? This question underlies all that follows. Let me now return to Ubiratan DâAmbrosio. It is an honour to be following up Ubiratan DâAmbrosioâs thinking, so let me briefly, and with a broad brush-stroke, go over what he was on about. He questioned inequity within mathematics education in a very fundamental way, and gave us some models for working towards creating a fairer world through a mathematics education that really paid attention to social and cultural issues. Many, many people have worked very strongly in this area, and I do not intend to give a summary of the comprehensive work that has been done. In more recent years, Ubiratan DâAmbrosio started to talk about mathematics as a dorsal spine. I want to highlight this metaphor because it is a very nice way of thinking about what has happened. He sees mathematics as the dorsal spine of civilization, the basis of science and technology (DâAmbrosio, 2007, 2015). The trouble is that you may have a spine and skeleton on which an animal may be built, but that animal sometimes turns into a monster rather than a beautiful creature. This has happened within mathematics, and, I would argue, within mathematics education. DâAmbrosio suggests that our essential goals are responsible creativity and ethical citizenship. What he did was highlight the role of mathematics and mathematics education in achieving both of those goals. In other words, he was pointing us to the wider reasons for our work as mathematicians and mathematics educators. But how? How do we do this? What is it I am supposed to do to engender responsible creativity and ethical citizenship? When I walk up the steps and go into my ofï¬ce, what actions will I take? I can presumably do some things in the way I behave, but how do I help to engender appropriate actions in the students that I teach? How are we to build a beautiful creature and not a monster. I think that DâAmbrosioâs essential message is that we should reinstate cultural processes within mathematics education in order to build beautiful creatures. I wish to think about what other things we might do. To develop a basis for making possible actions more explicit I would like to invoke ecological systems theory, which was developed in the context of child development by Urie Bronfenbrenner in 1979, a couple of years after DâAmbrosio introduced the ethnomathematical approach. The two theories have some overlapping principles (Bronfenbrenner, 1992).",
         "486",
         "2908"
        ],
        [
         "5",
         "34",
         "1f9d02ad-5546-4dcf-99c3-9bf600fed0d0",
         "Habitats and Biota of the Gulf of Mexico: Before the Deepwater Horizon Oil Spill: Volume 2: Fish Resources, Fisheries, Sea Turtles, Avian Resources, Marine Mammals, Diseases and Mortalities",
         "1269",
         "13.4.12 Global Status and U.S. Population Trends Manatee causes of mortality are listed as a special case in Figure 13.61. Mortalities from speeding watercraft have been the highest overall source of mortality, but there is some indication that with greater education and enforcement, these are on the wane. Cold stress due to periodic shutdown of power plants used as refuges by manatees has also decreased in recent years, due to concerted human action. Many carcasses are too decomposed for accurate assessments of cause of death, and human causes are probably larger than indicated in Figure 13.61 and Table 13.26.",
         "99",
         "618"
        ],
        [
         "6",
         "85",
         "43896dd4-7a1a-4e21-aa03-7c96fdc6d6d4",
         "Bayesian Methods in the Search for MH370",
         "193",
         "in the top right. It exhibits spatial variations very similar to the overall variations in the top left. The likelihood function p(y|xfinal ) is the ratio of these two densities and is shown in the lower left. Note that large values can occur in areas of limited",
         "47",
         "262"
        ],
        [
         "7",
         "67",
         "34f944b5-b819-4ae3-afa1-592b466d80ab",
         "UmelÃ¡ inteligencia",
         "198",
         "V takÃ½chto grafoch treba inak chÃ¡paÅ¥ pojem rieÅ¡enia problÃ©mu. Cesta zo zaÄiatoÄnÃ©ho uzla do niektorÃ©ho koncovÃ©ho uzla nemÃ´Å¾e byÅ¥ rieÅ¡enÃ­m, pretoÅ¾e ak je Äo len jeden uzol na tejto ceste takÃ½, Å¾e mÃ¡ nasledovnÃ­ky spojenÃ© s nÃ­m hranou A, tak sÃºÄasÅ¥ou rieÅ¡enia musia byÅ¥ vÅ¡etky takÃ© nasledovnÃ­ky. RieÅ¡enÃ­m v A/ALEBO grafe je jeho podgraf a nie cesta. Podgraf rieÅ¡enia pozostÃ¡va zo zaÄiatoÄnÃ©ho uzla a spolu s kaÅ¾dÃ½m uzlom, ktorÃ½ mÃ¡ nasledovnÃ­ky spojenÃ© s nÃ­m hranou typu A, obsahuje aj podgraf obsahujÃºci vÅ¡etky tieto hrany. Listy grafu rieÅ¡enia musia navyÅ¡e zodpovedaÅ¥ elementÃ¡rnym problÃ©mom, o ktorÃ½ch sa vie ako ich rieÅ¡iÅ¥. Napr. jeden moÅ¾nÃ½ podgraf rieÅ¡enia A/ALEBO grafu z Obr. 2.8 obsahuje vÅ¡etky oznaÄenÃ© uzly (za predpokladu, Å¾e elementÃ¡rny PodproblÃ©m 11,",
         "119",
         "759"
        ],
        [
         "8",
         "36",
         "2103da9d-e390-4d26-9e31-55c3f3027e12",
         "Bats in the Anthropocene : Conservation of Bats in a Changing World",
         "518",
         "12.6.6 Stakeholder Engagement and Citizen Science Collaborative conservation is more likely to be sustainable. In communitybased conservation management, stakeholders from a variety of factions within the community are required to work together to implement effective conservation practices. This often creates unlikely partnerships that bridge normal political, socioeconomic and religious divides. For example, former rebels work with local government officials to monitor bats in southern Mindanao, Philippines, a region known for often violent stand-offs between the Philippine government and Islamic separatists (LM Paguntalan pers. comm., SOS 2012). Uniting stakeholders toward",
         "89",
         "683"
        ],
        [
         "9",
         "297",
         "c063dfad-7d37-42d7-9ea3-a936e730e274",
         "The R Book",
         "297",
         "Here is yet another possibility with year, then month in full, then week of the year, then day of the week abbreviated, all separated by a single blank space: yet.another.date <- c(\"2016 January 2 Mon\",\"2017 February 6 Fri\",\"2018 March 10 Tue\") strptime(yet.another.date,\"%Y %B %W %a\") [1] \"2016-01-11\" \"2017-02-10\" \"2018-03-06\" The system is clever in that it knows the date of the Monday in week number 2 of January in 2016, and of the Tuesday in week 10 of 2018 (the information on month is redundant in this case): yet.more.dates <- c(\"2016 2 Mon\",\"2017 6 Fri\",\"2018 10 Tue\") strptime(yet.more.dates,\"%Y %W %a\") [1] \"2016-01-11\" \"2017-02-10\" \"2018-03-06\" 2.13.3",
         "105",
         "665"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_index</th>\n",
       "      <th>book_id</th>\n",
       "      <th>book_title</th>\n",
       "      <th>paragraph_index</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>3937721e-6e30-4bd1-8e04-50b05100bf28</td>\n",
       "      <td>Optics in Our Time</td>\n",
       "      <td>1001</td>\n",
       "      <td>Although we have learned a lot we still lack the full picture. In particular, there is still no unique answer to the long-standing question: âWhat is a photon?â In the present essay we of course do not answer this deep question either but illuminate one important aspect of the photon that on ï¬rst sight looks very strange that is the wave-particle dualism. Indeed, according to the quantum theory of radiation the photon is a wave and a particle at the same time and their respective distinct features manifest themselves in countless phenomena. The double-slit experiment with individual photons is one of them. The ultimate goal of our article is to discuss a rather special double-slit experiment based on two entangled photons which seems to show simultaneously the wave and the particle nature of light. Such a behavior which is strictly forbidden by quantum theory and, in particular, by the principle of complementarity makes the photon even stranger. However, a closer look at the details of the light generation reveals that there is no violation of quantum mechanics, and in the words of G. Stein: â. . .suddenly it doesnât look strange at all.â</td>\n",
       "      <td>193</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>231</td>\n",
       "      <td>97718729-2637-4aa2-8f86-026f7ce9722e</td>\n",
       "      <td>North Sea Region Climate Change Assessment</td>\n",
       "      <td>1560</td>\n",
       "      <td>1980â2005: c multi-model-mean in the CMIP5 experiment, d difference between multi-model mean and precipitation analyses from the Global Precipitation Climatology Project (Adler et al. 2003). Note the different scales for the respective mean and bias maps (Flato et al 2013: Figs. 9.2 and 9.4, panels (a) and (b). Abridged caption)</td>\n",
       "      <td>50</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>179</td>\n",
       "      <td>7a007b86-f839-46d7-be69-cc38ecf001b8</td>\n",
       "      <td>Habitats and Biota of the Gulf of Mexico: Before the Deepwater Horizon Oil Spill: Volume 1: Water Quality, Sediments, Sediment Contaminants, Oil and Gas Seeps, Coastal Habitats, Offshore Plankton and Benthos, and Shellfish</td>\n",
       "      <td>141</td>\n",
       "      <td>stable or increasing. Large numbers of leatherback sea turtles are captured each year in the Gulf as bycatch in pelagic longline fisheries. Hawksbills are the rarest of the five species of sea turtle that occur in the Gulf of Mexico, and their current abundance is only a fraction of historical levels because millions were killed for tortoiseshell (jewelry, combs, brushes, buttons, etc.) during the past 100 years. Significant threats to hawksbills include destruction of nesting habitat, their dependence on coral reefs (one of the worldâs most endangered ecosystems) for food and shelter, and the continued trade in hawksbill products. Impacts from bycatch in Gulf fisheries to hawksbill sea turtles are minimal. In summary, because sea turtles are difficult to study and since some species have been studied more than others, there are significant gaps in the data available by species, as well as by life stage. However, despite the data gaps and limitations associated with selected data sets</td>\n",
       "      <td>158</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>337</td>\n",
       "      <td>d9f69fee-936a-472a-983b-f760acabf8e4</td>\n",
       "      <td>Understanding Society and Natural Resources : Forging New Strands of Integration Across the Social Sciences</td>\n",
       "      <td>24</td>\n",
       "      <td>science during environmental crises through two case studies â the Deepwater Horizon oil spill and Hurricane Sandy. Machlis et al. suggest that a research agenda which includes integration efforts needs to be developed for understanding and improving science during crisis. Friedrichs (Chap. 4) makes the case for modified Malthusian theories to ground the study of resource management through science integration. He contends that the main impediment to integration both between various social scientific disciplines and between the social and the physical sciences is a refusal of social scientists to appreciate how deeply the societal sphere is embedded in wider biophysical and social-ecological systems. The chapter begins with a classical Malthusian framework and gradually adds complexity to it, showing how its logical structure is reproduced by simple neo-Malthusian theories that have been developed to account for contemporary global challenges. He demonstrates the potential of more sophisticated neo-Malthusian models and modified Malthusian theories contributing to better science integration. Finucane et al. (Chap. 5) present a conceptual framework for analyzing socialecological models of emerging infectious diseases. Specifically they examine whether risks, and perceptions of risk, associated with highly pathogenic avian influenza (HPAI) caused by the H5N1 virus can be associated with anthropogenic environmental changes produced by urbanization, agricultural change, and natural habitat alterations in the context of Vietnam. To address multi-scale issues within the framework, they draw upon multiple social science theories and methods. Finucane et al. conclude that no single theory or method is sufficient to explain complex phenomena such as emerging infectious disease and the relationships between factors influencing disease outbreaks. Thus, they argue that integrated approaches are the best way to provide an in-depth description and analysis of a complex problem. Esptein et al. (Chap. 6) use the social-ecological systems (SES) framework to study power. They explore the long-standing divide among social scientists regarding power and its effects on the sustainability of social-ecological systems. They argue that there has been little constructive interaction between power-centered and institution-centered approaches. The authors use the SES framework as a tool to confront interdisciplinary puzzles that bridges the gap between social and ecological research. The chapter outlines a systematic approach for integrating diverse conceptualizations of power with the SES framework and then applies this approach to study the relationship between power and social-ecological outcomes. The analysis suggests that the SES framework is a promising tool for social science integration, but also that important questions remain concerning the validity of classifications, measurement, and statistical tests. Manfredo et al. (Chap. 7) conclude Part II by making the case that increased integration of the human individual into dynamic, multi-level models is essential to understanding agency, innovation, and adaptation in social-ecological systems. They use the social-ecological systems framework introduced in the previous chapter as a starting point to examine how conservation science with a focus on the human individual â particularly the tradition of social science research known</td>\n",
       "      <td>480</td>\n",
       "      <td>3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264</td>\n",
       "      <td>ada20eed-7aaf-467c-a8c8-1706a97bb5e1</td>\n",
       "      <td>Proceedings of The 13Th international Congress On Mathematical Education : Icme-13</td>\n",
       "      <td>64</td>\n",
       "      <td>arriving on surf beaches come from more than one storm, and if we add two similar sine functions we get a curve with three peaks. Everyone has their own examplesâICMIâs Klein Project is a multilingual collection of contemporary mathematics written for teachers. It would be nice if the pleasure that we get from mathematics imbued the whole of mathematics education, but we know it does not. Why not? How do we manage to take the pleasure out of mathematics? This question underlies all that follows. Let me now return to Ubiratan DâAmbrosio. It is an honour to be following up Ubiratan DâAmbrosioâs thinking, so let me briefly, and with a broad brush-stroke, go over what he was on about. He questioned inequity within mathematics education in a very fundamental way, and gave us some models for working towards creating a fairer world through a mathematics education that really paid attention to social and cultural issues. Many, many people have worked very strongly in this area, and I do not intend to give a summary of the comprehensive work that has been done. In more recent years, Ubiratan DâAmbrosio started to talk about mathematics as a dorsal spine. I want to highlight this metaphor because it is a very nice way of thinking about what has happened. He sees mathematics as the dorsal spine of civilization, the basis of science and technology (DâAmbrosio, 2007, 2015). The trouble is that you may have a spine and skeleton on which an animal may be built, but that animal sometimes turns into a monster rather than a beautiful creature. This has happened within mathematics, and, I would argue, within mathematics education. DâAmbrosio suggests that our essential goals are responsible creativity and ethical citizenship. What he did was highlight the role of mathematics and mathematics education in achieving both of those goals. In other words, he was pointing us to the wider reasons for our work as mathematicians and mathematics educators. But how? How do we do this? What is it I am supposed to do to engender responsible creativity and ethical citizenship? When I walk up the steps and go into my ofï¬ce, what actions will I take? I can presumably do some things in the way I behave, but how do I help to engender appropriate actions in the students that I teach? How are we to build a beautiful creature and not a monster. I think that DâAmbrosioâs essential message is that we should reinstate cultural processes within mathematics education in order to build beautiful creatures. I wish to think about what other things we might do. To develop a basis for making possible actions more explicit I would like to invoke ecological systems theory, which was developed in the context of child development by Urie Bronfenbrenner in 1979, a couple of years after DâAmbrosio introduced the ethnomathematical approach. The two theories have some overlapping principles (Bronfenbrenner, 1992).</td>\n",
       "      <td>486</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>1f9d02ad-5546-4dcf-99c3-9bf600fed0d0</td>\n",
       "      <td>Habitats and Biota of the Gulf of Mexico: Before the Deepwater Horizon Oil Spill: Volume 2: Fish Resources, Fisheries, Sea Turtles, Avian Resources, Marine Mammals, Diseases and Mortalities</td>\n",
       "      <td>1269</td>\n",
       "      <td>13.4.12 Global Status and U.S. Population Trends Manatee causes of mortality are listed as a special case in Figure 13.61. Mortalities from speeding watercraft have been the highest overall source of mortality, but there is some indication that with greater education and enforcement, these are on the wane. Cold stress due to periodic shutdown of power plants used as refuges by manatees has also decreased in recent years, due to concerted human action. Many carcasses are too decomposed for accurate assessments of cause of death, and human causes are probably larger than indicated in Figure 13.61 and Table 13.26.</td>\n",
       "      <td>99</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85</td>\n",
       "      <td>43896dd4-7a1a-4e21-aa03-7c96fdc6d6d4</td>\n",
       "      <td>Bayesian Methods in the Search for MH370</td>\n",
       "      <td>193</td>\n",
       "      <td>in the top right. It exhibits spatial variations very similar to the overall variations in the top left. The likelihood function p(y|xfinal ) is the ratio of these two densities and is shown in the lower left. Note that large values can occur in areas of limited</td>\n",
       "      <td>47</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67</td>\n",
       "      <td>34f944b5-b819-4ae3-afa1-592b466d80ab</td>\n",
       "      <td>UmelÃ¡ inteligencia</td>\n",
       "      <td>198</td>\n",
       "      <td>V takÃ½chto grafoch treba inak chÃ¡paÅ¥ pojem rieÅ¡enia problÃ©mu. Cesta zo zaÄiatoÄnÃ©ho uzla do niektorÃ©ho koncovÃ©ho uzla nemÃ´Å¾e byÅ¥ rieÅ¡enÃ­m, pretoÅ¾e ak je Äo len jeden uzol na tejto ceste takÃ½, Å¾e mÃ¡ nasledovnÃ­ky spojenÃ© s nÃ­m hranou A, tak sÃºÄasÅ¥ou rieÅ¡enia musia byÅ¥ vÅ¡etky takÃ© nasledovnÃ­ky. RieÅ¡enÃ­m v A/ALEBO grafe je jeho podgraf a nie cesta. Podgraf rieÅ¡enia pozostÃ¡va zo zaÄiatoÄnÃ©ho uzla a spolu s kaÅ¾dÃ½m uzlom, ktorÃ½ mÃ¡ nasledovnÃ­ky spojenÃ© s nÃ­m hranou typu A, obsahuje aj podgraf obsahujÃºci vÅ¡etky tieto hrany. Listy grafu rieÅ¡enia musia navyÅ¡e zodpovedaÅ¥ elementÃ¡rnym problÃ©mom, o ktorÃ½ch sa vie ako ich rieÅ¡iÅ¥. Napr. jeden moÅ¾nÃ½ podgraf rieÅ¡enia A/ALEBO grafu z Obr. 2.8 obsahuje vÅ¡etky oznaÄenÃ© uzly (za predpokladu, Å¾e elementÃ¡rny PodproblÃ©m 11,</td>\n",
       "      <td>119</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>2103da9d-e390-4d26-9e31-55c3f3027e12</td>\n",
       "      <td>Bats in the Anthropocene : Conservation of Bats in a Changing World</td>\n",
       "      <td>518</td>\n",
       "      <td>12.6.6 Stakeholder Engagement and Citizen Science Collaborative conservation is more likely to be sustainable. In communitybased conservation management, stakeholders from a variety of factions within the community are required to work together to implement effective conservation practices. This often creates unlikely partnerships that bridge normal political, socioeconomic and religious divides. For example, former rebels work with local government officials to monitor bats in southern Mindanao, Philippines, a region known for often violent stand-offs between the Philippine government and Islamic separatists (LM Paguntalan pers. comm., SOS 2012). Uniting stakeholders toward</td>\n",
       "      <td>89</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>297</td>\n",
       "      <td>c063dfad-7d37-42d7-9ea3-a936e730e274</td>\n",
       "      <td>The R Book</td>\n",
       "      <td>297</td>\n",
       "      <td>Here is yet another possibility with year, then month in full, then week of the year, then day of the week abbreviated, all separated by a single blank space: yet.another.date &lt;- c(\"2016 January 2 Mon\",\"2017 February 6 Fri\",\"2018 March 10 Tue\") strptime(yet.another.date,\"%Y %B %W %a\") [1] \"2016-01-11\" \"2017-02-10\" \"2018-03-06\" The system is clever in that it knows the date of the Monday in week number 2 of January in 2016, and of the Tuesday in week 10 of 2018 (the information on month is redundant in this case): yet.more.dates &lt;- c(\"2016 2 Mon\",\"2017 6 Fri\",\"2018 10 Tue\") strptime(yet.more.dates,\"%Y %W %a\") [1] \"2016-01-11\" \"2017-02-10\" \"2018-03-06\" 2.13.3</td>\n",
       "      <td>105</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_index                               book_id  \\\n",
       "0          70  3937721e-6e30-4bd1-8e04-50b05100bf28   \n",
       "1         231  97718729-2637-4aa2-8f86-026f7ce9722e   \n",
       "2         179  7a007b86-f839-46d7-be69-cc38ecf001b8   \n",
       "3         337  d9f69fee-936a-472a-983b-f760acabf8e4   \n",
       "4         264  ada20eed-7aaf-467c-a8c8-1706a97bb5e1   \n",
       "5          34  1f9d02ad-5546-4dcf-99c3-9bf600fed0d0   \n",
       "6          85  43896dd4-7a1a-4e21-aa03-7c96fdc6d6d4   \n",
       "7          67  34f944b5-b819-4ae3-afa1-592b466d80ab   \n",
       "8          36  2103da9d-e390-4d26-9e31-55c3f3027e12   \n",
       "9         297  c063dfad-7d37-42d7-9ea3-a936e730e274   \n",
       "\n",
       "                                                                                                                                                                                                                       book_title  \\\n",
       "0                                                                                                                                                                                                              Optics in Our Time   \n",
       "1                                                                                                                                                                                      North Sea Region Climate Change Assessment   \n",
       "2  Habitats and Biota of the Gulf of Mexico: Before the Deepwater Horizon Oil Spill: Volume 1: Water Quality, Sediments, Sediment Contaminants, Oil and Gas Seeps, Coastal Habitats, Offshore Plankton and Benthos, and Shellfish   \n",
       "3                                                                                                                     Understanding Society and Natural Resources : Forging New Strands of Integration Across the Social Sciences   \n",
       "4                                                                                                                                              Proceedings of The 13Th international Congress On Mathematical Education : Icme-13   \n",
       "5                                   Habitats and Biota of the Gulf of Mexico: Before the Deepwater Horizon Oil Spill: Volume 2: Fish Resources, Fisheries, Sea Turtles, Avian Resources, Marine Mammals, Diseases and Mortalities   \n",
       "6                                                                                                                                                                                        Bayesian Methods in the Search for MH370   \n",
       "7                                                                                                                                                                                                             UmelÃ¡ inteligencia   \n",
       "8                                                                                                                                                             Bats in the Anthropocene : Conservation of Bats in a Changing World   \n",
       "9                                                                                                                                                                                                                      The R Book   \n",
       "\n",
       "   paragraph_index  \\\n",
       "0             1001   \n",
       "1             1560   \n",
       "2              141   \n",
       "3               24   \n",
       "4               64   \n",
       "5             1269   \n",
       "6              193   \n",
       "7              198   \n",
       "8              518   \n",
       "9              297   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Although we have learned a lot we still lack the full picture. In particular, there is still no unique answer to the long-standing question: âWhat is a photon?â In the present essay we of course do not answer this deep question either but illuminate one important aspect of the photon that on ï¬rst sight looks very strange that is the wave-particle dualism. Indeed, according to the quantum theory of radiation the photon is a wave and a particle at the same time and their respective distinct features manifest themselves in countless phenomena. The double-slit experiment with individual photons is one of them. The ultimate goal of our article is to discuss a rather special double-slit experiment based on two entangled photons which seems to show simultaneously the wave and the particle nature of light. Such a behavior which is strictly forbidden by quantum theory and, in particular, by the principle of complementarity makes the photon even stranger. However, a closer look at the details of the light generation reveals that there is no violation of quantum mechanics, and in the words of G. Stein: â. . .suddenly it doesnât look strange at all.â   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1980â2005: c multi-model-mean in the CMIP5 experiment, d difference between multi-model mean and precipitation analyses from the Global Precipitation Climatology Project (Adler et al. 2003). Note the different scales for the respective mean and bias maps (Flato et al 2013: Figs. 9.2 and 9.4, panels (a) and (b). Abridged caption)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         stable or increasing. Large numbers of leatherback sea turtles are captured each year in the Gulf as bycatch in pelagic longline fisheries. Hawksbills are the rarest of the five species of sea turtle that occur in the Gulf of Mexico, and their current abundance is only a fraction of historical levels because millions were killed for tortoiseshell (jewelry, combs, brushes, buttons, etc.) during the past 100 years. Significant threats to hawksbills include destruction of nesting habitat, their dependence on coral reefs (one of the worldâs most endangered ecosystems) for food and shelter, and the continued trade in hawksbill products. Impacts from bycatch in Gulf fisheries to hawksbill sea turtles are minimal. In summary, because sea turtles are difficult to study and since some species have been studied more than others, there are significant gaps in the data available by species, as well as by life stage. However, despite the data gaps and limitations associated with selected data sets   \n",
       "3  science during environmental crises through two case studies â the Deepwater Horizon oil spill and Hurricane Sandy. Machlis et al. suggest that a research agenda which includes integration efforts needs to be developed for understanding and improving science during crisis. Friedrichs (Chap. 4) makes the case for modified Malthusian theories to ground the study of resource management through science integration. He contends that the main impediment to integration both between various social scientific disciplines and between the social and the physical sciences is a refusal of social scientists to appreciate how deeply the societal sphere is embedded in wider biophysical and social-ecological systems. The chapter begins with a classical Malthusian framework and gradually adds complexity to it, showing how its logical structure is reproduced by simple neo-Malthusian theories that have been developed to account for contemporary global challenges. He demonstrates the potential of more sophisticated neo-Malthusian models and modified Malthusian theories contributing to better science integration. Finucane et al. (Chap. 5) present a conceptual framework for analyzing socialecological models of emerging infectious diseases. Specifically they examine whether risks, and perceptions of risk, associated with highly pathogenic avian influenza (HPAI) caused by the H5N1 virus can be associated with anthropogenic environmental changes produced by urbanization, agricultural change, and natural habitat alterations in the context of Vietnam. To address multi-scale issues within the framework, they draw upon multiple social science theories and methods. Finucane et al. conclude that no single theory or method is sufficient to explain complex phenomena such as emerging infectious disease and the relationships between factors influencing disease outbreaks. Thus, they argue that integrated approaches are the best way to provide an in-depth description and analysis of a complex problem. Esptein et al. (Chap. 6) use the social-ecological systems (SES) framework to study power. They explore the long-standing divide among social scientists regarding power and its effects on the sustainability of social-ecological systems. They argue that there has been little constructive interaction between power-centered and institution-centered approaches. The authors use the SES framework as a tool to confront interdisciplinary puzzles that bridges the gap between social and ecological research. The chapter outlines a systematic approach for integrating diverse conceptualizations of power with the SES framework and then applies this approach to study the relationship between power and social-ecological outcomes. The analysis suggests that the SES framework is a promising tool for social science integration, but also that important questions remain concerning the validity of classifications, measurement, and statistical tests. Manfredo et al. (Chap. 7) conclude Part II by making the case that increased integration of the human individual into dynamic, multi-level models is essential to understanding agency, innovation, and adaptation in social-ecological systems. They use the social-ecological systems framework introduced in the previous chapter as a starting point to examine how conservation science with a focus on the human individual â particularly the tradition of social science research known   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              arriving on surf beaches come from more than one storm, and if we add two similar sine functions we get a curve with three peaks. Everyone has their own examplesâICMIâs Klein Project is a multilingual collection of contemporary mathematics written for teachers. It would be nice if the pleasure that we get from mathematics imbued the whole of mathematics education, but we know it does not. Why not? How do we manage to take the pleasure out of mathematics? This question underlies all that follows. Let me now return to Ubiratan DâAmbrosio. It is an honour to be following up Ubiratan DâAmbrosioâs thinking, so let me briefly, and with a broad brush-stroke, go over what he was on about. He questioned inequity within mathematics education in a very fundamental way, and gave us some models for working towards creating a fairer world through a mathematics education that really paid attention to social and cultural issues. Many, many people have worked very strongly in this area, and I do not intend to give a summary of the comprehensive work that has been done. In more recent years, Ubiratan DâAmbrosio started to talk about mathematics as a dorsal spine. I want to highlight this metaphor because it is a very nice way of thinking about what has happened. He sees mathematics as the dorsal spine of civilization, the basis of science and technology (DâAmbrosio, 2007, 2015). The trouble is that you may have a spine and skeleton on which an animal may be built, but that animal sometimes turns into a monster rather than a beautiful creature. This has happened within mathematics, and, I would argue, within mathematics education. DâAmbrosio suggests that our essential goals are responsible creativity and ethical citizenship. What he did was highlight the role of mathematics and mathematics education in achieving both of those goals. In other words, he was pointing us to the wider reasons for our work as mathematicians and mathematics educators. But how? How do we do this? What is it I am supposed to do to engender responsible creativity and ethical citizenship? When I walk up the steps and go into my ofï¬ce, what actions will I take? I can presumably do some things in the way I behave, but how do I help to engender appropriate actions in the students that I teach? How are we to build a beautiful creature and not a monster. I think that DâAmbrosioâs essential message is that we should reinstate cultural processes within mathematics education in order to build beautiful creatures. I wish to think about what other things we might do. To develop a basis for making possible actions more explicit I would like to invoke ecological systems theory, which was developed in the context of child development by Urie Bronfenbrenner in 1979, a couple of years after DâAmbrosio introduced the ethnomathematical approach. The two theories have some overlapping principles (Bronfenbrenner, 1992).   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        13.4.12 Global Status and U.S. Population Trends Manatee causes of mortality are listed as a special case in Figure 13.61. Mortalities from speeding watercraft have been the highest overall source of mortality, but there is some indication that with greater education and enforcement, these are on the wane. Cold stress due to periodic shutdown of power plants used as refuges by manatees has also decreased in recent years, due to concerted human action. Many carcasses are too decomposed for accurate assessments of cause of death, and human causes are probably larger than indicated in Figure 13.61 and Table 13.26.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            in the top right. It exhibits spatial variations very similar to the overall variations in the top left. The likelihood function p(y|xfinal ) is the ratio of these two densities and is shown in the lower left. Note that large values can occur in areas of limited   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           V takÃ½chto grafoch treba inak chÃ¡paÅ¥ pojem rieÅ¡enia problÃ©mu. Cesta zo zaÄiatoÄnÃ©ho uzla do niektorÃ©ho koncovÃ©ho uzla nemÃ´Å¾e byÅ¥ rieÅ¡enÃ­m, pretoÅ¾e ak je Äo len jeden uzol na tejto ceste takÃ½, Å¾e mÃ¡ nasledovnÃ­ky spojenÃ© s nÃ­m hranou A, tak sÃºÄasÅ¥ou rieÅ¡enia musia byÅ¥ vÅ¡etky takÃ© nasledovnÃ­ky. RieÅ¡enÃ­m v A/ALEBO grafe je jeho podgraf a nie cesta. Podgraf rieÅ¡enia pozostÃ¡va zo zaÄiatoÄnÃ©ho uzla a spolu s kaÅ¾dÃ½m uzlom, ktorÃ½ mÃ¡ nasledovnÃ­ky spojenÃ© s nÃ­m hranou typu A, obsahuje aj podgraf obsahujÃºci vÅ¡etky tieto hrany. Listy grafu rieÅ¡enia musia navyÅ¡e zodpovedaÅ¥ elementÃ¡rnym problÃ©mom, o ktorÃ½ch sa vie ako ich rieÅ¡iÅ¥. Napr. jeden moÅ¾nÃ½ podgraf rieÅ¡enia A/ALEBO grafu z Obr. 2.8 obsahuje vÅ¡etky oznaÄenÃ© uzly (za predpokladu, Å¾e elementÃ¡rny PodproblÃ©m 11,   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       12.6.6 Stakeholder Engagement and Citizen Science Collaborative conservation is more likely to be sustainable. In communitybased conservation management, stakeholders from a variety of factions within the community are required to work together to implement effective conservation practices. This often creates unlikely partnerships that bridge normal political, socioeconomic and religious divides. For example, former rebels work with local government officials to monitor bats in southern Mindanao, Philippines, a region known for often violent stand-offs between the Philippine government and Islamic separatists (LM Paguntalan pers. comm., SOS 2012). Uniting stakeholders toward   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Here is yet another possibility with year, then month in full, then week of the year, then day of the week abbreviated, all separated by a single blank space: yet.another.date <- c(\"2016 January 2 Mon\",\"2017 February 6 Fri\",\"2018 March 10 Tue\") strptime(yet.another.date,\"%Y %B %W %a\") [1] \"2016-01-11\" \"2017-02-10\" \"2018-03-06\" The system is clever in that it knows the date of the Monday in week number 2 of January in 2016, and of the Tuesday in week 10 of 2018 (the information on month is redundant in this case): yet.more.dates <- c(\"2016 2 Mon\",\"2017 6 Fri\",\"2018 10 Tue\") strptime(yet.more.dates,\"%Y %W %a\") [1] \"2016-01-11\" \"2017-02-10\" \"2018-03-06\" 2.13.3   \n",
       "\n",
       "   word_count  char_count  \n",
       "0         193        1156  \n",
       "1          50         330  \n",
       "2         158         999  \n",
       "3         480        3420  \n",
       "4         486        2908  \n",
       "5          99         618  \n",
       "6          47         262  \n",
       "7         119         759  \n",
       "8          89         683  \n",
       "9         105         665  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "file_path = os.path.abspath(os.path.join(current_dir, \"..\", \"datasets\", \"paragraphs_limited_to_200_quarter.csv\"))\n",
    "books_ratings_df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "books_ratings_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272a35f4-d4bc-4678-835e-c4cf16e47f7b",
   "metadata": {},
   "source": [
    "### PROCESS JSON FILES -> get the metadata (SUMMARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97cfefc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open Research Library:\n",
      "NUM OF BOOKS: 403\n",
      "NUM OF AUTHORS: 823\n",
      "NUM OF FEED: 22\n",
      "\n",
      "MTF:\n",
      "NUM OF BOOKS: 43\n",
      "NUM OF AUTHORS: 123\n",
      "NUM OF FEED: 36\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_json_to_dataframe(file_path):\n",
    "    # Load JSON\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    authors = {}\n",
    "    entryauthor = []\n",
    "    books = []\n",
    "    feeds = []\n",
    "    book_author_mapping = {}\n",
    "    feed_entry_mapping = {}\n",
    "\n",
    "    # PROCESS JSON\n",
    "    for item in data:\n",
    "        fields = item.get(\"fields\", {})\n",
    "        model = item.get(\"model\")\n",
    "\n",
    "        # BOOKS\n",
    "        if model == \"core.entry\":\n",
    "            books.append({\n",
    "                \"id\": item[\"pk\"],\n",
    "                \"title\": fields.get(\"title\"),\n",
    "                \"summary\": fields.get(\"summary\"),\n",
    "                \"identifiers\": fields.get(\"identifiers\")\n",
    "            })\n",
    "\n",
    "        # AUTHORS\n",
    "        if model == \"core.author\":\n",
    "            authors[item[\"pk\"]] = {\n",
    "                \"name\": fields.get(\"name\", \"\"),\n",
    "                \"surname\": fields.get(\"surname\", \"\")\n",
    "            }\n",
    "\n",
    "        # BOOK-AUTHOR\n",
    "        if model == \"core.entryauthor\":\n",
    "            entry_id = fields.get(\"entry\")\n",
    "            author_id = fields.get(\"author\")\n",
    "            if entry_id not in book_author_mapping:\n",
    "                book_author_mapping[entry_id] = []\n",
    "            book_author_mapping[entry_id].append(author_id)\n",
    "\n",
    "        # FEEDS\n",
    "        if model == \"core.feed\":\n",
    "            feeds.append({\n",
    "                \"id\": item[\"pk\"],\n",
    "                \"title\": fields.get(\"title\"),\n",
    "                \"entries\": fields.get(\"entries\", [])\n",
    "            })\n",
    "            for entry_id in fields.get(\"entries\", []):\n",
    "                if entry_id not in feed_entry_mapping:\n",
    "                    feed_entry_mapping[entry_id] = []\n",
    "                feed_entry_mapping[entry_id].append(fields.get(\"title\"))\n",
    "\n",
    "    # list of book data with authors and feeds\n",
    "    book_data = []\n",
    "    for book in books:\n",
    "        book_id = book[\"id\"]\n",
    "\n",
    "        # AUTHORS for BOOKS\n",
    "        author_ids = book_author_mapping.get(book_id, [])\n",
    "        author_names = [\n",
    "            f\"{authors[author_id]['name']} {authors[author_id]['surname']}\" \n",
    "            for author_id in author_ids if author_id in authors\n",
    "        ]\n",
    "\n",
    "        # FEEDS for BOOKS\n",
    "        feed_titles = feed_entry_mapping.get(book_id, [])\n",
    "\n",
    "        # BOOK DATA\n",
    "        book_data.append({\n",
    "            \"book_title\": book[\"title\"],\n",
    "            \"summary\": book[\"summary\"],\n",
    "            \"identifiers\": book[\"identifiers\"],\n",
    "            \"authors\": \", \".join(author_names) if author_names else \"No authors\",\n",
    "            \"feeds\": \", \".join(feed_titles) if feed_titles else \"No feeds\"\n",
    "        })\n",
    "\n",
    "    print(f\"NUM OF BOOKS: {len(books)}\\nNUM OF AUTHORS: {len(authors)}\\nNUM OF FEED: {len(feeds)}\")\n",
    "\n",
    "    # DATAFRAME\n",
    "    df = pd.DataFrame(book_data)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    return df\n",
    "\n",
    "# PATH to JSON files\n",
    "current_dir = os.getcwd()\n",
    "json_path_1 = os.path.abspath(os.path.join(current_dir, \"..\", \"datasets\", \"openresearchlibrary_entities.json\"))\n",
    "json_path_2 = os.path.abspath(os.path.join(current_dir, \"..\", \"datasets\", \"mtf_entities.json\"))\n",
    "\n",
    "# PROCESS JSON files\n",
    "print(\"Open Research Library:\")\n",
    "df_opensearch = process_json_to_dataframe(json_path_1)\n",
    "print(\"\\nMTF:\")\n",
    "df_mtf = process_json_to_dataframe(json_path_2)\n",
    "\n",
    "df_summaries = pd.concat([df_opensearch, df_mtf], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bbb2d3-d671-4922-9420-2baba5bf7665",
   "metadata": {},
   "source": [
    "### OPEN RESEARCH LIBRARY - ENTITIES.JSON - HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026f9fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "identifiers",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "feeds",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b1bde9ab-6561-44b2-99f4-77a4fb08cd54",
       "rows": [
        [
         "0",
         "Digital Kenya : An Entrepreneurial Revolution in The Making",
         "Research & Development; Technology Policy; Development Economics",
         "{\"isbn\": \"urn:isbn:9783319184272\"}",
         "Bitange Ndemo, Tim Weiss",
         "OPP"
        ],
        [
         "1",
         "Environmental Governance of the Baltic Sea (Volume 10.0)",
         "Environmental Management; Water Policy",
         "{\"isbn\": \"urn:isbn:9783319270050\"}",
         "No authors",
         "BKS"
        ],
        [
         "2",
         "Weißbuch Gelenkersatz : Versorgungssituation Bei Endoprothetischen Hüft- Und Knieoperationen in Deutschland",
         "orthopedics; surgery; medicine; biotechnology",
         "{\"isbn\": \"urn:isbn:9783662529041\"}",
         "No authors",
         "DBS"
        ],
        [
         "3",
         "Saving For Development : How Latin America and The Caribbean Can Save More and Better",
         "development; economic policy",
         "{\"isbn\": \"urn:isbn:9781349949281\"}",
         "Eduardo Cavallo, Inter-American Development Bank, Tomás Serebrisky",
         "PrPr"
        ],
        [
         "4",
         "Informatics in the Future : Proceedings of the 11th European Computer Science Summit (ECSS 2015), Vienna, October 2015",
         "Introduction\n\nThis book is open access under a CC BY-NC 4.0 license.\n\nThis volume discusses the prospects and evolution of informatics (or computer science), which has become the operating system of our world, and is today seen as the science of the information society. Its artifacts change the world and its methods have an impact on how we think about and perceive the world. Classical computer science is built on the notion of an “abstract” machine, which can be instantiated by software to any concrete problem-solving machine, changing its behavior in response to external and internal states, allowing for self-reflective and “intelligent” behavior. However, current phenomena such as the Web, cyber physical systems or the Internet of Things show us that we might already have gone beyond this idea, exemplifying a metamorphosis from a stand-alone calculator to the global operating system of our society.\n\nThus computer scientists will need to reconsider the foundations of their discipline to realize the full potential of our field. Taking often contradictory developments into consideration, researchers will not be able to tackle specific technological or methodological problems in the future without also a broader reflection on their field. The papers in this book take a first step forward and reflect on these issues from different perspectives. The broad spectrum of topics includes\n\nInformatics: a discipline with a (short) history and a high impact\nInterdisciplinarity: how to do research\nEthics: what is our responsibility\nDiversity: why are there so few women in informatics\nCombining informatics, history and art: a special contribution.\nThis book is intended for all informatics researchers, in academia as well as in industry. It is our responsibility – not only as scientists but also as citizens – to make the public aware of the dichotomies and dialectic relationships of computer science.",
         "{\"isbn\": \"urn:isbn:9783319557359\"}",
         "Frank van Harmelen, Hannes Werthner",
         "DOVI"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>summary</th>\n",
       "      <th>identifiers</th>\n",
       "      <th>authors</th>\n",
       "      <th>feeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital Kenya : An Entrepreneurial Revolution in The Making</td>\n",
       "      <td>Research &amp; Development; Technology Policy; Development Economics</td>\n",
       "      <td>{\"isbn\": \"urn:isbn:9783319184272\"}</td>\n",
       "      <td>Bitange Ndemo, Tim Weiss</td>\n",
       "      <td>OPP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Environmental Governance of the Baltic Sea (Volume 10.0)</td>\n",
       "      <td>Environmental Management; Water Policy</td>\n",
       "      <td>{\"isbn\": \"urn:isbn:9783319270050\"}</td>\n",
       "      <td>No authors</td>\n",
       "      <td>BKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weißbuch Gelenkersatz : Versorgungssituation Bei Endoprothetischen Hüft- Und Knieoperationen in Deutschland</td>\n",
       "      <td>orthopedics; surgery; medicine; biotechnology</td>\n",
       "      <td>{\"isbn\": \"urn:isbn:9783662529041\"}</td>\n",
       "      <td>No authors</td>\n",
       "      <td>DBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saving For Development : How Latin America and The Caribbean Can Save More and Better</td>\n",
       "      <td>development; economic policy</td>\n",
       "      <td>{\"isbn\": \"urn:isbn:9781349949281\"}</td>\n",
       "      <td>Eduardo Cavallo, Inter-American Development Bank, Tomás Serebrisky</td>\n",
       "      <td>PrPr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Informatics in the Future : Proceedings of the 11th European Computer Science Summit (ECSS 2015), Vienna, October 2015</td>\n",
       "      <td>Introduction\\n\\nThis book is open access under a CC BY-NC 4.0 license.\\n\\nThis volume discusses the prospects and evolution of informatics (or computer science), which has become the operating system of our world, and is today seen as the science of the information society. Its artifacts change the world and its methods have an impact on how we think about and perceive the world. Classical computer science is built on the notion of an “abstract” machine, which can be instantiated by software to any concrete problem-solving machine, changing its behavior in response to external and internal states, allowing for self-reflective and “intelligent” behavior. However, current phenomena such as the Web, cyber physical systems or the Internet of Things show us that we might already have gone beyond this idea, exemplifying a metamorphosis from a stand-alone calculator to the global operating system of our society.\\n\\nThus computer scientists will need to reconsider the foundations of their discipline to realize the full potential of our field. Taking often contradictory developments into consideration, researchers will not be able to tackle specific technological or methodological problems in the future without also a broader reflection on their field. The papers in this book take a first step forward and reflect on these issues from different perspectives. The broad spectrum of topics includes\\n\\nInformatics: a discipline with a (short) history and a high impact\\nInterdisciplinarity: how to do research\\nEthics: what is our responsibility\\nDiversity: why are there so few women in informatics\\nCombining informatics, history and art: a special contribution.\\nThis book is intended for all informatics researchers, in academia as well as in industry. It is our responsibility – not only as scientists but also as citizens – to make the public aware of the dichotomies and dialectic relationships of computer science.</td>\n",
       "      <td>{\"isbn\": \"urn:isbn:9783319557359\"}</td>\n",
       "      <td>Frank van Harmelen, Hannes Werthner</td>\n",
       "      <td>DOVI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               book_title  \\\n",
       "0                                                             Digital Kenya : An Entrepreneurial Revolution in The Making   \n",
       "1                                                                Environmental Governance of the Baltic Sea (Volume 10.0)   \n",
       "2             Weißbuch Gelenkersatz : Versorgungssituation Bei Endoprothetischen Hüft- Und Knieoperationen in Deutschland   \n",
       "3                                   Saving For Development : How Latin America and The Caribbean Can Save More and Better   \n",
       "4  Informatics in the Future : Proceedings of the 11th European Computer Science Summit (ECSS 2015), Vienna, October 2015   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        summary  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Research & Development; Technology Policy; Development Economics   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Environmental Management; Water Policy   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 orthopedics; surgery; medicine; biotechnology   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  development; economic policy   \n",
       "4  Introduction\\n\\nThis book is open access under a CC BY-NC 4.0 license.\\n\\nThis volume discusses the prospects and evolution of informatics (or computer science), which has become the operating system of our world, and is today seen as the science of the information society. Its artifacts change the world and its methods have an impact on how we think about and perceive the world. Classical computer science is built on the notion of an “abstract” machine, which can be instantiated by software to any concrete problem-solving machine, changing its behavior in response to external and internal states, allowing for self-reflective and “intelligent” behavior. However, current phenomena such as the Web, cyber physical systems or the Internet of Things show us that we might already have gone beyond this idea, exemplifying a metamorphosis from a stand-alone calculator to the global operating system of our society.\\n\\nThus computer scientists will need to reconsider the foundations of their discipline to realize the full potential of our field. Taking often contradictory developments into consideration, researchers will not be able to tackle specific technological or methodological problems in the future without also a broader reflection on their field. The papers in this book take a first step forward and reflect on these issues from different perspectives. The broad spectrum of topics includes\\n\\nInformatics: a discipline with a (short) history and a high impact\\nInterdisciplinarity: how to do research\\nEthics: what is our responsibility\\nDiversity: why are there so few women in informatics\\nCombining informatics, history and art: a special contribution.\\nThis book is intended for all informatics researchers, in academia as well as in industry. It is our responsibility – not only as scientists but also as citizens – to make the public aware of the dichotomies and dialectic relationships of computer science.   \n",
       "\n",
       "                          identifiers  \\\n",
       "0  {\"isbn\": \"urn:isbn:9783319184272\"}   \n",
       "1  {\"isbn\": \"urn:isbn:9783319270050\"}   \n",
       "2  {\"isbn\": \"urn:isbn:9783662529041\"}   \n",
       "3  {\"isbn\": \"urn:isbn:9781349949281\"}   \n",
       "4  {\"isbn\": \"urn:isbn:9783319557359\"}   \n",
       "\n",
       "                                                              authors feeds  \n",
       "0                                            Bitange Ndemo, Tim Weiss   OPP  \n",
       "1                                                          No authors   BKS  \n",
       "2                                                          No authors   DBS  \n",
       "3  Eduardo Cavallo, Inter-American Development Bank, Tomás Serebrisky  PrPr  \n",
       "4                                 Frank van Harmelen, Hannes Werthner  DOVI  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_opensearch.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c1c298",
   "metadata": {},
   "source": [
    "### MTF - ENTITIES.JSON - HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bff23a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "identifiers",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "feeds",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fff2c87d-980e-4992-8007-de9d121df8f3",
       "rows": [
        [
         "0",
         "Odporúčanie pre softvérových inžinierov",
         "Táto knižka je výsledkom doktorandského seminára, ktorý som viedol v akademickom roku 2014/2015. Na Fakulte informatiky a informačných technológií máme šikovných študentov \nschopných naplniť aj náročné predstavy. Jednou takou predstavou je, aby zo seminára vznikol \nmonotematický výskumný text, ktorý dopracujeme do podoby, pripravenej na tlač. V oblasti \nprogramových a informačných systémov sa takéto štúdie podarilo vydať už niekoľkokrát. Zatiaľ \nčo v prvom zväzku Štúdií sme podchytili seminár venovaný návrhovým vzorom a v druhom se\u0002minár venovaný webovej inteligencii, v treťom sa seminár sústreďoval na podstatu softvérovej \narchitektúry a v štvrtom zväzku sme spracovali témy seminára, venovaného softvérovým paradigmám. Zatiaľ posledný, piaty zväzok sa venuje webovede, vznikajúcej vedeckej disciplíne, \nktorá chce študovať web v rôznych aspektoch.\nTento v poradí už šiesty zväzok sa zameriava na odporúčanie v softvérovom inžinierstve. \nMetódy odporúčania informácií sa intenzívne študovali v predošlých zhruba dvadsiatich rokoch \nnajmä v súvislosti s odporúčaním informácií na webe. V posledných rokoch dochádza k čoraz \nintenzívnejšiemu uvedomeniu, že tieto alebo podobné metódy môžu byť užitočné aj \nv softvérovom inžinierstve. Ide najmä o odporúčania, ktoré sa poskytnú softvérovému inžinierovi. Ukázalo sa, že je až prekvapujúco veľa možností, čo by bolo vhodné odporúčať niekomu, kto \nsa podieľa na vývoji softvéru. Druhou stránkou je pestrosť metód, ako odporúčania robiť. \nCelú problematiku som rozdelil do trinástich častí medzi študentov seminára. Východiskovým literárnym zdrojom pre štúdium bol monografický zborník [1]. Po prednesení príspevkov \na diskusii na seminári spracovali autori témy aj písomne. Prvotnú zodpovednosť za kapitoly sme \nsi podelili takto: Blšták za kapitoly 6 a 7, Bystrický za kapitoly 10 a 12, Frťala za kapitoly 9 a \n13, Kaššák za kapitoly 1 a 4 , Konôpka za kapitoly 3 a 11, Laurinec za kapitolu 8 a Lóderer za \nkapitoly 2 a 5. Spomenutý zborník sa ukázal byť v mnohom aj cennou inšpiráciou pri písaní, čo \ns vďakou priznávame. Autori však preštudovali množstvo ďalšej súčasnej vedeckej literatúry \no príslušnej problematike, o čom svedčia aj zoznamy literatúry pripojené na koniec každej kapitoly. Vedomosti z nich získané tiež využili pri písaní textu.",
         "{\"doi\": null, \"isbn\": \"978-3-642-45134-8\"}",
         "Pavol Návrat, Miroslav Blšták, Michal Bystrický, Tomáš Frťala, Ondrej Kaššák, Martin Konôpka, Peter Laurinec, Marek Lóderer",
         "PSI_B"
        ],
        [
         "1",
         "Úvod do matematickej logiky",
         "Tento učebný  text je určený študentom prvého ročníka fakulty informatiky a in- formačných  technológií  Slovenskej  technickej  univerzity  v  Bratislave.  Predstavuje spísane  prednášky  z  predmetu  matematická logika.\nŠtruktúra tohoto textu je upravená tak, že každá kapitola tvorí jednu prednášku.\nČitateľovi predkladáme 11 kapitol, čo je podľa našich skúsenosti maximálny možný počet  prednášok,  ktorý sa  dá  stihnúť’  počas  13-týždňového  semestra.  V zlých ”rokoch“  sa  fyzicky  nestihne  odprednášať  ani  11  prednášok.  Vtedy  tento  učebný´\ntext slúži študentom na samoštúdium, pretože základne vedomosti majú mat’ všetci študenti  rovnaké,  bez  ohľadu na  rok, v  ktorom študovali.\nPo  obsahovej  stránke  možno  učebnicu  rozdeliť’ na štyri časti.\n-\tV prvých troch kapitolách zadeﬁnujeme formuly výrokovej logiky, objasníme si  ich  význam  a  ukážeme,  ako  sa  odvodzujú.  Ukážeme  si  tiež,  že  daným spôsobom  vieme  formulu  odvodiť’ práve vtedy, keď je  vždy  pravdivá.\n-\tKapitoly  4  až  6  sú  nadstavbou  prvých  troch.  Opíšeme  si  ďalšie  metódy, pomocou  ktorých  vieme  zistiť’,  či  je  formula  tautológia,  ako  aj  aplikácie výrokovej logiky na  spínacie  a  logické obvody  a  na  neurónové  siete.\n-\tĎalšie tri kapitoly sa zaoberajú predikátovou logikou. Tak ako pri výrokovej logike, objasníme si význam formúl predikátovej logiky a metódy ich odvodzovania.  Na  odvodzovanie  formúl  budeme   používať’  sémantické   stromy a  Gentzenovský  (sekventový) kalkulus.\n-\tV  posledných  dvoch  kapitolách  sa  zaoberáme  netradičnými  logikami.  Opíšeme  si  základy modálnej  a  viachodnotovej  logiky.",
         "{\"doi\": null, \"isbn\": \"978-80-227-4656-4\"}",
         "Martin Knor",
         "MA_B"
        ],
        [
         "2",
         "Algebra a diskrétna  matematika",
         "Cieľom tejto učebnice je poskytnúť študentom informatiky na Fakulte informatiky a informačných technológií STU ucelený text k prednáške „Algebra \na diskrétna matematika“. Diskrétna matematika patrí medzi teoretické základy \ninformatiky. Slúži nielen pre rozvoj matematicko-logických schopností študentov, ale aj ako teoretická príprava pre ďalšie „pokročilejšie“ informatické predmety. Pri koncipovaní obsahu tejto prednášky stáli sme pred neľahkou úlohou, čo \nzahrnúť do jej obsahu a čo nie. Pretože táto prednáška substituuje čiastočne aj \nbývalý predmet „Lineárna algebra“, zahrnuli sme z tejto oblasti do učebnice \nv rozsahu dvoch prednášok aj základy lineárnej algebry, teórie matíc a sústav \nlineárnych rovníc spolu s elementárnou teóriou determinantov. \nUčebnica je určená pre študentov prvého ročníka bakalárskeho štúdia, ktorí majú \nzákladné stredoškolské vedomosti z teórie množín, algebry a výrokovej logiky. \nV prednáške sme sa snažili čo najviac vyjsť v ústrety potrebám informatiky, preto \naj oproti časti týkajúcej sa algebry je relatívne uprednostnená diskrétna matematika. Cieľom učebnice je aj rozvinúť u študentov schopnosť rigorózneho matematického myslenia pri riešení a formulovaní problémov informatiky. \nPrvá kapitola sa týka metód matematického dôkazu. Kapitoly 2 až 5 sú venované \nteórii množín a kombinatorike, v 6. a 7. kapitole sa venujeme grupám a boolovskej algebre. Kapitoly 8 až 9 sú venované maticiam, sústavám lineárnych rovníc \na determinantom. Zvyšok učebnice sa v 10. až 13. kapitole venuje teórii grafov \na základným algoritmom a aplikáciám teórie grafov. \nKaždá kapitola je sprevádzaná príkladmi, ktorých riešenie poskytne študentom \nschopnosť dobre sa orientovať v danej problematike. Chceme poďakovať mnohým našim študentom, ktorí nám pomohli nájsť veľa nepríjemných preklepov, \nnepresností a evidentných chýb, a tým prispeli k zvýšeniu kvality tejto učebnice. \nTaktiež sa musíme poďakovať nášmu zosnulému kolegovi prof. Ing. Norbertovi \nFrištackému, PhD., s ktorým sme sa často radili pri koncipovaní sylabu prednášky. Na jeho radu sme zaradili do prednášky Quinovu a McCluskeyho metódu \noptimalizácie Boolovej funkcie špecifikujúcej logický obvod. Až pri prednášaní \ntohto predmetu sme zistili, že táto „aplikačná“ časť diskrétnej matematiky patrí \nmedzi študentmi k najobľúbenejšej časti predmetu.",
         "{\"doi\": null, \"isbn\": \"9788022729345\"}",
         "Vladimír Kvasnička, Jiří Pospíchal",
         "ADM_B"
        ],
        [
         "3",
         "Základy digitálnych mien a blockchain sietí",
         "Tento učebný text je primárne určený ako podporná literatúra pre predmet Digitálne meny<br>a blockchain, no je ho možné z časti použiť aj na predmet Inovácie na finančných trhoch, ktoré<br>sa vyučujú na Fakulte informatiky a informačných technológií Slovenskej technickej univerzite<br>v Bratislave. Čitateľ sa oboznámi so základmi digitálnych a virtuálnych mien ako sú bitcoin,<br>ethereum, polkadot, a iné. Ďalej sa dozvie o blockchain sieťach, ako fungujú decentralizovane<br>a distribuovane, ako ukladajú dáta, ako sa posielajú transakcie a ako sa dosahuje konsenzus , ale<br>nerozoberáme veľmi do hĺbky ako fungujú konsenzuálne algoritmy . Značná časť obsahu je<br>venovaná problematike aplikačných prípad ov použitia blockchain technológie, jej vhodnosti<br>a le okrajovo takisto výzvam, ktorým výskumno vývojové tímy čelili a ich riešeniam Tento<br>materiál nepokrýva všetky oblasti, ktoré sú vyučované v rámci predmetu Digitálne meny a<br>blockchain . Oblasť komunikácie na základe sieťových protokolov a takisto nižšej úrovni<br>kryptogra fie nie sú vôbec v texte spomínané.",
         "{\"doi\": null, \"isbn\": \"ISBN 978 80 227 5396 8\"}",
         "Kristián Košťál",
         "DMBLOCK_B"
        ],
        [
         "4",
         "Quantum Computing for Everyone",
         "Quantum computing is often in the news: China teleported a qubit from earth to a satellite; Shor’s algorithm has put our current encryption methods at risk; quantum key distribution will make encryption safe again;\nGrover’s algorithm will speed up data searches. But what does all this really mean? How does it all work? All of this will be explained.",
         "{\"doi\": \"10.7551/mitpress/11860.001.0001\", \"isbn\": \"9780262350914\"}",
         "Chris Bernhardt",
         "No feeds"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>summary</th>\n",
       "      <th>identifiers</th>\n",
       "      <th>authors</th>\n",
       "      <th>feeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Odporúčanie pre softvérových inžinierov</td>\n",
       "      <td>Táto knižka je výsledkom doktorandského seminára, ktorý som viedol v akademickom roku 2014/2015. Na Fakulte informatiky a informačných technológií máme šikovných študentov \\nschopných naplniť aj náročné predstavy. Jednou takou predstavou je, aby zo seminára vznikol \\nmonotematický výskumný text, ktorý dopracujeme do podoby, pripravenej na tlač. V oblasti \\nprogramových a informačných systémov sa takéto štúdie podarilo vydať už niekoľkokrát. Zatiaľ \\nčo v prvom zväzku Štúdií sme podchytili seminár venovaný návrhovým vzorom a v druhom se\u0002minár venovaný webovej inteligencii, v treťom sa seminár sústreďoval na podstatu softvérovej \\narchitektúry a v štvrtom zväzku sme spracovali témy seminára, venovaného softvérovým paradigmám. Zatiaľ posledný, piaty zväzok sa venuje webovede, vznikajúcej vedeckej disciplíne, \\nktorá chce študovať web v rôznych aspektoch.\\nTento v poradí už šiesty zväzok sa zameriava na odporúčanie v softvérovom inžinierstve. \\nMetódy odporúčania informácií sa intenzívne študovali v predošlých zhruba dvadsiatich rokoch \\nnajmä v súvislosti s odporúčaním informácií na webe. V posledných rokoch dochádza k čoraz \\nintenzívnejšiemu uvedomeniu, že tieto alebo podobné metódy môžu byť užitočné aj \\nv softvérovom inžinierstve. Ide najmä o odporúčania, ktoré sa poskytnú softvérovému inžinierovi. Ukázalo sa, že je až prekvapujúco veľa možností, čo by bolo vhodné odporúčať niekomu, kto \\nsa podieľa na vývoji softvéru. Druhou stránkou je pestrosť metód, ako odporúčania robiť. \\nCelú problematiku som rozdelil do trinástich častí medzi študentov seminára. Východiskovým literárnym zdrojom pre štúdium bol monografický zborník [1]. Po prednesení príspevkov \\na diskusii na seminári spracovali autori témy aj písomne. Prvotnú zodpovednosť za kapitoly sme \\nsi podelili takto: Blšták za kapitoly 6 a 7, Bystrický za kapitoly 10 a 12, Frťala za kapitoly 9 a \\n13, Kaššák za kapitoly 1 a 4 , Konôpka za kapitoly 3 a 11, Laurinec za kapitolu 8 a Lóderer za \\nkapitoly 2 a 5. Spomenutý zborník sa ukázal byť v mnohom aj cennou inšpiráciou pri písaní, čo \\ns vďakou priznávame. Autori však preštudovali množstvo ďalšej súčasnej vedeckej literatúry \\no príslušnej problematike, o čom svedčia aj zoznamy literatúry pripojené na koniec každej kapitoly. Vedomosti z nich získané tiež využili pri písaní textu.</td>\n",
       "      <td>{\"doi\": null, \"isbn\": \"978-3-642-45134-8\"}</td>\n",
       "      <td>Pavol Návrat, Miroslav Blšták, Michal Bystrický, Tomáš Frťala, Ondrej Kaššák, Martin Konôpka, Peter Laurinec, Marek Lóderer</td>\n",
       "      <td>PSI_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Úvod do matematickej logiky</td>\n",
       "      <td>Tento učebný  text je určený študentom prvého ročníka fakulty informatiky a in- formačných  technológií  Slovenskej  technickej  univerzity  v  Bratislave.  Predstavuje spísane  prednášky  z  predmetu  matematická logika.\\nŠtruktúra tohoto textu je upravená tak, že každá kapitola tvorí jednu prednášku.\\nČitateľovi predkladáme 11 kapitol, čo je podľa našich skúsenosti maximálny možný počet  prednášok,  ktorý sa  dá  stihnúť’  počas  13-týždňového  semestra.  V zlých ”rokoch“  sa  fyzicky  nestihne  odprednášať  ani  11  prednášok.  Vtedy  tento  učebný´\\ntext slúži študentom na samoštúdium, pretože základne vedomosti majú mat’ všetci študenti  rovnaké,  bez  ohľadu na  rok, v  ktorom študovali.\\nPo  obsahovej  stránke  možno  učebnicu  rozdeliť’ na štyri časti.\\n-\\tV prvých troch kapitolách zadeﬁnujeme formuly výrokovej logiky, objasníme si  ich  význam  a  ukážeme,  ako  sa  odvodzujú.  Ukážeme  si  tiež,  že  daným spôsobom  vieme  formulu  odvodiť’ práve vtedy, keď je  vždy  pravdivá.\\n-\\tKapitoly  4  až  6  sú  nadstavbou  prvých  troch.  Opíšeme  si  ďalšie  metódy, pomocou  ktorých  vieme  zistiť’,  či  je  formula  tautológia,  ako  aj  aplikácie výrokovej logiky na  spínacie  a  logické obvody  a  na  neurónové  siete.\\n-\\tĎalšie tri kapitoly sa zaoberajú predikátovou logikou. Tak ako pri výrokovej logike, objasníme si význam formúl predikátovej logiky a metódy ich odvodzovania.  Na  odvodzovanie  formúl  budeme   používať’  sémantické   stromy a  Gentzenovský  (sekventový) kalkulus.\\n-\\tV  posledných  dvoch  kapitolách  sa  zaoberáme  netradičnými  logikami.  Opíšeme  si  základy modálnej  a  viachodnotovej  logiky.</td>\n",
       "      <td>{\"doi\": null, \"isbn\": \"978-80-227-4656-4\"}</td>\n",
       "      <td>Martin Knor</td>\n",
       "      <td>MA_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algebra a diskrétna  matematika</td>\n",
       "      <td>Cieľom tejto učebnice je poskytnúť študentom informatiky na Fakulte informatiky a informačných technológií STU ucelený text k prednáške „Algebra \\na diskrétna matematika“. Diskrétna matematika patrí medzi teoretické základy \\ninformatiky. Slúži nielen pre rozvoj matematicko-logických schopností študentov, ale aj ako teoretická príprava pre ďalšie „pokročilejšie“ informatické predmety. Pri koncipovaní obsahu tejto prednášky stáli sme pred neľahkou úlohou, čo \\nzahrnúť do jej obsahu a čo nie. Pretože táto prednáška substituuje čiastočne aj \\nbývalý predmet „Lineárna algebra“, zahrnuli sme z tejto oblasti do učebnice \\nv rozsahu dvoch prednášok aj základy lineárnej algebry, teórie matíc a sústav \\nlineárnych rovníc spolu s elementárnou teóriou determinantov. \\nUčebnica je určená pre študentov prvého ročníka bakalárskeho štúdia, ktorí majú \\nzákladné stredoškolské vedomosti z teórie množín, algebry a výrokovej logiky. \\nV prednáške sme sa snažili čo najviac vyjsť v ústrety potrebám informatiky, preto \\naj oproti časti týkajúcej sa algebry je relatívne uprednostnená diskrétna matematika. Cieľom učebnice je aj rozvinúť u študentov schopnosť rigorózneho matematického myslenia pri riešení a formulovaní problémov informatiky. \\nPrvá kapitola sa týka metód matematického dôkazu. Kapitoly 2 až 5 sú venované \\nteórii množín a kombinatorike, v 6. a 7. kapitole sa venujeme grupám a boolovskej algebre. Kapitoly 8 až 9 sú venované maticiam, sústavám lineárnych rovníc \\na determinantom. Zvyšok učebnice sa v 10. až 13. kapitole venuje teórii grafov \\na základným algoritmom a aplikáciám teórie grafov. \\nKaždá kapitola je sprevádzaná príkladmi, ktorých riešenie poskytne študentom \\nschopnosť dobre sa orientovať v danej problematike. Chceme poďakovať mnohým našim študentom, ktorí nám pomohli nájsť veľa nepríjemných preklepov, \\nnepresností a evidentných chýb, a tým prispeli k zvýšeniu kvality tejto učebnice. \\nTaktiež sa musíme poďakovať nášmu zosnulému kolegovi prof. Ing. Norbertovi \\nFrištackému, PhD., s ktorým sme sa často radili pri koncipovaní sylabu prednášky. Na jeho radu sme zaradili do prednášky Quinovu a McCluskeyho metódu \\noptimalizácie Boolovej funkcie špecifikujúcej logický obvod. Až pri prednášaní \\ntohto predmetu sme zistili, že táto „aplikačná“ časť diskrétnej matematiky patrí \\nmedzi študentmi k najobľúbenejšej časti predmetu.</td>\n",
       "      <td>{\"doi\": null, \"isbn\": \"9788022729345\"}</td>\n",
       "      <td>Vladimír Kvasnička, Jiří Pospíchal</td>\n",
       "      <td>ADM_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Základy digitálnych mien a blockchain sietí</td>\n",
       "      <td>Tento učebný text je primárne určený ako podporná literatúra pre predmet Digitálne meny&lt;br&gt;a blockchain, no je ho možné z časti použiť aj na predmet Inovácie na finančných trhoch, ktoré&lt;br&gt;sa vyučujú na Fakulte informatiky a informačných technológií Slovenskej technickej univerzite&lt;br&gt;v Bratislave. Čitateľ sa oboznámi so základmi digitálnych a virtuálnych mien ako sú bitcoin,&lt;br&gt;ethereum, polkadot, a iné. Ďalej sa dozvie o blockchain sieťach, ako fungujú decentralizovane&lt;br&gt;a distribuovane, ako ukladajú dáta, ako sa posielajú transakcie a ako sa dosahuje konsenzus , ale&lt;br&gt;nerozoberáme veľmi do hĺbky ako fungujú konsenzuálne algoritmy . Značná časť obsahu je&lt;br&gt;venovaná problematike aplikačných prípad ov použitia blockchain technológie, jej vhodnosti&lt;br&gt;a le okrajovo takisto výzvam, ktorým výskumno vývojové tímy čelili a ich riešeniam Tento&lt;br&gt;materiál nepokrýva všetky oblasti, ktoré sú vyučované v rámci predmetu Digitálne meny a&lt;br&gt;blockchain . Oblasť komunikácie na základe sieťových protokolov a takisto nižšej úrovni&lt;br&gt;kryptogra fie nie sú vôbec v texte spomínané.</td>\n",
       "      <td>{\"doi\": null, \"isbn\": \"ISBN 978 80 227 5396 8\"}</td>\n",
       "      <td>Kristián Košťál</td>\n",
       "      <td>DMBLOCK_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quantum Computing for Everyone</td>\n",
       "      <td>Quantum computing is often in the news: China teleported a qubit from earth to a satellite; Shor’s algorithm has put our current encryption methods at risk; quantum key distribution will make encryption safe again;\\nGrover’s algorithm will speed up data searches. But what does all this really mean? How does it all work? All of this will be explained.</td>\n",
       "      <td>{\"doi\": \"10.7551/mitpress/11860.001.0001\", \"isbn\": \"9780262350914\"}</td>\n",
       "      <td>Chris Bernhardt</td>\n",
       "      <td>No feeds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    book_title  \\\n",
       "0      Odporúčanie pre softvérových inžinierov   \n",
       "1                  Úvod do matematickej logiky   \n",
       "2              Algebra a diskrétna  matematika   \n",
       "3  Základy digitálnych mien a blockchain sietí   \n",
       "4               Quantum Computing for Everyone   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        summary  \\\n",
       "0                                            Táto knižka je výsledkom doktorandského seminára, ktorý som viedol v akademickom roku 2014/2015. Na Fakulte informatiky a informačných technológií máme šikovných študentov \\nschopných naplniť aj náročné predstavy. Jednou takou predstavou je, aby zo seminára vznikol \\nmonotematický výskumný text, ktorý dopracujeme do podoby, pripravenej na tlač. V oblasti \\nprogramových a informačných systémov sa takéto štúdie podarilo vydať už niekoľkokrát. Zatiaľ \\nčo v prvom zväzku Štúdií sme podchytili seminár venovaný návrhovým vzorom a v druhom se\u0002minár venovaný webovej inteligencii, v treťom sa seminár sústreďoval na podstatu softvérovej \\narchitektúry a v štvrtom zväzku sme spracovali témy seminára, venovaného softvérovým paradigmám. Zatiaľ posledný, piaty zväzok sa venuje webovede, vznikajúcej vedeckej disciplíne, \\nktorá chce študovať web v rôznych aspektoch.\\nTento v poradí už šiesty zväzok sa zameriava na odporúčanie v softvérovom inžinierstve. \\nMetódy odporúčania informácií sa intenzívne študovali v predošlých zhruba dvadsiatich rokoch \\nnajmä v súvislosti s odporúčaním informácií na webe. V posledných rokoch dochádza k čoraz \\nintenzívnejšiemu uvedomeniu, že tieto alebo podobné metódy môžu byť užitočné aj \\nv softvérovom inžinierstve. Ide najmä o odporúčania, ktoré sa poskytnú softvérovému inžinierovi. Ukázalo sa, že je až prekvapujúco veľa možností, čo by bolo vhodné odporúčať niekomu, kto \\nsa podieľa na vývoji softvéru. Druhou stránkou je pestrosť metód, ako odporúčania robiť. \\nCelú problematiku som rozdelil do trinástich častí medzi študentov seminára. Východiskovým literárnym zdrojom pre štúdium bol monografický zborník [1]. Po prednesení príspevkov \\na diskusii na seminári spracovali autori témy aj písomne. Prvotnú zodpovednosť za kapitoly sme \\nsi podelili takto: Blšták za kapitoly 6 a 7, Bystrický za kapitoly 10 a 12, Frťala za kapitoly 9 a \\n13, Kaššák za kapitoly 1 a 4 , Konôpka za kapitoly 3 a 11, Laurinec za kapitolu 8 a Lóderer za \\nkapitoly 2 a 5. Spomenutý zborník sa ukázal byť v mnohom aj cennou inšpiráciou pri písaní, čo \\ns vďakou priznávame. Autori však preštudovali množstvo ďalšej súčasnej vedeckej literatúry \\no príslušnej problematike, o čom svedčia aj zoznamy literatúry pripojené na koniec každej kapitoly. Vedomosti z nich získané tiež využili pri písaní textu.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Tento učebný  text je určený študentom prvého ročníka fakulty informatiky a in- formačných  technológií  Slovenskej  technickej  univerzity  v  Bratislave.  Predstavuje spísane  prednášky  z  predmetu  matematická logika.\\nŠtruktúra tohoto textu je upravená tak, že každá kapitola tvorí jednu prednášku.\\nČitateľovi predkladáme 11 kapitol, čo je podľa našich skúsenosti maximálny možný počet  prednášok,  ktorý sa  dá  stihnúť’  počas  13-týždňového  semestra.  V zlých ”rokoch“  sa  fyzicky  nestihne  odprednášať  ani  11  prednášok.  Vtedy  tento  učebný´\\ntext slúži študentom na samoštúdium, pretože základne vedomosti majú mat’ všetci študenti  rovnaké,  bez  ohľadu na  rok, v  ktorom študovali.\\nPo  obsahovej  stránke  možno  učebnicu  rozdeliť’ na štyri časti.\\n-\\tV prvých troch kapitolách zadeﬁnujeme formuly výrokovej logiky, objasníme si  ich  význam  a  ukážeme,  ako  sa  odvodzujú.  Ukážeme  si  tiež,  že  daným spôsobom  vieme  formulu  odvodiť’ práve vtedy, keď je  vždy  pravdivá.\\n-\\tKapitoly  4  až  6  sú  nadstavbou  prvých  troch.  Opíšeme  si  ďalšie  metódy, pomocou  ktorých  vieme  zistiť’,  či  je  formula  tautológia,  ako  aj  aplikácie výrokovej logiky na  spínacie  a  logické obvody  a  na  neurónové  siete.\\n-\\tĎalšie tri kapitoly sa zaoberajú predikátovou logikou. Tak ako pri výrokovej logike, objasníme si význam formúl predikátovej logiky a metódy ich odvodzovania.  Na  odvodzovanie  formúl  budeme   používať’  sémantické   stromy a  Gentzenovský  (sekventový) kalkulus.\\n-\\tV  posledných  dvoch  kapitolách  sa  zaoberáme  netradičnými  logikami.  Opíšeme  si  základy modálnej  a  viachodnotovej  logiky.   \n",
       "2  Cieľom tejto učebnice je poskytnúť študentom informatiky na Fakulte informatiky a informačných technológií STU ucelený text k prednáške „Algebra \\na diskrétna matematika“. Diskrétna matematika patrí medzi teoretické základy \\ninformatiky. Slúži nielen pre rozvoj matematicko-logických schopností študentov, ale aj ako teoretická príprava pre ďalšie „pokročilejšie“ informatické predmety. Pri koncipovaní obsahu tejto prednášky stáli sme pred neľahkou úlohou, čo \\nzahrnúť do jej obsahu a čo nie. Pretože táto prednáška substituuje čiastočne aj \\nbývalý predmet „Lineárna algebra“, zahrnuli sme z tejto oblasti do učebnice \\nv rozsahu dvoch prednášok aj základy lineárnej algebry, teórie matíc a sústav \\nlineárnych rovníc spolu s elementárnou teóriou determinantov. \\nUčebnica je určená pre študentov prvého ročníka bakalárskeho štúdia, ktorí majú \\nzákladné stredoškolské vedomosti z teórie množín, algebry a výrokovej logiky. \\nV prednáške sme sa snažili čo najviac vyjsť v ústrety potrebám informatiky, preto \\naj oproti časti týkajúcej sa algebry je relatívne uprednostnená diskrétna matematika. Cieľom učebnice je aj rozvinúť u študentov schopnosť rigorózneho matematického myslenia pri riešení a formulovaní problémov informatiky. \\nPrvá kapitola sa týka metód matematického dôkazu. Kapitoly 2 až 5 sú venované \\nteórii množín a kombinatorike, v 6. a 7. kapitole sa venujeme grupám a boolovskej algebre. Kapitoly 8 až 9 sú venované maticiam, sústavám lineárnych rovníc \\na determinantom. Zvyšok učebnice sa v 10. až 13. kapitole venuje teórii grafov \\na základným algoritmom a aplikáciám teórie grafov. \\nKaždá kapitola je sprevádzaná príkladmi, ktorých riešenie poskytne študentom \\nschopnosť dobre sa orientovať v danej problematike. Chceme poďakovať mnohým našim študentom, ktorí nám pomohli nájsť veľa nepríjemných preklepov, \\nnepresností a evidentných chýb, a tým prispeli k zvýšeniu kvality tejto učebnice. \\nTaktiež sa musíme poďakovať nášmu zosnulému kolegovi prof. Ing. Norbertovi \\nFrištackému, PhD., s ktorým sme sa často radili pri koncipovaní sylabu prednášky. Na jeho radu sme zaradili do prednášky Quinovu a McCluskeyho metódu \\noptimalizácie Boolovej funkcie špecifikujúcej logický obvod. Až pri prednášaní \\ntohto predmetu sme zistili, že táto „aplikačná“ časť diskrétnej matematiky patrí \\nmedzi študentmi k najobľúbenejšej časti predmetu.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Tento učebný text je primárne určený ako podporná literatúra pre predmet Digitálne meny<br>a blockchain, no je ho možné z časti použiť aj na predmet Inovácie na finančných trhoch, ktoré<br>sa vyučujú na Fakulte informatiky a informačných technológií Slovenskej technickej univerzite<br>v Bratislave. Čitateľ sa oboznámi so základmi digitálnych a virtuálnych mien ako sú bitcoin,<br>ethereum, polkadot, a iné. Ďalej sa dozvie o blockchain sieťach, ako fungujú decentralizovane<br>a distribuovane, ako ukladajú dáta, ako sa posielajú transakcie a ako sa dosahuje konsenzus , ale<br>nerozoberáme veľmi do hĺbky ako fungujú konsenzuálne algoritmy . Značná časť obsahu je<br>venovaná problematike aplikačných prípad ov použitia blockchain technológie, jej vhodnosti<br>a le okrajovo takisto výzvam, ktorým výskumno vývojové tímy čelili a ich riešeniam Tento<br>materiál nepokrýva všetky oblasti, ktoré sú vyučované v rámci predmetu Digitálne meny a<br>blockchain . Oblasť komunikácie na základe sieťových protokolov a takisto nižšej úrovni<br>kryptogra fie nie sú vôbec v texte spomínané.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Quantum computing is often in the news: China teleported a qubit from earth to a satellite; Shor’s algorithm has put our current encryption methods at risk; quantum key distribution will make encryption safe again;\\nGrover’s algorithm will speed up data searches. But what does all this really mean? How does it all work? All of this will be explained.   \n",
       "\n",
       "                                                           identifiers  \\\n",
       "0                           {\"doi\": null, \"isbn\": \"978-3-642-45134-8\"}   \n",
       "1                           {\"doi\": null, \"isbn\": \"978-80-227-4656-4\"}   \n",
       "2                               {\"doi\": null, \"isbn\": \"9788022729345\"}   \n",
       "3                      {\"doi\": null, \"isbn\": \"ISBN 978 80 227 5396 8\"}   \n",
       "4  {\"doi\": \"10.7551/mitpress/11860.001.0001\", \"isbn\": \"9780262350914\"}   \n",
       "\n",
       "                                                                                                                       authors  \\\n",
       "0  Pavol Návrat, Miroslav Blšták, Michal Bystrický, Tomáš Frťala, Ondrej Kaššák, Martin Konôpka, Peter Laurinec, Marek Lóderer   \n",
       "1                                                                                                                  Martin Knor   \n",
       "2                                                                                           Vladimír Kvasnička, Jiří Pospíchal   \n",
       "3                                                                                                              Kristián Košťál   \n",
       "4                                                                                                              Chris Bernhardt   \n",
       "\n",
       "       feeds  \n",
       "0      PSI_B  \n",
       "1       MA_B  \n",
       "2      ADM_B  \n",
       "3  DMBLOCK_B  \n",
       "4   No feeds  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mtf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab881b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f35e464a",
   "metadata": {},
   "source": [
    "## Analyze - Public Dataset - GoodReads books - book descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5159b6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "no_of_ratings",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "no_of_reviews",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "genres",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "59790b4f-500c-4648-936b-9c9a6ac6006e",
       "rows": [
        [
         "0",
         "0",
         "Divergent",
         "Veronica Roth",
         "4.15",
         "3765886",
         "Â 117,791",
         "In Beatrice Prior's dystopian Chicago world, society is divided into five factions, each dedicated to the cultivation of a particular virtueÃ¢ÂÂCandor (the honest), Abnegation (the selfless), Dauntless (the brave), Amity (the peaceful), and Erudite (the intelligent). On an appointed day of every year, all sixteen-year-olds must select the faction to which they will devote the rest of their lives. For Beatrice, the decision is between staying with her family and being who she really isÃ¢ÂÂshe can't have both. So she makes a choice that surprises everyone, including herself.During the highly competitive initiation that follows, Beatrice renames herself Tris and struggles alongside her fellow initiates to live out the choice they have made. Together they must undergo extreme physical tests of endurance and intense psychological simulations, some with devastating consequences. As initiation transforms them all, Tris must determine who her friends really areÃ¢ÂÂand where, exactly, a romance with a sometimes fascinating, sometimes exasperating boy fits into the life she's chosen. But Tris also has a secret, one she's kept hidden from everyone because she's been warned it can mean death. And as she discovers unrest and growing conflict that threaten to unravel her seemingly perfect society, she also learns that her secret might help her save those she loves . . . or it might destroy her.",
         "Young Adult, Dystopia, Fantasy, Fiction, Science Fiction, Romance, Adventure"
        ],
        [
         "1",
         "1",
         "Catching Fire",
         "Suzanne Collins",
         "4.31",
         "3305054",
         "Â 113,480",
         "Sparks are igniting.Flames are spreading.And the Capitol wants revenge. Against all odds, Katniss Everdeen has won the Hunger Games. She and fellow District 12 tribute Peeta Mellark are miraculously still alive. Katniss should be relieved, happy even. After all, she has returned to her family and her longtime friend, Gale. Yet nothing is the way Katniss wishes it to be. Gale holds her at an icy distance. Peeta has turned his back on her completely. And there are whispers of a rebellion against the CapitolÃ¢ÂÂa rebellion that Katniss and Peeta may have helped create. Much to her shock, Katniss has fueled an unrest that she's afraid she cannot stop. And what scares her even more is that she's not entirely convinced she should try. As time draws near for Katniss and Peeta to visit the districts on the Capitol's cruel Victory Tour, the stakes are higher than ever. If they can't prove, without a shadow of a doubt, that they are lost in their love for each other, the consequences will be horrifying.In Catching Fire, the second novel of the Hunger Games trilogy, Suzanne Collins continues the story of Katniss Everdeen, testing her more than ever before . . . and surprising readers at every turn.",
         "Young Adult, Dystopia, Fiction, Fantasy, Science Fiction, Romance, Adventure"
        ],
        [
         "2",
         "2",
         "The Fault in Our Stars",
         "John Green",
         "4.15",
         "4851513",
         "Â 174,662",
         "Despite the tumor-shrinking medical miracle that has bought her a few years, Hazel has never been anything but terminal, her final chapter inscribed upon diagnosis. But when a gorgeous plot twist named Augustus Waters suddenly appears at Cancer Kid Support Group, Hazel's story is about to be completely rewritten.Insightful, bold, irreverent, and raw, The Fault in Our Stars is award-winning author John Green's most ambitious and heartbreaking work yet, brilliantly exploring the funny, thrilling, and tragic business of being alive and in love.",
         "Young Adult, Romance, Fiction, Contemporary, Realistic Fiction, Teen, Coming Of Age"
        ],
        [
         "3",
         "3",
         "To Kill a Mockingbird",
         "Harper Lee",
         "4.27",
         "5784553",
         "Â 112,055",
         "The unforgettable novel of a childhood in a sleepy Southern town and the crisis of conscience that rocked it. \"To Kill A Mockingbird\" became both an instant bestseller and a critical success when it was first published in 1960. It went on to win the Pulitzer Prize in 1961 and was later made into an Academy Award-winning film, also a classic.Compassionate, dramatic, and deeply moving, \"To Kill A Mockingbird\" takes readers to the roots of human behavior - to innocence and experience, kindness and cruelty, love and hatred, humor and pathos. Now with over 18 million copies in print and translated into forty languages, this regional story by a young Alabama woman claims universal appeal. Harper Lee always considered her book to be a simple love story. Today it is regarded as a masterpiece of American literature.",
         "Classics, Fiction, Historical Fiction, School, Literature, Young Adult, Historical"
        ],
        [
         "4",
         "4",
         "The Lightning Thief",
         "Rick Riordan",
         "4.3",
         "2752945",
         "Â 87,446",
         "Alternate cover for this ISBN can be found herePercy Jackson is a good kid, but he can't seem to focus on his schoolwork or control his temper. And lately, being away at boarding school is only getting worse - Percy could have sworn his pre-algebra teacher turned into a monster and tried to kill him. When Percy's mom finds out, she knows it's time that he knew the truth about where he came from, and that he go to the one place he'll be safe. She sends Percy to Camp Half Blood, a summer camp for demigods (on Long Island), where he learns that the father he never knew is Poseidon, God of the Sea. Soon a mystery unfolds and together with his friendsÃ¢ÂÂone a satyr and the other the demigod daughter of Athena - Percy sets out on a quest across the United States to reach the gates of the Underworld (located in a recording studio in Hollywood) and prevent a catastrophic war between the gods.",
         "Fantasy, Young Adult, Mythology, Fiction, Middle Grade, Adventure, Greek Mythology"
        ],
        [
         "5",
         "5",
         "Harry Potter and the Prisoner of Azkaban",
         "J.K. Rowling",
         "4.58",
         "3889833",
         "Â 77,063",
         "Harry Potter, along with his best friends, Ron and Hermione, is about to start his third year at Hogwarts School of Witchcraft and Wizardry. Harry can't wait to get back to school after the summer holidays. (Who wouldn't if they lived with the horrible Dursleys?) But when Harry gets to Hogwarts, the atmosphere is tense. There's an escaped mass murderer on the loose, and the sinister prison guards of Azkaban have been called in to guard the school...",
         "Fantasy, Fiction, Young Adult, Magic, Childrens, Middle Grade, Audiobook"
        ],
        [
         "6",
         "6",
         "The Book Thief",
         "Markus Zusak",
         "4.39",
         "2410045",
         "Â 138,420",
         "Librarian's note: An alternate cover edition can be found hereIt is 1939. Nazi Germany. The country is holding its breath. Death has never been busier, and will be busier still.By her brother's graveside, Liesel's life is changed when she picks up a single object, partially hidden in the snow. It is The Gravedigger's Handbook, left behind there by accident, and it is her first act of book thievery. So begins a love affair with books and words, as Liesel, with the help of her accordian-playing foster father, learns to read. Soon she is stealing books from Nazi book-burnings, the mayor's wife's library, wherever there are books to be found.But these are dangerous times. When Liesel's foster family hides a Jew in their basement, Liesel's world is both opened up, and closed down.In superbly crafted writing that burns with intensity, award-winning author Markus Zusak has given us one of the most enduring stories of our time.(Note: this title was not published as YA fiction)",
         "Historical Fiction, Fiction, Young Adult, Historical, Classics, War, World War II"
        ],
        [
         "7",
         "7",
         "The Hobbit",
         "J.R.R. Tolkien",
         "4.28",
         "3729821",
         "Â 65,508",
         "In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort.Written for J.R.R. TolkienÃ¢ÂÂs own children, The Hobbit met with instant critical acclaim when it was first published in 1937. Now recognized as a timeless classic, this introduction to the hobbit Bilbo Baggins, the wizard Gandalf, Gollum, and the spectacular world of Middle-earth recounts of the adventures of a reluctant hero, a powerful and dangerous ring, and the cruel dragon Smaug the Magnificent. The text in this 372-page paperback edition is based on that first published in Great Britain by Collins Modern Classics (1998), and includes a note on the text by Douglas A. Anderson (2001).",
         "Fantasy, Classics, Fiction, Adventure, Young Adult, High Fantasy, Science Fiction Fantasy"
        ],
        [
         "8",
         "8",
         "Insurgent",
         "Veronica Roth",
         "3.98",
         "1435810",
         "Â 62,356",
         "One choice can transform youÃ¢ÂÂor it can destroy you. But every choice has consequences, and as unrest surges in the factions all around her, Tris Prior must continue trying to save those she lovesÃ¢ÂÂand herselfÃ¢ÂÂwhile grappling with haunting questions of grief and forgiveness, identity and loyalty, politics and love.Tris's initiation day should have been marked by celebration and victory with her chosen faction; instead, the day ended with unspeakable horrors. War now looms as conflict between the factions and their ideologies grows. And in times of war, sides must be chosen, secrets will emerge, and choices will become even more irrevocableÃ¢ÂÂand even more powerful. Transformed by her own decisions but also by haunting grief and guilt, radical new discoveries, and shifting relationships, Tris must fully embrace her Divergence, even if she does not know what she may lose by doing so.New York Times bestselling author Veronica Roth's much-anticipated second book of the dystopian DIVERGENT series is another intoxicating thrill ride of a story, rich with hallmark twists, heartbreaks, romance, and powerful insights about human nature.",
         "Young Adult, Dystopia, Fiction, Fantasy, Science Fiction, Romance, Adventure"
        ],
        [
         "9",
         "9",
         "Harry Potter and the Chamber of Secrets",
         "J.K. Rowling",
         "4.43",
         "3669432",
         "Â 73,212",
         "Ever since Harry Potter had come home for the summer, the Dursleys had been so mean and hideous that all Harry wanted was to get back to the Hogwarts School for Witchcraft and Wizardry. But just as heÃ¢ÂÂs packing his bags, Harry receives a warning from a strange impish creature who says that if Harry returns to Hogwarts, disaster will strike.And strike it does. For in HarryÃ¢ÂÂs second year at Hogwarts, fresh torments and horrors arise, including an outrageously stuck-up new professor and a spirit who haunts the girlsÃ¢ÂÂ bathroom. But then the real trouble begins Ã¢ÂÂ someone is turning Hogwarts students to stone. Could it be Draco Malfoy, a more poisonous rival than ever? Could it possibly be Hagrid, whose mysterious past is finally told? Or could it be the one everyone at Hogwarts most suspectsÃ¢ÂÂ¦ Harry Potter himself!",
         "Fantasy, Fiction, Young Adult, Magic, Childrens, Middle Grade, Audiobook"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>no_of_ratings</th>\n",
       "      <th>no_of_reviews</th>\n",
       "      <th>description</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Divergent</td>\n",
       "      <td>Veronica Roth</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3765886</td>\n",
       "      <td>Â 117,791</td>\n",
       "      <td>In Beatrice Prior's dystopian Chicago world, s...</td>\n",
       "      <td>Young Adult, Dystopia, Fantasy, Fiction, Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Catching Fire</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3305054</td>\n",
       "      <td>Â 113,480</td>\n",
       "      <td>Sparks are igniting.Flames are spreading.And t...</td>\n",
       "      <td>Young Adult, Dystopia, Fiction, Fantasy, Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Fault in Our Stars</td>\n",
       "      <td>John Green</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4851513</td>\n",
       "      <td>Â 174,662</td>\n",
       "      <td>Despite the tumor-shrinking medical miracle th...</td>\n",
       "      <td>Young Adult, Romance, Fiction, Contemporary, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.27</td>\n",
       "      <td>5784553</td>\n",
       "      <td>Â 112,055</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>Classics, Fiction, Historical Fiction, School,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The Lightning Thief</td>\n",
       "      <td>Rick Riordan</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2752945</td>\n",
       "      <td>Â 87,446</td>\n",
       "      <td>Alternate cover for this ISBN can be found her...</td>\n",
       "      <td>Fantasy, Young Adult, Mythology, Fiction, Midd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.58</td>\n",
       "      <td>3889833</td>\n",
       "      <td>Â 77,063</td>\n",
       "      <td>Harry Potter, along with his best friends, Ron...</td>\n",
       "      <td>Fantasy, Fiction, Young Adult, Magic, Children...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>The Book Thief</td>\n",
       "      <td>Markus Zusak</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2410045</td>\n",
       "      <td>Â 138,420</td>\n",
       "      <td>Librarian's note: An alternate cover edition c...</td>\n",
       "      <td>Historical Fiction, Fiction, Young Adult, Hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>The Hobbit</td>\n",
       "      <td>J.R.R. Tolkien</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3729821</td>\n",
       "      <td>Â 65,508</td>\n",
       "      <td>In a hole in the ground there lived a hobbit. ...</td>\n",
       "      <td>Fantasy, Classics, Fiction, Adventure, Young A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Insurgent</td>\n",
       "      <td>Veronica Roth</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1435810</td>\n",
       "      <td>Â 62,356</td>\n",
       "      <td>One choice can transform youÃ¢ÂÂor it can de...</td>\n",
       "      <td>Young Adult, Dystopia, Fiction, Fantasy, Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.43</td>\n",
       "      <td>3669432</td>\n",
       "      <td>Â 73,212</td>\n",
       "      <td>Ever since Harry Potter had come home for the ...</td>\n",
       "      <td>Fantasy, Fiction, Young Adult, Magic, Children...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     title           author  \\\n",
       "0           0                                 Divergent    Veronica Roth   \n",
       "1           1                             Catching Fire  Suzanne Collins   \n",
       "2           2                    The Fault in Our Stars       John Green   \n",
       "3           3                     To Kill a Mockingbird       Harper Lee   \n",
       "4           4                       The Lightning Thief     Rick Riordan   \n",
       "5           5  Harry Potter and the Prisoner of Azkaban     J.K. Rowling   \n",
       "6           6                            The Book Thief     Markus Zusak   \n",
       "7           7                                The Hobbit   J.R.R. Tolkien   \n",
       "8           8                                 Insurgent    Veronica Roth   \n",
       "9           9   Harry Potter and the Chamber of Secrets     J.K. Rowling   \n",
       "\n",
       "   rating  no_of_ratings no_of_reviews  \\\n",
       "0    4.15        3765886     Â 117,791   \n",
       "1    4.31        3305054     Â 113,480   \n",
       "2    4.15        4851513     Â 174,662   \n",
       "3    4.27        5784553     Â 112,055   \n",
       "4    4.30        2752945      Â 87,446   \n",
       "5    4.58        3889833      Â 77,063   \n",
       "6    4.39        2410045     Â 138,420   \n",
       "7    4.28        3729821      Â 65,508   \n",
       "8    3.98        1435810      Â 62,356   \n",
       "9    4.43        3669432      Â 73,212   \n",
       "\n",
       "                                         description  \\\n",
       "0  In Beatrice Prior's dystopian Chicago world, s...   \n",
       "1  Sparks are igniting.Flames are spreading.And t...   \n",
       "2  Despite the tumor-shrinking medical miracle th...   \n",
       "3  The unforgettable novel of a childhood in a sl...   \n",
       "4  Alternate cover for this ISBN can be found her...   \n",
       "5  Harry Potter, along with his best friends, Ron...   \n",
       "6  Librarian's note: An alternate cover edition c...   \n",
       "7  In a hole in the ground there lived a hobbit. ...   \n",
       "8  One choice can transform youÃ¢ÂÂor it can de...   \n",
       "9  Ever since Harry Potter had come home for the ...   \n",
       "\n",
       "                                              genres  \n",
       "0  Young Adult, Dystopia, Fantasy, Fiction, Scien...  \n",
       "1  Young Adult, Dystopia, Fiction, Fantasy, Scien...  \n",
       "2  Young Adult, Romance, Fiction, Contemporary, R...  \n",
       "3  Classics, Fiction, Historical Fiction, School,...  \n",
       "4  Fantasy, Young Adult, Mythology, Fiction, Midd...  \n",
       "5  Fantasy, Fiction, Young Adult, Magic, Children...  \n",
       "6  Historical Fiction, Fiction, Young Adult, Hist...  \n",
       "7  Fantasy, Classics, Fiction, Adventure, Young A...  \n",
       "8  Young Adult, Dystopia, Fiction, Fantasy, Scien...  \n",
       "9  Fantasy, Fiction, Young Adult, Magic, Children...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "file_path = os.path.abspath(os.path.join(current_dir, \"..\", \"datasets\", \"book_details_clean.csv\"))\n",
    "books_ratings_df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "books_ratings_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c51b1b-2f2a-4010-a63b-477f65a65568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Count: 163.31394560385746\n",
      "Average Character Count: 996.4563399382205\n",
      "Minimum Word Count: 1\n",
      "Maximum Word Count: 1467\n",
      "Minimum Character Count: 5\n",
      "Maximum Character Count: 18656\n",
      "\n",
      "Dataset: 13273 book descriptions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "file_path = os.path.abspath(os.path.join(current_dir, \"..\", \"datasets\", \"book_details_clean.csv\"))\n",
    "books_ratings_df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Calculate word count and character count for each description\n",
    "word_counts = books_ratings_df['description'].apply(lambda x: len(str(x).split()))\n",
    "char_counts = books_ratings_df['description'].apply(lambda x: len(str(x)))\n",
    "# Calculate average, min, and max for word count and character count\n",
    "avg_word_count = word_counts.mean()\n",
    "avg_char_count = char_counts.mean()\n",
    "\n",
    "min_word_count = word_counts.min()\n",
    "max_word_count = word_counts.max()\n",
    "\n",
    "min_char_count = char_counts.min()\n",
    "max_char_count = char_counts.max()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average Word Count: {avg_word_count}\")\n",
    "print(f\"Average Character Count: {avg_char_count}\")\n",
    "print(f\"Minimum Word Count: {min_word_count}\")\n",
    "print(f\"Maximum Word Count: {max_word_count}\")\n",
    "print(f\"Minimum Character Count: {min_char_count}\")\n",
    "print(f\"Maximum Character Count: {max_char_count}\")\n",
    "print(f\"\\nDataset: {len(books_ratings_df)} book descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57ad9c",
   "metadata": {},
   "source": [
    "### Ratings, Number of ratings, Number of reviews - GoodReads dataset\n",
    "- defining thresholds for popularity / novelty:\n",
    "  - Suggested Popularity Thresholds (Top 25%):\n",
    "  - Suggested Novelty Thresholds (Bottom 25%):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ae808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Summary:\n",
      "count   13,273.00000\n",
      "mean         4.03937\n",
      "std          0.32612\n",
      "min          0.00000\n",
      "25%          3.86000\n",
      "50%          4.04000\n",
      "75%          4.23000\n",
      "max          5.00000\n",
      "Name: rating, dtype: float64\n",
      "\n",
      "Number of Ratings Summary:\n",
      "count      13,273.00000\n",
      "mean       63,017.00505\n",
      "std       238,176.16809\n",
      "min             0.00000\n",
      "25%           829.00000\n",
      "50%        10,751.00000\n",
      "75%        43,042.00000\n",
      "max     8,104,716.00000\n",
      "Name: no_of_ratings, dtype: float64\n",
      "\n",
      "Number of Reviews Summary:\n",
      "count    13,273.00000\n",
      "mean      3,631.26708\n",
      "std      10,515.87531\n",
      "min           0.00000\n",
      "25%          87.00000\n",
      "50%         712.00000\n",
      "75%       2,756.00000\n",
      "max     227,613.00000\n",
      "Name: no_of_reviews, dtype: float64\n",
      "\n",
      "Suggested Popularity Thresholds (Top 25%):\n",
      " - No. of Ratings > 43042\n",
      " - No. of Reviews > 2756\n",
      " - Rating > 4.04 (Above Mean)\n",
      "\n",
      "Suggested Novelty Thresholds (Bottom 25%):\n",
      " - No. of Ratings < 829\n",
      " - No. of Reviews < 87\n",
      " - Rating < 3.86 (Bottom Quartile)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# === Load and Clean Data ===\n",
    "current_dir = os.getcwd()\n",
    "file_path = os.path.abspath(os.path.join(current_dir, \"..\", \"datasets\", \"book_details_clean.csv\"))\n",
    "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Clean 'no_of_ratings' and 'no_of_reviews'\n",
    "df['no_of_ratings'] = df['no_of_ratings'].astype(str).str.replace(r'[^\\d]', '', regex=True).astype(int)\n",
    "df['no_of_reviews'] = df['no_of_reviews'].astype(str).str.replace(r'[^\\d]', '', regex=True).astype(int)\n",
    "\n",
    "# === Summary Statistics ===\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "\n",
    "print(\"Ratings Summary:\")\n",
    "print(df['rating'].describe())\n",
    "\n",
    "print(\"\\nNumber of Ratings Summary:\")\n",
    "print(df['no_of_ratings'].describe())\n",
    "\n",
    "print(\"\\nNumber of Reviews Summary:\")\n",
    "print(df['no_of_reviews'].describe())\n",
    "\n",
    "# === Threshold Suggestions ===\n",
    "\n",
    "# Popularity (Top 25%)\n",
    "pop_ratings_threshold = np.percentile(df['no_of_ratings'], 75)\n",
    "pop_reviews_threshold = np.percentile(df['no_of_reviews'], 75)\n",
    "pop_rating_score_threshold = df['rating'].mean()  # or median\n",
    "\n",
    "# Novelty (Bottom 25%)\n",
    "novel_ratings_threshold = np.percentile(df['no_of_ratings'], 25)\n",
    "novel_reviews_threshold = np.percentile(df['no_of_reviews'], 25)\n",
    "novel_rating_score_threshold = np.percentile(df['rating'], 25)\n",
    "\n",
    "# === Print Thresholds ===\n",
    "\n",
    "print(\"\\nSuggested Popularity Thresholds (Top 25%):\")\n",
    "print(f\" - No. of Ratings > {pop_ratings_threshold:.0f}\")\n",
    "print(f\" - No. of Reviews > {pop_reviews_threshold:.0f}\")\n",
    "print(f\" - Rating > {pop_rating_score_threshold:.2f} (Above Mean)\")\n",
    "\n",
    "print(\"\\nSuggested Novelty Thresholds (Bottom 25%):\")\n",
    "print(f\" - No. of Ratings < {novel_ratings_threshold:.0f}\")\n",
    "print(f\" - No. of Reviews < {novel_reviews_threshold:.0f}\")\n",
    "print(f\" - Rating < {novel_rating_score_threshold:.2f} (Bottom Quartile)\")\n",
    "\n",
    "# === Visualize Distributions ===\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Ratings\n",
    "axs[0].hist(df['rating'], bins=30, color='skyblue')\n",
    "axs[0].axvline(novel_rating_score_threshold, color='red', linestyle='--', label='Novelty (25%)')\n",
    "axs[0].axvline(pop_rating_score_threshold, color='green', linestyle='--', label='Popularity (mean)')\n",
    "axs[0].set_title(\"Distribution of Ratings\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Number of Ratings\n",
    "axs[1].hist(np.log1p(df['no_of_ratings']), bins=30, color='orange')\n",
    "axs[1].axvline(np.log1p(novel_ratings_threshold), color='red', linestyle='--', label='Novelty (25%)')\n",
    "axs[1].axvline(np.log1p(pop_ratings_threshold), color='green', linestyle='--', label='Popularity (75%)')\n",
    "axs[1].set_title(\"Log-Scaled Number of Ratings\")\n",
    "axs[1].legend()\n",
    "\n",
    "# Number of Reviews\n",
    "axs[2].hist(np.log1p(df['no_of_reviews']), bins=30, color='cyan')\n",
    "axs[2].axvline(np.log1p(novel_reviews_threshold), color='red', linestyle='--', label='Novelty (25%)')\n",
    "axs[2].axvline(np.log1p(pop_reviews_threshold), color='green', linestyle='--', label='Popularity (75%)')\n",
    "axs[2].set_title(\"Log-Scaled Number of Reviews\")\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fddbf3",
   "metadata": {},
   "source": [
    "### Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aaf6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiction                 7212\n",
      "Romance                 4326\n",
      "Fantasy                 3365\n",
      "Contemporary            2835\n",
      "Young Adult             2588\n",
      "Nonfiction              2208\n",
      "Mystery                 2186\n",
      "Historical Fiction      1821\n",
      "Audiobook               1782\n",
      "Classics                1565\n",
      "Thriller                1417\n",
      "Adult                   1413\n",
      "Paranormal              1385\n",
      "Contemporary Romance    1353\n",
      "Historical              1348\n",
      "Science Fiction         1048\n",
      "Crime                   1047\n",
      "Mystery Thriller        1032\n",
      "Biography                934\n",
      "Suspense                 904\n",
      "Name: count, dtype: int64\n",
      "Diff ROWS: 10921\n",
      "Diff GENRES: 648\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "file_path = os.path.abspath(os.path.join(current_dir, \"..\", \"datasets\", \"book_details_clean.csv\"))\n",
    "books_ratings_df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Step 1: Convert the \"genres\" column to a list of all genres\n",
    "all_genres = books_ratings_df['genres'].dropna().str.split(', ')\n",
    "\n",
    "# Step 2: Flatten the list of lists into a single list\n",
    "flattened_genres = [genre.strip() for sublist in all_genres for genre in sublist]\n",
    "\n",
    "# Step 3: Use pandas to count each genre\n",
    "import pandas as pd\n",
    "genre_counts = pd.Series(flattened_genres).value_counts()\n",
    "\n",
    "# Step 4: Display the top genres\n",
    "print(genre_counts.head(20))  \n",
    "print(f\"Diff ROWS: {len(books_ratings_df['genres'].unique())}\")\n",
    "print(f\"Diff GENRES: {len(genre_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e42e7e",
   "metadata": {},
   "source": [
    "# Recommendation pipeline Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e917a493-a5f9-4961-954b-899248045b84",
   "metadata": {},
   "source": [
    "## Content Based Algorithms - Implementation to recommend paragraphs and book descriptions\n",
    "\n",
    "Feature Extraction Methods:  \n",
    "1. TF-IDF  \n",
    "2. LSA  \n",
    "3. Bow  \n",
    "4. FastText   \n",
    "5. GloVe  \n",
    "6. Sentence-BERT   \n",
    "\n",
    "Similarity calculation metric:\n",
    "- Cosine Similarity\n",
    "\n",
    "-> choose 1 book description/paragraph  \n",
    "-> run the algorithms for finding the recommended book description/paragraph for that chosen one - based on:  \n",
    "- summary  \n",
    "- paragraph  \n",
    "- book description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb90e8c",
   "metadata": {},
   "source": [
    "## 1. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07752c0b",
   "metadata": {},
   "source": [
    "### RUN - TRACK PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import multiprocessing\n",
    "\n",
    "# SETTINGS\n",
    "input_book_index = 0  # Book index for paragraph testing\n",
    "input_paragraph_index = 7  # Paragraph index for paragraph testing\n",
    "\n",
    "top_n = 5\n",
    "exclude_input_book = True\n",
    "threshold = 0.5\n",
    "max_runtime = 3600  # Maximum runtime in seconds (1 hour)\n",
    "\n",
    "# Load TF-IDF Model\n",
    "tfidf_vectorizer = joblib.load(\"saved_models/tfidf.pkl\")\n",
    "\n",
    "print(\"TF-IDF model loaded\")\n",
    "\n",
    "def tfidf_recommendations(data, book_index, paragraph_index, tfidf_vectorizer, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    process = psutil.Process()\n",
    "    cpu_start = psutil.cpu_percent(interval=None)\n",
    "    start_time = time.time()\n",
    "\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return {}, [], {}\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    input_book_index = input_para.iloc[0][\"book_index\"]\n",
    "    input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "    \n",
    "    input_data = {\n",
    "        \"book_index\": input_book_index,\n",
    "        \"paragraph_index\": paragraph_index,\n",
    "        \"book_title\": input_book_title,\n",
    "        \"text\": input_text\n",
    "    }\n",
    "    \n",
    "    filtered_data = data if not exclude_input_book else data[data[\"book_index\"] != book_index]\n",
    "    filtered_data = filtered_data.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "    \n",
    "    tfidf_matrix = tfidf_vectorizer.transform(filtered_data['text'])\n",
    "    target_vector = tfidf_vectorizer.transform([input_text])\n",
    "    cosine_sim = cosine_similarity(target_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    start_iteration_time = time.time()\n",
    "    iterations_done = 0\n",
    "    with tqdm(total=len(cosine_sim), desc=f\"Computing Similarities (TF-IDF)\", unit=\"iteration\") as pbar:\n",
    "        max_similarity_score = max(cosine_sim) if len(cosine_sim) > 0 else 0\n",
    "        threshold_value = threshold * max_similarity_score\n",
    "        filtered_scores = []\n",
    "        \n",
    "        for idx, score in enumerate(cosine_sim):\n",
    "            if score >= threshold_value and score < 1.0:\n",
    "                filtered_scores.append((idx, score))\n",
    "            pbar.update(1)  # Update tqdm for each iteration\n",
    "            iterations_done += 1\n",
    "            \n",
    "            if time.time() - start_time > max_runtime:\n",
    "                print(\"TF-IDF exceeded max runtime and was stopped.\")\n",
    "                elapsed_time = time.time() - start_time\n",
    "                cpu_end = psutil.cpu_percent(interval=None)\n",
    "                cpu_usage = cpu_end - cpu_start\n",
    "                memory_usage = process.memory_info().rss / (1024 * 1024)\n",
    "                \n",
    "                ips = iterations_done / elapsed_time if elapsed_time > 0 else 0\n",
    "                remaining_iterations = len(cosine_sim) - iterations_done\n",
    "                estimated_remaining_time = remaining_iterations / ips if ips > 0 else 0\n",
    "                estimated_total_time = elapsed_time + estimated_remaining_time\n",
    "                \n",
    "                performance_data = {\n",
    "                    \"algorithm\": \"TF-IDF\",\n",
    "                    \"elapsed_time\": elapsed_time,\n",
    "                    \"memory_usage\": memory_usage,\n",
    "                    \"cpu_usage\": cpu_usage,\n",
    "                    \"iterations_done\": iterations_done,\n",
    "                    \"total_iterations\": len(cosine_sim),\n",
    "                    \"iterations_per_second\": ips,\n",
    "                    \"estimated_remaining_time\": estimated_remaining_time,\n",
    "                    \"estimated_total_time\": estimated_total_time\n",
    "                }\n",
    "                return performance_data, input_data, []\n",
    "    \n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    recommendations = [(filtered_data.iloc[idx][\"book_index\"],\n",
    "                        filtered_data.iloc[idx][\"paragraph_index\"],\n",
    "                        round(score, 3),\n",
    "                        filtered_data.iloc[idx][\"book_title\"],\n",
    "                        filtered_data.iloc[idx][\"text\"])\n",
    "                        for idx, score in filtered_scores]\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    cpu_end = psutil.cpu_percent(interval=None)\n",
    "    cpu_usage = cpu_end - cpu_start\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)\n",
    "    \n",
    "    ips = iterations_done / elapsed_time if elapsed_time > 0 else 0\n",
    "    \n",
    "    performance_data = {\n",
    "        \"algorithm\": \"TF-IDF\",\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"memory_usage\": memory_usage,\n",
    "        \"cpu_usage\": cpu_usage,\n",
    "        \"iterations_done\": iterations_done,\n",
    "        \"total_iterations\": len(cosine_sim),\n",
    "        \"iterations_per_second\": ips\n",
    "    }\n",
    "    \n",
    "    return performance_data, input_data, recommendations\n",
    "\n",
    "# Run TF-IDF Recommendation with Progress Bar\n",
    "data = df_paragraphs\n",
    "algo_name = \"TF-IDF\"\n",
    "\n",
    "performance_data, input_data, recommendations = tfidf_recommendations(data, input_book_index, input_paragraph_index, tfidf_vectorizer, top_n=top_n, threshold=threshold, exclude_input_book=exclude_input_book)\n",
    "\n",
    "# Create DataFrame for performance results\n",
    "performance_df = pd.DataFrame([performance_data])\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "if recommendations:\n",
    "    recommendations_list = [\n",
    "        {\"book_index\": book_idx,\n",
    "         \"paragraph_index\": para_idx,\n",
    "         \"similarity_score\": similarity,\n",
    "         \"recommended_book\": rec_title,\n",
    "         \"recommended_text\": text}\n",
    "        for book_idx, para_idx, similarity, rec_title, text in recommendations\n",
    "    ]\n",
    "    recommendations_df = pd.DataFrame(recommendations_list)\n",
    "    final_df = pd.concat([performance_df, input_df, recommendations_df], ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.concat([performance_df, input_df], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(f\"results/{algo_name.lower()}_performance_results.csv\", index=False)\n",
    "\n",
    "# Display Performance Data\n",
    "print(f\"{algo_name} testing complete! Results saved.\")\n",
    "print(f\"Elapsed Time: {performance_data['elapsed_time']:.2f} sec, Memory Usage: {performance_data['memory_usage']:.2f} MB, CPU Usage: {performance_data['cpu_usage']:.2f}%, IPS: {performance_data['iterations_per_second']:.2f}\")\n",
    "if \"estimated_total_time\" in performance_data:\n",
    "    print(f\"Estimated Remaining Time: {performance_data['estimated_remaining_time']:.2f} sec, Estimated Total Time: {performance_data['estimated_total_time']:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396e650",
   "metadata": {},
   "source": [
    "### for summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def tfidf_summary(data, book_title, top_n, similarity, threshold=0.5, return_all=False):\n",
    "    tfidf = TfidfVectorizer(stop_words='english', max_features=10000)   # Compute TF-IDF matrix\n",
    "    tfidf_matrix = tfidf.fit_transform(data['combined']).toarray()      # Convert sparse matrix to dense\n",
    "    \n",
    "    # Get the index of the book that matches the title\n",
    "    idx = data.index[data[\"book_title\"] == book_title].tolist()[0]\n",
    "    \n",
    "    # COSINE \n",
    "    if similarity == \"cosine\":  \n",
    "        cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        \n",
    "        filtered_scores = [(i, score) for i, score in sim_scores if i != idx]\n",
    "        max_similarity_score = max(score for _, score in filtered_scores)\n",
    "        \n",
    "        th = threshold * max_similarity_score\n",
    "        filtered_scores = [(i, score) for i, score in filtered_scores if score >= th]\n",
    "\n",
    "        # Sort the remaining items based on similarity scores (descending)\n",
    "        filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if not return_all:\n",
    "            filtered_scores = filtered_scores[:top_n]\n",
    "\n",
    "\n",
    "        recommendations = [(i, data[\"book_title\"].iloc[i], round(score, 3)) for i, score in filtered_scores]\n",
    "\n",
    "    return recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ec3fe",
   "metadata": {},
   "source": [
    "### for paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b42472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# TF-IDF Recommendation\n",
    "def tfidf_recommendations(data, book_index, paragraph_index, tfidf_vectorizer, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    # Extract the input paragraph\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "\n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return []\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    # input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "\n",
    "    # Filter dataset based on `exclude_input_book`\n",
    "    filtered_data = data if not exclude_input_book else data[data[\"book_index\"] != book_index]\n",
    "\n",
    "    # Remove duplicates\n",
    "    filtered_data = filtered_data.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "    # Compute TF-IDF matrix\n",
    "    tfidf_matrix = tfidf_vectorizer.transform(filtered_data['text'])  # Transform all paragraphs\n",
    "\n",
    "    # Vectorize the input paragraph\n",
    "    target_vector = tfidf_vectorizer.transform([input_text])\n",
    "\n",
    "    # Compute Cosine Similarity\n",
    "    cosine_sim = cosine_similarity(target_vector, tfidf_matrix).flatten()\n",
    "\n",
    "\n",
    "    # Apply threshold\n",
    "    sim_scores = list(enumerate(cosine_sim))\n",
    "    max_similarity_score = max(cosine_sim) if len(sim_scores) > 0 else 0\n",
    "    threshold_value = threshold * max_similarity_score\n",
    "\n",
    "    # Filter, sort, and get top N recommendations\n",
    "    filtered_scores = [(idx, score) for idx, score in sim_scores if score >= threshold_value and score < 1.0]  # Exclude exact matches\n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Return structured recommendations\n",
    "    recommendations = [(filtered_data.iloc[idx][\"book_index\"],\n",
    "                        filtered_data.iloc[idx][\"paragraph_index\"],\n",
    "                        filtered_data.iloc[idx][\"text\"],\n",
    "                        filtered_data.iloc[idx][\"book_title\"],\n",
    "                        round(score, 3))\n",
    "                        for idx, score in filtered_scores]\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ba40d-8be1-4c0d-acab-5c579b0ea9a3",
   "metadata": {},
   "source": [
    "## 2. LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5298c06f",
   "metadata": {},
   "source": [
    "### RUN - TRACK PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b3410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Similarities (LSA): 100%|██████████| 181559/181559 [00:00<00:00, 1483399.74iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LSA testing complete! Results saved.\n",
      "Elapsed Time: 19.11 sec, Memory Usage: 2397.43 MB, CPU Usage: 6.80%, IPS: 9499.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# SETTINGS\n",
    "input_book_index = 0  # Book index for paragraph testing\n",
    "input_paragraph_index = 7  # Paragraph index for paragraph testing\n",
    "\n",
    "top_n = 5\n",
    "exclude_input_book = True\n",
    "threshold = 0.5\n",
    "max_runtime = 3600  # Maximum runtime in seconds (1 hour)\n",
    "\n",
    "# Load LSA Model\n",
    "tfidf_vectorizer, lsa_model, lsa_matrix = joblib.load(\"saved_models/lsa.pkl\")\n",
    "\n",
    "print(\"LSA model loaded\")\n",
    "\n",
    "def lsa_recommendations(data, book_index, paragraph_index, tfidf_vectorizer, lsa_model, lsa_matrix, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    process = psutil.Process()\n",
    "    cpu_start = psutil.cpu_percent(interval=None)\n",
    "    start_time = time.time()\n",
    "\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return {}, [], {}\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    input_book_index = input_para.iloc[0][\"book_index\"]\n",
    "    input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "    \n",
    "    input_data = {\n",
    "        \"book_index\": input_book_index,\n",
    "        \"paragraph_index\": paragraph_index,\n",
    "        \"book_title\": input_book_title,\n",
    "        \"text\": input_text\n",
    "    }\n",
    "    \n",
    "    filtered_data = data if not exclude_input_book else data[data[\"book_index\"] != book_index]\n",
    "    filtered_data = filtered_data.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "    \n",
    "    input_vector = lsa_model.transform(tfidf_vectorizer.transform([input_text]))\n",
    "    \n",
    "    tfidf_matrix_filtered = tfidf_vectorizer.transform(filtered_data[\"text\"])\n",
    "    lsa_matrix_filtered = lsa_model.transform(tfidf_matrix_filtered)\n",
    "\n",
    "    cosine_sim = cosine_similarity(input_vector, lsa_matrix_filtered)[0]\n",
    "\n",
    "    # Progress bar for similarity computation\n",
    "    start_iteration_time = time.time()\n",
    "    iterations_done = 0\n",
    "    with tqdm(total=len(cosine_sim), desc=f\"Computing Similarities (LSA)\", unit=\"iteration\") as pbar:\n",
    "        max_similarity_score = max(cosine_sim) if len(cosine_sim) > 0 else 0\n",
    "        threshold_value = threshold * max_similarity_score\n",
    "        filtered_scores = []\n",
    "        \n",
    "        for idx, score in enumerate(cosine_sim):\n",
    "            if score >= threshold_value and score < 1.0:\n",
    "                filtered_scores.append((idx, score))\n",
    "            pbar.update(1)  # Update tqdm for each iteration\n",
    "            iterations_done += 1\n",
    "            \n",
    "            # Stop execution if runtime exceeds max_runtime\n",
    "            if time.time() - start_time > max_runtime:\n",
    "                print(\"LSA exceeded max runtime and was stopped.\")\n",
    "                elapsed_time = time.time() - start_time\n",
    "                cpu_end = psutil.cpu_percent(interval=None)\n",
    "                cpu_usage = cpu_end - cpu_start\n",
    "                memory_usage = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "                \n",
    "                ips = iterations_done / elapsed_time if elapsed_time > 0 else 0\n",
    "                remaining_iterations = len(cosine_sim) - iterations_done\n",
    "                estimated_remaining_time = remaining_iterations / ips if ips > 0 else 0\n",
    "                estimated_total_time = elapsed_time + estimated_remaining_time\n",
    "                \n",
    "                performance_data = {\n",
    "                    \"algorithm\": \"LSA\",\n",
    "                    \"elapsed_time\": elapsed_time,\n",
    "                    \"memory_usage\": memory_usage,\n",
    "                    \"cpu_usage\": cpu_usage,\n",
    "                    \"iterations_done\": iterations_done,\n",
    "                    \"total_iterations\": len(cosine_sim),\n",
    "                    \"iterations_per_second\": ips,\n",
    "                    \"estimated_remaining_time\": estimated_remaining_time,\n",
    "                    \"estimated_total_time\": estimated_total_time\n",
    "                }\n",
    "                return performance_data, input_data, []\n",
    "    \n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    recommendations = [(filtered_data.iloc[idx][\"book_index\"],\n",
    "                        filtered_data.iloc[idx][\"paragraph_index\"],\n",
    "                        round(score, 3),\n",
    "                        filtered_data.iloc[idx][\"book_title\"],\n",
    "                        filtered_data.iloc[idx][\"text\"])\n",
    "                        for idx, score in filtered_scores]\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    cpu_end = psutil.cpu_percent(interval=None)\n",
    "    cpu_usage = cpu_end - cpu_start\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "    \n",
    "    ips = iterations_done / elapsed_time if elapsed_time > 0 else 0\n",
    "    \n",
    "    performance_data = {\n",
    "        \"algorithm\": \"LSA\",\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"memory_usage\": memory_usage,\n",
    "        \"cpu_usage\": cpu_usage,\n",
    "        \"iterations_done\": iterations_done,\n",
    "        \"total_iterations\": len(cosine_sim),\n",
    "        \"iterations_per_second\": ips\n",
    "    }\n",
    "    \n",
    "    return performance_data, input_data, recommendations\n",
    "\n",
    "# Run LSA Recommendation with Progress Bar\n",
    "data = df_paragraphs\n",
    "algo_name = \"LSA\"\n",
    "\n",
    "performance_data, input_data, recommendations = lsa_recommendations(data, input_book_index, input_paragraph_index, tfidf_vectorizer, lsa_model, lsa_matrix, top_n=top_n, threshold=threshold, exclude_input_book=exclude_input_book)\n",
    "\n",
    "# Create DataFrame for performance results\n",
    "performance_df = pd.DataFrame([performance_data])\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "if recommendations:\n",
    "    recommendations_list = [\n",
    "        {\"book_index\": book_idx,\n",
    "         \"paragraph_index\": para_idx,\n",
    "         \"similarity_score\": similarity,\n",
    "         \"recommended_book\": rec_title,\n",
    "         \"recommended_text\": text}\n",
    "        for book_idx, para_idx, similarity, rec_title, text in recommendations\n",
    "    ]\n",
    "    recommendations_df = pd.DataFrame(recommendations_list)\n",
    "    final_df = pd.concat([performance_df, input_df, recommendations_df], ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.concat([performance_df, input_df], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(f\"results/{algo_name.lower()}_performance_results.csv\", index=False)\n",
    "\n",
    "# Display Performance Data\n",
    "print(f\"{algo_name} testing complete! Results saved.\")\n",
    "print(f\"Elapsed Time: {performance_data['elapsed_time']:.2f} sec, Memory Usage: {performance_data['memory_usage']:.2f} MB, CPU Usage: {performance_data['cpu_usage']:.2f}%, IPS: {performance_data['iterations_per_second']:.2f}\")\n",
    "if \"estimated_total_time\" in performance_data:\n",
    "    print(f\"Estimated Remaining Time: {performance_data['estimated_remaining_time']:.2f} sec, Estimated Total Time: {performance_data['estimated_total_time']:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6bfeb",
   "metadata": {},
   "source": [
    "### for summary - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e654681-2078-46b1-9a06-7b586d0bd509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def lsa_summary(data, title, top_n, threshold=0.5, return_all=False):\n",
    "    # Preprocess the text with TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(data['combined'])\n",
    "\n",
    "    # Apply LSA (Latent Semantic Analysis)\n",
    "    lsa = TruncatedSVD(n_components=100, random_state=42)  # Use 100 components for more nuanced analysis\n",
    "    lsa_matrix = lsa.fit_transform(tfidf_matrix)\n",
    "\n",
    "    # Compute cosine similarity matrix on the LSA-reduced features\n",
    "    lsa_cosine_sim = cosine_similarity(lsa_matrix)\n",
    "\n",
    "    idx = data.index[data[\"book_title\"] == title].tolist()[0]\n",
    "    sim_scores = list(enumerate(lsa_cosine_sim[idx]))\n",
    "    \n",
    "    # Remove the book itself and calculate max similarity\n",
    "    filtered_scores = [(i, score) for i, score in sim_scores if i != idx]\n",
    "    max_similarity_score = max(score for _, score in filtered_scores)\n",
    "\n",
    "    # Apply dynamic threshold\n",
    "    th = threshold * max_similarity_score\n",
    "    filtered_scores = [(i, score) for i, score in filtered_scores if score >= th]\n",
    "\n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if not return_all:\n",
    "        filtered_scores = filtered_scores[:top_n]\n",
    "\n",
    "    # recommendations = [(i[0], data[\"book_title\"].iloc[i[0]]) for i in sim_scores]\n",
    "    recommendations = [(i, data[\"book_title\"].iloc[i], round(score, 3)) for i, score in filtered_scores]\n",
    "    return recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d4a60",
   "metadata": {},
   "source": [
    "### for paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f873be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Train LSA Model\n",
    "def train_lsa(data, n_components=100):\n",
    "    # - data: DataFrame containing the text data.\n",
    "    # - n_components: Number of dimensions for SVD (default=100).\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(data['text'])\n",
    "\n",
    "    lsa_model = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    lsa_matrix = lsa_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "    return tfidf_vectorizer, lsa_model, lsa_matrix\n",
    "\n",
    "# LSA Recommendation Function (Fixed)\n",
    "def lsa_recommendations(data, book_index, paragraph_index, tfidf_vectorizer, lsa_model, lsa_matrix, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    # Extract the input paragraph\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "\n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return []\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "\n",
    "    # Compute LSA representation for the input paragraph\n",
    "    input_vector = lsa_model.transform(tfidf_vectorizer.transform([input_text]))\n",
    "\n",
    "    # Filter dataset if `exclude_input_book=True`\n",
    "    if exclude_input_book:\n",
    "        filtered_data = data[data[\"book_index\"] != book_index].reset_index(drop=True)\n",
    "    else:\n",
    "        filtered_data = data.copy().reset_index(drop=True)\n",
    "\n",
    "    # Align `lsa_matrix` with `filtered_data`\n",
    "    tfidf_matrix_filtered = tfidf_vectorizer.transform(filtered_data[\"text\"])\n",
    "    lsa_matrix_filtered = lsa_model.transform(tfidf_matrix_filtered)\n",
    "\n",
    "    # Compute cosine similarity with **filtered** LSA matrix\n",
    "    cosine_sim = cosine_similarity(input_vector, lsa_matrix_filtered)[0]\n",
    "\n",
    "    # Get valid indices from filtered data\n",
    "    valid_indices = filtered_data.index.tolist()\n",
    "\n",
    "    # Ensure index lengths match\n",
    "    if len(cosine_sim) != len(valid_indices):\n",
    "        print(f\"Mismatch detected: cosine_sim={len(cosine_sim)}, valid_indices={len(valid_indices)}\")\n",
    "        return []\n",
    "\n",
    "    # Apply threshold\n",
    "    sim_scores = [(valid_indices[idx], score) for idx, score in enumerate(cosine_sim) if score < 1.0]  # Exclude exact matches\n",
    "\n",
    "    if not sim_scores:\n",
    "        print(\"No valid recommendations found.\")\n",
    "        return []\n",
    "\n",
    "    max_similarity_score = max(score for _, score in sim_scores)\n",
    "    threshold_value = threshold * max_similarity_score\n",
    "\n",
    "    # Filter, sort, and get top N recommendations\n",
    "    filtered_scores = [(idx, score) for idx, score in sim_scores if score >= threshold_value]\n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Return structured recommendations\n",
    "    recommendations = [(filtered_data.loc[idx, \"book_index\"],\n",
    "                        filtered_data.loc[idx, \"paragraph_index\"],\n",
    "                        filtered_data.loc[idx, \"text\"],\n",
    "                        filtered_data.loc[idx, \"book_title\"],\n",
    "                        round(score, 3))\n",
    "                        for idx, score in filtered_scores]\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a47790-a9e5-4aa4-b8c8-3441bd400828",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1229b29",
   "metadata": {},
   "source": [
    "### RUN - TRACK PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f938d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# SETTINGS\n",
    "input_book_index = 0  # Book index for paragraph testing\n",
    "input_paragraph_index = 7  # Paragraph index for paragraph testing\n",
    "\n",
    "top_n = 5\n",
    "exclude_input_book = True\n",
    "threshold = 0.5\n",
    "max_runtime = 3600  # Maximum runtime in seconds (1 hour)\n",
    "\n",
    "# Load BoW Model\n",
    "bow_vectorizer, bow_matrix = joblib.load(\"saved_models/bow.pkl\")\n",
    "\n",
    "print(\"BoW model loaded\")\n",
    "\n",
    "def bow_recommendations(data, book_index, paragraph_index, bow_vectorizer, bow_matrix, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    process = psutil.Process()\n",
    "    cpu_start = psutil.cpu_percent(interval=0.1)\n",
    "    start_time = time.time()\n",
    "\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return {}, [], {}\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    input_book_index = input_para.iloc[0][\"book_index\"]\n",
    "    input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "    \n",
    "    input_data = {\n",
    "        \"book_index\": input_book_index,\n",
    "        \"paragraph_index\": paragraph_index,\n",
    "        \"book_title\": input_book_title,\n",
    "        \"text\": input_text\n",
    "    }\n",
    "    \n",
    "    filtered_data = data if not exclude_input_book else data[data[\"book_index\"] != book_index]\n",
    "    filtered_data = filtered_data.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "    \n",
    "    input_vector = bow_vectorizer.transform([input_text])\n",
    "    cosine_sim = cosine_similarity(input_vector, bow_matrix).flatten()\n",
    "    \n",
    "    with tqdm(total=len(filtered_data), desc=f\"Computing Similarities (BoW)\", unit=\"iteration\") as pbar:\n",
    "        filtered_scores = [(i, score) for i, score in enumerate(cosine_sim) if score < 1.0]\n",
    "        max_similarity_score = max(score for _, score in filtered_scores) if filtered_scores else 0\n",
    "        threshold_value = threshold * max_similarity_score\n",
    "        \n",
    "        filtered_scores = [(idx, score) for idx, score in filtered_scores if score >= threshold_value]\n",
    "        filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        pbar.update(len(filtered_scores))\n",
    "        \n",
    "        if time.time() - start_time > max_runtime:\n",
    "            print(\"BoW exceeded max runtime and was stopped.\")\n",
    "            elapsed_time = time.time() - start_time\n",
    "            cpu_end = psutil.cpu_percent(interval=0.1)\n",
    "            cpu_usage = cpu_end - cpu_start\n",
    "            memory_usage = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "            \n",
    "            ips = len(filtered_scores) / elapsed_time if elapsed_time > 0 else 0\n",
    "            remaining_iterations = len(filtered_data) - len(filtered_scores)\n",
    "            estimated_remaining_time = remaining_iterations / ips if ips > 0 else 0\n",
    "            estimated_total_time = elapsed_time + estimated_remaining_time\n",
    "            \n",
    "            performance_data = {\n",
    "                \"algorithm\": \"BoW\",\n",
    "                \"elapsed_time\": elapsed_time,\n",
    "                \"memory_usage\": memory_usage,\n",
    "                \"cpu_usage\": cpu_usage,\n",
    "                \"iterations_done\": len(filtered_scores),\n",
    "                \"total_iterations\": len(filtered_data),\n",
    "                \"iterations_per_second\": ips,\n",
    "                \"estimated_remaining_time\": estimated_remaining_time,\n",
    "                \"estimated_total_time\": estimated_total_time\n",
    "            }\n",
    "            return performance_data, input_data, []\n",
    "    \n",
    "    recommendations = [(filtered_data.iloc[idx][\"book_index\"],\n",
    "                        filtered_data.iloc[idx][\"paragraph_index\"],\n",
    "                        round(score, 3),\n",
    "                        filtered_data.iloc[idx][\"book_title\"],\n",
    "                        filtered_data.iloc[idx][\"text\"])\n",
    "                        for idx, score in filtered_scores]\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    cpu_end = psutil.cpu_percent(interval=0.1)\n",
    "    cpu_usage = cpu_end - cpu_start\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "    \n",
    "    ips = len(filtered_scores) / elapsed_time if elapsed_time > 0 else 0\n",
    "    \n",
    "    performance_data = {\n",
    "        \"algorithm\": \"BoW\",\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"memory_usage\": memory_usage,\n",
    "        \"cpu_usage\": cpu_usage,\n",
    "        \"iterations_done\": len(filtered_scores),\n",
    "        \"total_iterations\": len(filtered_data),\n",
    "        \"iterations_per_second\": ips\n",
    "    }\n",
    "    \n",
    "    return performance_data, input_data, recommendations\n",
    "\n",
    "# Run BoW Recommendation with Progress Bar\n",
    "data = df_paragraphs\n",
    "algo_name = \"BoW\"\n",
    "\n",
    "performance_data, input_data, recommendations = bow_recommendations(data, input_book_index, input_paragraph_index, bow_vectorizer, bow_matrix, top_n=top_n, threshold=threshold, exclude_input_book=exclude_input_book)\n",
    "\n",
    "# Create DataFrame for performance results\n",
    "performance_df = pd.DataFrame([performance_data])\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "if recommendations:\n",
    "    recommendations_list = [\n",
    "        {\"book_index\": book_idx,\n",
    "         \"paragraph_index\": para_idx,\n",
    "         \"similarity_score\": similarity,\n",
    "         \"recommended_book\": rec_title,\n",
    "         \"recommended_text\": text}\n",
    "        for book_idx, para_idx, similarity, rec_title, text in recommendations\n",
    "    ]\n",
    "    recommendations_df = pd.DataFrame(recommendations_list)\n",
    "    final_df = pd.concat([performance_df, input_df, recommendations_df], ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.concat([performance_df, input_df], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(f\"results/{algo_name.lower()}_performance_results.csv\", index=False)\n",
    "\n",
    "# Display Performance Data\n",
    "print(f\"{algo_name} testing complete! Results saved.\")\n",
    "print(f\"Elapsed Time: {performance_data['elapsed_time']:.2f} sec, Memory Usage: {performance_data['memory_usage']:.2f} MB, CPU Usage: {performance_data['cpu_usage']:.2f}%, IPS: {performance_data['iterations_per_second']:.2f}\")\n",
    "if \"estimated_total_time\" in performance_data:\n",
    "    print(f\"Estimated Remaining Time: {performance_data['estimated_remaining_time']:.2f} sec, Estimated Total Time: {performance_data['estimated_total_time']:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3705b2a9",
   "metadata": {},
   "source": [
    "### for summary - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf47de7-a358-44cd-87c8-51ec8e48d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def bow_summary(data, book_title, top_n, threshold=0.5, return_all=False):\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    bow_matrix = count_vectorizer.fit_transform(data['combined'])\n",
    "    \n",
    "    cosine_sim = cosine_similarity(bow_matrix, bow_matrix)\n",
    "    \n",
    "    idx = data[data[\"book_title\"] == book_title].index[0]\n",
    "    \n",
    "    scores = list(enumerate(cosine_sim[idx]))\n",
    "    filtered_scores = [(i, score) for i, score in scores if i != idx]  \n",
    "    \n",
    "    # Find the maximum similarity score\n",
    "    max_similarity_score = max(score for _, score in filtered_scores)\n",
    "    \n",
    "    # Apply dynamic threshold\n",
    "    dynamic_threshold = threshold * max_similarity_score\n",
    "    filtered_scores = [(i, score) for i, score in filtered_scores if score >= dynamic_threshold]\n",
    "    \n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if not return_all:\n",
    "        filtered_scores = filtered_scores[:top_n]\n",
    "\n",
    "    recommendations = [(i, data[\"book_title\"].iloc[i], round(score, 3)) for i, score in filtered_scores]\n",
    "    \n",
    "    return recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d27af",
   "metadata": {},
   "source": [
    "### for paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db3d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Train BoW Model\n",
    "def train_bow(data):\n",
    "    bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "    bow_matrix = bow_vectorizer.fit_transform(data['text'])  # Transform entire dataset\n",
    "    return bow_vectorizer, bow_matrix\n",
    "\n",
    "# BoW Recommendation Function\n",
    "def bow_recommendations(data, book_index, paragraph_index, bow_vectorizer, bow_matrix, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    # Extract the input paragraph\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "\n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return []\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    # input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "\n",
    "    # Filter dataset based on `exclude_input_book`\n",
    "    filtered_data = data if not exclude_input_book else data[data[\"book_index\"] != book_index]\n",
    "\n",
    "    # Compute BoW representation for the input paragraph\n",
    "    input_vector = bow_vectorizer.transform([input_text])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = cosine_similarity(input_vector, bow_matrix).flatten()\n",
    "\n",
    "    \n",
    "    # Apply threshold\n",
    "    sim_scores = list(enumerate(cosine_sim))\n",
    "    max_similarity_score = max(cosine_sim) if len(sim_scores) > 0 else 0\n",
    "    threshold_value = threshold * max_similarity_score\n",
    "\n",
    "    # Filter and sort recommendations\n",
    "    filtered_scores = [(idx, score) for idx, score in sim_scores if score >= threshold_value and score < 1.0]\n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Return structured recommendations\n",
    "    recommendations = [(filtered_data.iloc[idx][\"book_index\"],\n",
    "                        filtered_data.iloc[idx][\"paragraph_index\"],\n",
    "                        filtered_data.iloc[idx][\"text\"],\n",
    "                        filtered_data.iloc[idx][\"book_title\"],\n",
    "                        round(score, 3))\n",
    "                        for idx, score in filtered_scores]\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9892ee7-a6c4-4cd1-a2dd-338048c4a67d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee3b6c",
   "metadata": {},
   "source": [
    "### RUN - TRACK PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03acf95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "from gensim.models import FastText\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# SETTINGS\n",
    "input_book_index = 0  # Book index for paragraph testing\n",
    "input_paragraph_index = 7  # Paragraph index for paragraph testing\n",
    "\n",
    "top_n = 5\n",
    "exclude_input_book = True\n",
    "threshold = 0.5\n",
    "max_runtime = 3600  # Maximum runtime in seconds (1 hour)\n",
    "\n",
    "# Load FastText Model\n",
    "# fasttext_model = joblib.load(\"saved_models/fasttext.model\")\n",
    "fasttext_model = FastText.load(\"saved_models/fasttext.model\")\n",
    "\n",
    "print(\"FastText model loaded\")\n",
    "\n",
    "def fasttext_recommendations(data, book_index, paragraph_index, model, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    process = psutil.Process()\n",
    "    psutil.cpu_percent(interval=None)\n",
    "    cpu_start = psutil.cpu_percent(interval=0.1)\n",
    "    start_time = time.time()\n",
    "\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return {}, [], {}\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    input_book_index = input_para.iloc[0][\"book_index\"]\n",
    "    input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "    \n",
    "    input_data = {\n",
    "        \"book_index\": input_book_index,\n",
    "        \"paragraph_index\": paragraph_index,\n",
    "        \"book_title\": input_book_title,\n",
    "        \"text\": input_text\n",
    "    }\n",
    "    \n",
    "    filtered_data = data if not exclude_input_book else data[data[\"book_index\"] != book_index]\n",
    "    filtered_data = filtered_data.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "    \n",
    "    def get_document_vector(text):\n",
    "        tokens = text.split()\n",
    "        vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "    \n",
    "    input_vector = get_document_vector(input_text)\n",
    "    doc_vectors = np.array([get_document_vector(row[\"text\"]) for _, row in filtered_data.iterrows()])\n",
    "    \n",
    "    cosine_sim = np.zeros(len(filtered_data))\n",
    "    with tqdm(total=len(filtered_data), desc=f\"Computing Cosine Similarities (FastText)\", unit=\"comparison\") as pbar:\n",
    "        for i in range(len(filtered_data)):\n",
    "            cosine_sim[i] = cosine_similarity([input_vector], [doc_vectors[i]])[0, 0]\n",
    "            pbar.update(1)\n",
    "    \n",
    "    start_iteration_time = time.time()\n",
    "    iterations_done = 0\n",
    "    with tqdm(total=len(cosine_sim), desc=f\"Filtering & Sorting Similarities (FastText)\", unit=\"iteration\") as pbar:\n",
    "        max_similarity_score = max(cosine_sim) if len(cosine_sim) > 0 else 0\n",
    "        threshold_value = threshold * max_similarity_score\n",
    "        filtered_scores = []\n",
    "        \n",
    "        for idx, score in enumerate(cosine_sim):\n",
    "            if score >= threshold_value and score < 1.0:\n",
    "                filtered_scores.append((idx, score))\n",
    "            pbar.update(1)  # Update tqdm for each iteration\n",
    "            iterations_done += 1\n",
    "            \n",
    "            if time.time() - start_time > max_runtime:\n",
    "                print(\"FastText exceeded max runtime and was stopped.\")\n",
    "                elapsed_time = time.time() - start_time\n",
    "                cpu_end = psutil.cpu_percent(interval=0.1)\n",
    "                cpu_usage = cpu_end - cpu_start\n",
    "                memory_usage = process.memory_info().rss / (1024 * 1024)\n",
    "                \n",
    "                ips = iterations_done / elapsed_time if elapsed_time > 0 else 0\n",
    "                remaining_iterations = len(cosine_sim) - iterations_done\n",
    "                estimated_remaining_time = remaining_iterations / ips if ips > 0 else 0\n",
    "                estimated_total_time = elapsed_time + estimated_remaining_time\n",
    "                \n",
    "                performance_data = {\n",
    "                    \"algorithm\": \"FastText\",\n",
    "                    \"elapsed_time\": elapsed_time,\n",
    "                    \"memory_usage\": memory_usage,\n",
    "                    \"cpu_usage\": cpu_usage,\n",
    "                    \"iterations_done\": iterations_done,\n",
    "                    \"total_iterations\": len(cosine_sim),\n",
    "                    \"iterations_per_second\": ips,\n",
    "                    \"estimated_remaining_time\": estimated_remaining_time,\n",
    "                    \"estimated_total_time\": estimated_total_time\n",
    "                }\n",
    "                return performance_data, input_data, []\n",
    "    \n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    recommendations = [(filtered_data.iloc[idx][\"book_index\"],\n",
    "                        filtered_data.iloc[idx][\"paragraph_index\"],\n",
    "                        round(score, 3),\n",
    "                        filtered_data.iloc[idx][\"book_title\"],\n",
    "                        filtered_data.iloc[idx][\"text\"])\n",
    "                        for idx, score in filtered_scores]\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    cpu_end = psutil.cpu_percent(interval=0.1)\n",
    "    cpu_usage = cpu_end - cpu_start\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)\n",
    "    \n",
    "    ips = iterations_done / elapsed_time if elapsed_time > 0 else 0\n",
    "    \n",
    "    performance_data = {\n",
    "        \"algorithm\": \"FastText\",\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"memory_usage\": memory_usage,\n",
    "        \"cpu_usage\": cpu_usage,\n",
    "        \"iterations_done\": iterations_done,\n",
    "        \"total_iterations\": len(cosine_sim),\n",
    "        \"iterations_per_second\": ips\n",
    "    }\n",
    "    \n",
    "    return performance_data, input_data, recommendations\n",
    "\n",
    "# Run FastText Recommendation with Progress Bar\n",
    "data = df_paragraphs\n",
    "algo_name = \"FastText\"\n",
    "\n",
    "performance_data, input_data, recommendations = fasttext_recommendations(data, input_book_index, input_paragraph_index, fasttext_model, top_n=top_n, threshold=threshold, exclude_input_book=exclude_input_book)\n",
    "\n",
    "# Create DataFrame for performance results\n",
    "performance_df = pd.DataFrame([performance_data])\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "if recommendations:\n",
    "    recommendations_list = [\n",
    "        {\"book_index\": book_idx,\n",
    "         \"paragraph_index\": para_idx,\n",
    "         \"similarity_score\": similarity,\n",
    "         \"recommended_book\": rec_title,\n",
    "         \"recommended_text\": text}\n",
    "        for book_idx, para_idx, similarity, rec_title, text in recommendations\n",
    "    ]\n",
    "    recommendations_df = pd.DataFrame(recommendations_list)\n",
    "    final_df = pd.concat([performance_df, input_df, recommendations_df], ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.concat([performance_df, input_df], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(f\"results/{algo_name.lower()}_performance_results.csv\", index=False)\n",
    "\n",
    "# Display Performance Data\n",
    "print(f\"{algo_name} testing complete! Results saved.\")\n",
    "print(f\"Elapsed Time: {performance_data['elapsed_time']:.2f} sec, Memory Usage: {performance_data['memory_usage']:.2f} MB, CPU Usage: {performance_data['cpu_usage']:.2f}%, IPS: {performance_data['iterations_per_second']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b7e017",
   "metadata": {},
   "source": [
    "### for summary - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d59a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def train_fasttext_summary(data, vector_size=100, window=5, min_count=1, epochs=50):\n",
    "    tokenized_descriptions = [desc.split() for desc in data['combined']]\n",
    "    model = FastText(sentences=tokenized_descriptions, vector_size=vector_size, window=window, min_count=min_count, epochs=epochs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def fasttext_summary(data, book_title, model, top_n=5, threshold=0.5, return_all=False):\n",
    "    # Tokenize descriptions\n",
    "    tokenized_descriptions = [desc.split() for desc in data['combined']]\n",
    "\n",
    "    # Function to get document vector by averaging word embeddings\n",
    "    def get_document_vector(tokens):\n",
    "        vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "    # Generate document vectors for all books\n",
    "    doc_vectors = np.array([get_document_vector(tokens) for tokens in tokenized_descriptions])\n",
    "\n",
    "    # Get index of the queried book\n",
    "    if book_title not in data[\"book_title\"].values:\n",
    "        print(f\"Book '{book_title}' not found!\")\n",
    "        return []\n",
    "\n",
    "    book_idx = data[data[\"book_title\"] == book_title].index[0]\n",
    "    book_vector = doc_vectors[book_idx].reshape(1, -1)\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    similarities = cosine_similarity(book_vector, doc_vectors)[0]\n",
    "\n",
    "    # Exclude queried book before filtering\n",
    "    scores_with_indices = [(i, score) for i, score in enumerate(similarities) if i != book_idx]\n",
    "\n",
    "    if not scores_with_indices:\n",
    "        print(\"No valid recommendations found!\")\n",
    "        return []\n",
    "\n",
    "    max_similarity_score = max(score for _, score in scores_with_indices)\n",
    "    dynamic_threshold = threshold * max_similarity_score\n",
    "\n",
    "    filtered_scores = [(i, score) for i, score in scores_with_indices if score >= dynamic_threshold and score < 1.0]\n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if not return_all:\n",
    "        filtered_scores = filtered_scores[:top_n]\n",
    "\n",
    "    recommendations = [(i, data[\"book_title\"].iloc[i], round(score, 3)) for i, score in filtered_scores]\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec7045",
   "metadata": {},
   "source": [
    "### for paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c964ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Train FastText Model\n",
    "def train_fasttext(data):\n",
    "    tokenized_texts = [text.split() for text in data['text']]\n",
    "    model = FastText(tokenized_texts, vector_size=100, window=5, min_count=1, epochs=10)\n",
    "    return model\n",
    "\n",
    "# FastText Recommendation Function\n",
    "def fasttext_recommendations(data, book_index, paragraph_index, model, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    # Extract the input paragraph\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "\n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return []\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "\n",
    "    # Filter dataset\n",
    "    filtered_data = data if not exclude_input_book else data[data[\"book_index\"] != book_index]\n",
    "\n",
    "    # Convert text to FastText vectors\n",
    "    def get_document_vector(text):\n",
    "        tokens = text.split()\n",
    "        vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "    # Compute embeddings\n",
    "    input_vector = get_document_vector(input_text)\n",
    "    doc_vectors = np.array([get_document_vector(row[\"text\"]) for _, row in filtered_data.iterrows()])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = cosine_similarity([input_vector], doc_vectors)[0]\n",
    "\n",
    "    \n",
    "    # Apply threshold\n",
    "    sim_scores = list(enumerate(cosine_sim))\n",
    "    max_similarity_score = max(cosine_sim) if len(sim_scores) > 0 else 0\n",
    "    threshold_value = threshold * max_similarity_score\n",
    "\n",
    "    filtered_scores = [(idx, score) for idx, score in sim_scores if score >= threshold_value and score < 1.0]\n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Return structured recommendations\n",
    "    recommendations = [(filtered_data.iloc[idx][\"book_index\"],\n",
    "                        filtered_data.iloc[idx][\"paragraph_index\"],\n",
    "                        filtered_data.iloc[idx][\"text\"],\n",
    "                        filtered_data.iloc[idx][\"book_title\"],\n",
    "                        round(score, 3))\n",
    "                        for idx, score in filtered_scores]\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9e19fc-49fc-4f7b-b1f9-972258eca6d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24035fff",
   "metadata": {},
   "source": [
    "### RUN - TRACK PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53833e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Cosine Similarities (GloVe): 100%|██████████| 181559/181559 [00:49<00:00, 3660.42comparison/s]\n",
      "Filtering & Sorting Similarities (GloVe): 100%|██████████| 181559/181559 [00:00<00:00, 1379306.32iteration/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GloVe testing complete! Results saved.\n",
      "Elapsed Time: 82.95 sec, Memory Usage: 3469.90 MB, CPU Usage: 6.30%, IPS: 2188.82\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "# SETTINGS'\n",
    "input_book_index = 0  # Book index for paragraph testing\n",
    "input_paragraph_index = 7  # Paragraph index for paragraph testing\n",
    "\n",
    "top_n = 5\n",
    "exclude_input_book = True\n",
    "threshold = 0.5\n",
    "max_runtime = 3600  # Maximum runtime in seconds (1 hour)\n",
    "\n",
    "# Load GloVe Model\n",
    "glove_embeddings = joblib.load(\"saved_models/glove.pkl\")\n",
    "embedding_dim = 50\n",
    "\n",
    "print(\"GloVe model loaded\")\n",
    "\n",
    "def glove_recommendations(data, book_index, paragraph_index, embeddings_index, embedding_dim=50, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    process = psutil.Process()\n",
    "    cpu_start = psutil.cpu_percent(interval=None)\n",
    "    start_time = time.time()\n",
    "\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return {}, [], {}\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    input_book_index = input_para.iloc[0][\"book_index\"]\n",
    "    input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "    \n",
    "    input_data = {\n",
    "        \"book_index\": input_book_index,\n",
    "        \"paragraph_index\": paragraph_index,\n",
    "        \"book_title\": input_book_title,\n",
    "        \"text\": input_text\n",
    "    }\n",
    "    \n",
    "    filtered_data = data if not exclude_input_book else data[data[\"book_index\"] != book_index]\n",
    "    filtered_data = filtered_data.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "    \n",
    "    def get_document_vector(text):\n",
    "        tokens = text.split()\n",
    "        vectors = [embeddings_index[word] for word in tokens if word in embeddings_index]\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(embedding_dim)\n",
    "    \n",
    "    input_vector = get_document_vector(input_text)\n",
    "    doc_vectors = np.array([get_document_vector(row[\"text\"]) for _, row in filtered_data.iterrows()])\n",
    "    \n",
    "    cosine_sim = np.zeros(len(filtered_data))\n",
    "    with tqdm(total=len(filtered_data), desc=f\"Computing Cosine Similarities (GloVe)\", unit=\"comparison\") as pbar:\n",
    "        for i in range(len(filtered_data)):\n",
    "            cosine_sim[i] = cosine_similarity([input_vector], [doc_vectors[i]])[0, 0]\n",
    "            pbar.update(1)\n",
    "    \n",
    "    start_iteration_time = time.time()\n",
    "    iterations_done = 0\n",
    "    with tqdm(total=len(cosine_sim), desc=f\"Filtering & Sorting Similarities (GloVe)\", unit=\"iteration\") as pbar:\n",
    "        max_similarity_score = max(cosine_sim) if len(cosine_sim) > 0 else 0\n",
    "        threshold_value = threshold * max_similarity_score\n",
    "        filtered_scores = []\n",
    "        \n",
    "        for idx, score in enumerate(cosine_sim):\n",
    "            if score >= threshold_value and score < 1.0:\n",
    "                filtered_scores.append((idx, score))\n",
    "            pbar.update(1)  # Update tqdm for each iteration\n",
    "            iterations_done += 1\n",
    "            \n",
    "            if time.time() - start_time > max_runtime:\n",
    "                print(\"GloVe exceeded max runtime and was stopped.\")\n",
    "                elapsed_time = time.time() - start_time\n",
    "                cpu_end = psutil.cpu_percent(interval=None)\n",
    "                cpu_usage = cpu_end - cpu_start\n",
    "                memory_usage = process.memory_info().rss / (1024 * 1024)\n",
    "                \n",
    "                ips = iterations_done / elapsed_time if elapsed_time > 0 else 0\n",
    "                remaining_iterations = len(cosine_sim) - iterations_done\n",
    "                estimated_remaining_time = remaining_iterations / ips if ips > 0 else 0\n",
    "                estimated_total_time = elapsed_time + estimated_remaining_time\n",
    "                \n",
    "                performance_data = {\n",
    "                    \"algorithm\": \"GloVe\",\n",
    "                    \"elapsed_time\": elapsed_time,\n",
    "                    \"memory_usage\": memory_usage,\n",
    "                    \"cpu_usage\": cpu_usage,\n",
    "                    \"iterations_done\": iterations_done,\n",
    "                    \"total_iterations\": len(cosine_sim),\n",
    "                    \"iterations_per_second\": ips,\n",
    "                    \"estimated_remaining_time\": estimated_remaining_time,\n",
    "                    \"estimated_total_time\": estimated_total_time\n",
    "                }\n",
    "                return performance_data, input_data, []\n",
    "    \n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    recommendations = [(filtered_data.iloc[idx][\"book_index\"],\n",
    "                        filtered_data.iloc[idx][\"paragraph_index\"],\n",
    "                        round(score, 3),\n",
    "                        filtered_data.iloc[idx][\"book_title\"],\n",
    "                        filtered_data.iloc[idx][\"text\"])\n",
    "                        for idx, score in filtered_scores]\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    cpu_end = psutil.cpu_percent(interval=None)\n",
    "    cpu_usage = cpu_end - cpu_start\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)\n",
    "    \n",
    "    ips = iterations_done / elapsed_time if elapsed_time > 0 else 0\n",
    "    \n",
    "    performance_data = {\n",
    "        \"algorithm\": \"GloVe\",\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"memory_usage\": memory_usage,\n",
    "        \"cpu_usage\": cpu_usage,\n",
    "        \"iterations_done\": iterations_done,\n",
    "        \"total_iterations\": len(cosine_sim),\n",
    "        \"iterations_per_second\": ips\n",
    "    }\n",
    "    \n",
    "    return performance_data, input_data, recommendations\n",
    "\n",
    "# Run GloVe Recommendation with Progress Bar\n",
    "data = df_paragraphs\n",
    "algo_name = \"GloVe\"\n",
    "\n",
    "performance_data, input_data, recommendations = glove_recommendations(data, input_book_index, input_paragraph_index, glove_embeddings, embedding_dim, top_n=top_n, threshold=threshold, exclude_input_book=exclude_input_book)\n",
    "\n",
    "# Create DataFrame for performance results\n",
    "performance_df = pd.DataFrame([performance_data])\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "if recommendations:\n",
    "    recommendations_list = [\n",
    "        {\"book_index\": book_idx,\n",
    "         \"paragraph_index\": para_idx,\n",
    "         \"similarity_score\": similarity,\n",
    "         \"recommended_book\": rec_title,\n",
    "         \"recommended_text\": text}\n",
    "        for book_idx, para_idx, similarity, rec_title, text in recommendations\n",
    "    ]\n",
    "    recommendations_df = pd.DataFrame(recommendations_list)\n",
    "    final_df = pd.concat([performance_df, input_df, recommendations_df], ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.concat([performance_df, input_df], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(f\"results/{algo_name.lower()}_performance_results.csv\", index=False)\n",
    "\n",
    "# Display Performance Data\n",
    "print(f\"{algo_name} testing complete! Results saved.\")\n",
    "print(f\"Elapsed Time: {performance_data['elapsed_time']:.2f} sec, Memory Usage: {performance_data['memory_usage']:.2f} MB, CPU Usage: {performance_data['cpu_usage']:.2f}%, IPS: {performance_data['iterations_per_second']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e368a",
   "metadata": {},
   "source": [
    "### for summary - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feed460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vectors = np.array(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vectors\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "def glove_summary(data, book_title, top_n, threshold=0.5, return_all=False, embedding_dim=50):\n",
    "    current_dir = os.getcwd()\n",
    "    glove_path = os.path.join(current_dir, \"..\", \"..\", \"glove.6B\", f\"glove.6B.{embedding_dim}d.txt\")\n",
    "    glove_path = os.path.abspath(glove_path)\n",
    "\n",
    "    # Load pre-trained GloVe embeddings\n",
    "    embeddings_index = load_glove_embeddings(glove_path)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_descriptions = [desc.split() for desc in data['combined']]\n",
    "    \n",
    "    # Get document vectors by averaging GloVe word embeddings\n",
    "    def get_document_vector(tokens):\n",
    "        vectors = [embeddings_index[word] for word in tokens if word in embeddings_index]\n",
    "        # Return the mean vector or a zero vector of embedding_dim\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(embedding_dim)\n",
    "    \n",
    "    # Generate vectors for all documents\n",
    "    doc_vectors = np.array([get_document_vector(tokens) for tokens in tokenized_descriptions])\n",
    "    \n",
    "    # Get the vector for the queried book\n",
    "    book_idx = data[data[\"book_title\"] == book_title].index[0]\n",
    "    book_vector = doc_vectors[book_idx]\n",
    "    \n",
    "    similarities = cosine_similarity([book_vector], doc_vectors)[0]\n",
    "    \n",
    "    # Exclude the queried book itself and find the max similarity score\n",
    "    scores_with_indices = list(enumerate(similarities))\n",
    "    filtered_scores = [(i, score) for i, score in scores_with_indices if i != book_idx]\n",
    "\n",
    "    max_similarity_score = max(score for _, score in filtered_scores)\n",
    "    \n",
    "    # Apply dynamic threshold (percentage of the max score)\n",
    "    dynamic_threshold = threshold * max_similarity_score\n",
    "    filtered_scores = [(i, score) for i, score in filtered_scores if score >= dynamic_threshold]\n",
    "    \n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if not return_all:\n",
    "        filtered_scores = filtered_scores[:top_n]\n",
    "\n",
    "    recommendations = [(i, data[\"book_title\"].iloc[i], round(score, 3)) for i, score in filtered_scores]\n",
    "    \n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927190e",
   "metadata": {},
   "source": [
    "### for paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5437a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "# Load GloVe Embeddings\n",
    "def load_glove_embeddings(file_path, embedding_dim=50):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vectors = np.array(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vectors\n",
    "    return embeddings_index\n",
    "\n",
    "# Loads embeddings from file\n",
    "def train_glove(data, embedding_dim=50):\n",
    "    current_dir = os.getcwd()\n",
    "    glove_path = os.path.join(current_dir, \"..\", \"..\", \"glove.6B\", f\"glove.6B.{embedding_dim}d.txt\")\n",
    "    glove_path = os.path.abspath(glove_path)\n",
    "\n",
    "    embeddings_index = load_glove_embeddings(glove_path, embedding_dim)\n",
    "    return embeddings_index\n",
    "\n",
    "# GloVe Recommendation Function\n",
    "def glove_recommendations(data, book_index, paragraph_index, embeddings_index, embedding_dim=50, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    # Extract the input paragraph\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "\n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return []\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "\n",
    "    # Filter dataset based on `exclude_input_book`\n",
    "    filtered_data = data if not exclude_input_book else data[data[\"book_index\"] != book_index]\n",
    "\n",
    "    # Convert text to GloVe vectors\n",
    "    def get_document_vector(text):\n",
    "        tokens = text.split()\n",
    "        vectors = [embeddings_index[word] for word in tokens if word in embeddings_index]\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(embedding_dim)\n",
    "\n",
    "    # Compute embeddings\n",
    "    input_vector = get_document_vector(input_text)\n",
    "    doc_vectors = np.array([get_document_vector(row[\"text\"]) for _, row in filtered_data.iterrows()])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = cosine_similarity([input_vector], doc_vectors)[0]\n",
    "\n",
    "\n",
    "    # Apply threshold\n",
    "    sim_scores = list(enumerate(cosine_sim))\n",
    "    max_similarity_score = max(cosine_sim) if len(sim_scores) > 0 else 0\n",
    "    threshold_value = threshold * max_similarity_score\n",
    "\n",
    "    filtered_scores = [(idx, score) for idx, score in sim_scores if score >= threshold_value and score < 1.0]\n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Return structured recommendations\n",
    "    recommendations = [(filtered_data.iloc[idx][\"book_index\"],\n",
    "                        filtered_data.iloc[idx][\"paragraph_index\"],\n",
    "                        filtered_data.iloc[idx][\"text\"],\n",
    "                        filtered_data.iloc[idx][\"book_title\"],\n",
    "                        round(score, 3))\n",
    "                        for idx, score in filtered_scores]\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b75c6fc-cd90-42e6-8d99-fd28d496e339",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b10cd",
   "metadata": {},
   "source": [
    "### RUN - TRACK PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e600a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# SETTINGS\n",
    "input_book_index = 0  # Book index for paragraph testing\n",
    "input_paragraph_index = 7  # Paragraph index for paragraph testing\n",
    "\n",
    "top_n = 5\n",
    "exclude_input_book = True\n",
    "threshold = 0.5\n",
    "max_runtime = 3600  # Maximum runtime in seconds (1 hour)\n",
    "\n",
    "# Load BERT Model\n",
    "bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"BERT model loaded\")\n",
    "\n",
    "def bert_recommendations(data, book_index, paragraph_index, model, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    process = psutil.Process()\n",
    "    cpu_start = psutil.cpu_percent(interval=0.1)\n",
    "    start_time = time.time()\n",
    "\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return {}, [], {}\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    input_book_index = input_para.iloc[0][\"book_index\"]\n",
    "    input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "    \n",
    "    input_data = {\n",
    "        \"book_index\": input_book_index,\n",
    "        \"paragraph_index\": paragraph_index,\n",
    "        \"book_title\": input_book_title,\n",
    "        \"text\": input_text\n",
    "    }\n",
    "    \n",
    "    filtered_data = data if not exclude_input_book else data[data[\"book_index\"] != book_index]\n",
    "    filtered_data = filtered_data.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "    \n",
    "    input_embedding = model.encode(input_text, convert_to_tensor=True)\n",
    "    embeddings = model.encode(filtered_data['text'].tolist(), convert_to_tensor=True)\n",
    "    \n",
    "    similarities = cosine_similarity([input_embedding.cpu().numpy()], embeddings.cpu().numpy())[0]\n",
    "    \n",
    "    with tqdm(total=len(filtered_data), desc=f\"Computing Similarities (BERT)\", unit=\"iteration\") as pbar:\n",
    "        filtered_scores = [(i, score) for i, score in enumerate(similarities) if score < 1.0]\n",
    "        max_similarity_score = max(score for _, score in filtered_scores) if filtered_scores else 0\n",
    "        threshold_value = threshold * max_similarity_score\n",
    "        \n",
    "        filtered_scores = [(idx, score) for idx, score in filtered_scores if score >= threshold_value]\n",
    "        filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        pbar.update(len(filtered_scores))\n",
    "        \n",
    "        if time.time() - start_time > max_runtime:\n",
    "            print(\"BERT exceeded max runtime and was stopped.\")\n",
    "            elapsed_time = time.time() - start_time\n",
    "            cpu_end = psutil.cpu_percent(interval=0.1)\n",
    "            cpu_usage = cpu_end - cpu_start\n",
    "            memory_usage = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "            \n",
    "            ips = len(filtered_scores) / elapsed_time if elapsed_time > 0 else 0\n",
    "            remaining_iterations = len(filtered_data) - len(filtered_scores)\n",
    "            estimated_remaining_time = remaining_iterations / ips if ips > 0 else 0\n",
    "            estimated_total_time = elapsed_time + estimated_remaining_time\n",
    "            \n",
    "            performance_data = {\n",
    "                \"algorithm\": \"BERT\",\n",
    "                \"elapsed_time\": elapsed_time,\n",
    "                \"memory_usage\": memory_usage,\n",
    "                \"cpu_usage\": cpu_usage,\n",
    "                \"iterations_done\": len(filtered_scores),\n",
    "                \"total_iterations\": len(filtered_data),\n",
    "                \"iterations_per_second\": ips,\n",
    "                \"estimated_remaining_time\": estimated_remaining_time,\n",
    "                \"estimated_total_time\": estimated_total_time\n",
    "            }\n",
    "            return performance_data, input_data, []\n",
    "    \n",
    "    recommendations = [(filtered_data.iloc[idx][\"book_index\"],\n",
    "                        filtered_data.iloc[idx][\"paragraph_index\"],\n",
    "                        round(score, 3),\n",
    "                        filtered_data.iloc[idx][\"book_title\"],\n",
    "                        filtered_data.iloc[idx][\"text\"])\n",
    "                        for idx, score in filtered_scores]\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    cpu_end = psutil.cpu_percent(interval=0.1)\n",
    "    cpu_usage = cpu_end - cpu_start\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "    \n",
    "    ips = len(filtered_scores) / elapsed_time if elapsed_time > 0 else 0\n",
    "    \n",
    "    performance_data = {\n",
    "        \"algorithm\": \"BERT\",\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"memory_usage\": memory_usage,\n",
    "        \"cpu_usage\": cpu_usage,\n",
    "        \"iterations_done\": len(filtered_scores),\n",
    "        \"total_iterations\": len(filtered_data),\n",
    "        \"iterations_per_second\": ips\n",
    "    }\n",
    "    \n",
    "    return performance_data, input_data, recommendations\n",
    "\n",
    "# Run BERT Recommendation with Progress Bar\n",
    "data = df_paragraphs\n",
    "algo_name = \"BERT\"\n",
    "\n",
    "performance_data, input_data, recommendations = bert_recommendations(data, input_book_index, input_paragraph_index, bert_model, top_n=top_n, threshold=threshold, exclude_input_book=exclude_input_book)\n",
    "\n",
    "# Create DataFrame for performance results\n",
    "performance_df = pd.DataFrame([performance_data])\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "if recommendations:\n",
    "    recommendations_list = [\n",
    "        {\"book_index\": book_idx,\n",
    "         \"paragraph_index\": para_idx,\n",
    "         \"similarity_score\": similarity,\n",
    "         \"recommended_book\": rec_title,\n",
    "         \"recommended_text\": text}\n",
    "        for book_idx, para_idx, similarity, rec_title, text in recommendations\n",
    "    ]\n",
    "    recommendations_df = pd.DataFrame(recommendations_list)\n",
    "    final_df = pd.concat([performance_df, input_df, recommendations_df], ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.concat([performance_df, input_df], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(f\"results/{algo_name.lower()}_performance_results.csv\", index=False)\n",
    "\n",
    "# Display Performance Data\n",
    "print(f\"{algo_name} testing complete! Results saved.\")\n",
    "print(f\"Elapsed Time: {performance_data['elapsed_time']:.2f} sec, Memory Usage: {performance_data['memory_usage']:.2f} MB, CPU Usage: {performance_data['cpu_usage']:.2f}%, IPS: {performance_data['iterations_per_second']:.2f}\")\n",
    "if \"estimated_total_time\" in performance_data:\n",
    "    print(f\"Estimated Remaining Time: {performance_data['estimated_remaining_time']:.2f} sec, Estimated Total Time: {performance_data['estimated_total_time']:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3737c4d",
   "metadata": {},
   "source": [
    "### for summary - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a39a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def bert_summary(data, book_title, top_n, threshold=0.5, return_all=False):\n",
    "    # Load pre-trained BERT model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Generate embeddings for all descriptions\n",
    "    embeddings = model.encode(data['combined'].tolist(), convert_to_tensor=True)\n",
    "    \n",
    "    # Generate embedding for the queried book\n",
    "    book_embedding = model.encode(data[data[\"book_title\"] == book_title]['combined'].iloc[0], convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    similarities = cosine_similarity([book_embedding.cpu().numpy()], embeddings.cpu().numpy())[0]\n",
    "    \n",
    "    # Remove the queried book itself and find the max similarity score\n",
    "    similarities_with_indices = list(enumerate(similarities))\n",
    "    filtered_scores = [(i, score) for i, score in similarities_with_indices if data[\"book_title\"].iloc[i] != book_title]\n",
    "\n",
    "    max_similarity_score = max(score for _, score in filtered_scores)\n",
    "    \n",
    "    # Apply dynamic threshold\n",
    "    dynamic_threshold = threshold * max_similarity_score\n",
    "    filtered_scores = [(i, score) for i, score in filtered_scores if score >= dynamic_threshold]\n",
    "    \n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if not return_all:\n",
    "        filtered_scores = filtered_scores[:top_n]\n",
    "\n",
    "    recommendations = [(i, data[\"book_title\"].iloc[i], round(score, 3)) for i, score in filtered_scores]\n",
    "    \n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2541fb",
   "metadata": {},
   "source": [
    "### for paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0390c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Train BERT Model\n",
    "def train_bert():\n",
    "    return SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# BERT Recommendation Function\n",
    "def bert_recommendations(data, book_index, paragraph_index, model, top_n=5, threshold=0.5, exclude_input_book=True):\n",
    "    # Get input paragraph text\n",
    "    input_para = data[(data[\"book_index\"] == book_index) & (data[\"paragraph_index\"] == paragraph_index)]\n",
    "    \n",
    "    if input_para.empty:\n",
    "        print(\"Paragraph not found!\")\n",
    "        return []\n",
    "\n",
    "    input_text = input_para.iloc[0][\"text\"]\n",
    "    # input_book_title = input_para.iloc[0][\"book_title\"]\n",
    "\n",
    "    # Filter dataset based on whether input book should be excluded\n",
    "    filtered_data = data if not exclude_input_book else data[data[\"book_index\"] != book_index]\n",
    "\n",
    "    # Compute BERT embeddings\n",
    "    input_embedding = model.encode(input_text, convert_to_tensor=True)\n",
    "    embeddings = model.encode(filtered_data['text'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    similarities = cosine_similarity([input_embedding.cpu().numpy()], embeddings.cpu().numpy())[0]\n",
    "\n",
    "\n",
    "    # Remove exact matches (similarity = 1.0) and filter by threshold\n",
    "    filtered_scores = [(i, score) for i, score in enumerate(similarities) if score < 1.0]\n",
    "    max_similarity_score = max(score for _, score in filtered_scores) if filtered_scores else 0\n",
    "    threshold_value = threshold * max_similarity_score\n",
    "\n",
    "    filtered_scores = [(idx, score) for idx, score in filtered_scores if score >= threshold_value]\n",
    "    filtered_scores = sorted(filtered_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if len(filtered_scores) > top_n:\n",
    "        filtered_scores = filtered_scores[:top_n]\n",
    "\n",
    "    recommendations = [(filtered_data.iloc[idx][\"book_index\"],\n",
    "                        filtered_data.iloc[idx][\"paragraph_index\"],\n",
    "                        filtered_data.iloc[idx][\"text\"],\n",
    "                        filtered_data.iloc[idx][\"book_title\"],\n",
    "                        round(score, 3))\n",
    "                        for idx, score in filtered_scores]\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c28a1e-f8cb-4a3a-853f-b1d4ad6e1e20",
   "metadata": {},
   "source": [
    "## Example usage - short summaries of books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c8993",
   "metadata": {},
   "source": [
    "### 1 input - test coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53809958-44f3-44ad-86f9-68b45b62fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "book_title = \"Uses of Technology in Upper Secondary Mathematics Education\"\n",
    "print(f\"BOOK TITLE: {book_title}\\n\")\n",
    "top_n = 5\n",
    "all = True\n",
    "\n",
    "# Define different thresholds for different algorithms\n",
    "thresholds = {\n",
    "    \"TF-IDF\": 0.4,\n",
    "    \"LSA\": 0.4,\n",
    "    \"BERT\": 0.5,\n",
    "    \"BoW\": 0.4,\n",
    "    \"FastText\": 0.9,\n",
    "    \"GloVe\": 0.95\n",
    "}\n",
    "\n",
    "# Combine Features\n",
    "df_opensearch[\"combined\"] = df_opensearch[\"book_title\"] + \" \" + df_opensearch[\"summary\"]\n",
    "df_mtf[\"combined\"] = df_mtf[\"book_title\"] + \" \" + df_mtf[\"summary\"]\n",
    "\n",
    "# Use OpenSearch dataset\n",
    "data = df_opensearch\n",
    "\n",
    "# Check if the book title exists in the data\n",
    "if book_title not in df_opensearch[\"book_title\"].values:\n",
    "    print(f\"Book '{book_title}' was not found!\")\n",
    "\n",
    "recommendations = []\n",
    "coverage_scores = []\n",
    "\n",
    "# Function to Print Recommendations\n",
    "def show_rec(algo, all_rec):\n",
    "    print(f\"Recommendations using: {algo}\")\n",
    "    num_recs = len(all_rec)\n",
    "    coverage_scores.append((algo, len(all_rec)))\n",
    "    for rec in all_rec:\n",
    "        if len(rec) == 3:\n",
    "            idx, rec_title, similarity = rec\n",
    "            recommendations.append([algo, idx, rec_title, similarity])\n",
    "            print(f\"{idx}: {rec_title} (Cosine similarity: {similarity:.3f})\")\n",
    "        elif len(rec) == 2:\n",
    "            idx, rec_title = rec\n",
    "            recommendations.append([algo, idx, rec_title, None])\n",
    "            print(f\"{idx}: {rec_title}\")\n",
    "    print(f\"Num of RECOMMENDATIONS: {len(all_rec)}\\n\\n\")\n",
    "\n",
    "\n",
    "# RUN ALL ALGORITHMS WITH DIFFERENT THRESHOLDS\n",
    "\n",
    "# 1. TF-IDF\n",
    "similarity = \"cosine\"\n",
    "tfidf_rec = tfidf_summary(data, book_title, top_n, similarity, thresholds[\"TF-IDF\"], all)\n",
    "show_rec(f\"1. TF-IDF + {similarity}\", tfidf_rec)\n",
    "\n",
    "# 2. LSA\n",
    "lsa_rec = lsa_summary(data, book_title, top_n, thresholds[\"LSA\"], all)\n",
    "show_rec(\"2. LSA\", lsa_rec)\n",
    "\n",
    "# 3. BoW\n",
    "bow_rec = bow_summary(data, book_title, top_n, thresholds[\"BoW\"], all)\n",
    "show_rec(\"3. BoW\", bow_rec)\n",
    "\n",
    "# 4. FASTTEXT (High Threshold)\n",
    "fasttext_model = train_fasttext_summary(data)\n",
    "fasttext_rec = fasttext_summary(data, book_title, fasttext_model, top_n, thresholds[\"FastText\"], all)\n",
    "show_rec(\"4. FastText\", fasttext_rec)\n",
    "\n",
    "# 5. GloVe (High Threshold)\n",
    "glove_rec = glove_summary(data, book_title, top_n, thresholds[\"GloVe\"], all, embedding_dim=50)\n",
    "show_rec(\"5. GloVe\", glove_rec)\n",
    "\n",
    "# 6. BERT\n",
    "bert_rec = bert_summary(data, book_title, top_n, thresholds[\"BERT\"], all)\n",
    "show_rec(\"6. BERT\", bert_rec)\n",
    "\n",
    "print(\"DONE WITH RECOMMENDATIONS\")\n",
    "\n",
    "# Print coverage scores\n",
    "for i in coverage_scores:\n",
    "    print(i)\n",
    "\n",
    "# SAVE RECS AND COVERAGE\n",
    "recommendations_df = pd.DataFrame(recommendations, columns=[\"Algorithm\", \"Index\", \"Title\", \"Similarity\"])\n",
    "recommendations_df.to_csv(\"results/results_for_summaries/summaries_all_rec.csv\", index=False)\n",
    "\n",
    "coverage_df = pd.DataFrame(coverage_scores, columns=[\"Algorithm\", \"Num_of_rec\"])\n",
    "coverage_df.to_csv(\"results/results_for_summaries/summaries_all_rec_coverage.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50862c2a",
   "metadata": {},
   "source": [
    "### RUN 10 times - test coverage and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beceef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# SETTINGS\n",
    "num_runs = 10  # Change this to how many different books you want to test\n",
    "top_n = 5\n",
    "all = True  # Set to True to get all recommendations for coverage analysis\n",
    "\n",
    "# Define different thresholds for different algorithms\n",
    "thresholds = {\n",
    "    \"TF-IDF\": 0.4,\n",
    "    \"LSA\": 0.4,\n",
    "    \"BERT\": 0.5,\n",
    "    \"BoW\": 0.4,\n",
    "    \"FastText\": 0.9,\n",
    "    \"GloVe\": 0.95,\n",
    "}\n",
    "\n",
    "# Ensure the catalog has enough books\n",
    "total_books = len(df_opensearch)\n",
    "if num_runs > total_books:\n",
    "    print(f\"Not enough books in the catalog! Reducing runs to {total_books}\")\n",
    "    num_runs = total_books\n",
    "\n",
    "# Generate random book indices\n",
    "random_book_indices = random.sample(range(total_books), num_runs)\n",
    "\n",
    "# Find book titles for selected indices\n",
    "random_book_titles = [df_opensearch.iloc[idx][\"book_title\"] for idx in random_book_indices]\n",
    "\n",
    "# Ensure combined feature exists (Only needs to be done ONCE)\n",
    "df_opensearch[\"combined\"] = df_opensearch[\"book_title\"] + \" \" + df_opensearch[\"summary\"]\n",
    "df_mtf[\"combined\"] = df_mtf[\"book_title\"] + \" \" + df_mtf[\"summary\"]\n",
    "\n",
    "# Use OpenSearch dataset\n",
    "data = df_opensearch\n",
    "\n",
    "# Store coverage scores\n",
    "coverage_scores = []\n",
    "\n",
    "# Function to Print Recommendations and Store Coverage\n",
    "def show_rec(algo, all_rec, book_title):\n",
    "    print(f\"Book Title: {book_title} - Recommendations using: {algo}\")\n",
    "    coverage_scores.append((algo, len(all_rec), book_title))  # Store coverage per book title\n",
    "    for rec in all_rec:\n",
    "        if len(rec) == 3:\n",
    "            idx, rec_title, similarity = rec\n",
    "            print(f\"{idx}: {rec_title} (Cosine similarity: {similarity:.3f})\")\n",
    "        elif len(rec) == 2:\n",
    "            idx, rec_title = rec\n",
    "            print(f\"{idx}: {rec_title}\")\n",
    "    print(f\"Num of RECOMMENDATIONS: {len(all_rec)}\\n\\n\")\n",
    "\n",
    "\n",
    "# LOOP OVER MULTIPLE RANDOM BOOKS\n",
    "for book_title in random_book_titles:\n",
    "    print(f\"🔹 Testing Book Title: {book_title}\\n\")\n",
    "\n",
    "    # Run all 10 algorithms with **individual thresholds**\n",
    "    similarity = \"cosine\"\n",
    "    tfidf_rec = tfidf_summary(data, book_title, top_n, similarity, thresholds[\"TF-IDF\"], all)\n",
    "    show_rec(f\"1. TF-IDF + {similarity}\", tfidf_rec, book_title)\n",
    "\n",
    "    lsa_rec = lsa_summary(data, book_title, top_n, thresholds[\"LSA\"], all)\n",
    "    show_rec(\"2. LSA\", lsa_rec, book_title)\n",
    "\n",
    "    bert_rec = bert_summary(data, book_title, top_n, thresholds[\"BERT\"], all)\n",
    "    show_rec(\"3. BERT\", bert_rec, book_title)\n",
    "\n",
    "    bow_rec = bow_summary(data, book_title, top_n, thresholds[\"BoW\"], all)\n",
    "    show_rec(\"4. BoW\", bow_rec, book_title)\n",
    "\n",
    "    fasttext_model = train_fasttext_summary(data)\n",
    "    fasttext_rec = fasttext_summary(data, book_title, fasttext_model, top_n, thresholds[\"FastText\"], all)\n",
    "    show_rec(\"5. FastText\", fasttext_rec, book_title)\n",
    "\n",
    "    glove_rec = glove_summary(data, book_title, top_n, thresholds[\"GloVe\"], all, embedding_dim=50)\n",
    "    show_rec(\"6. GloVe\", glove_rec, book_title)\n",
    "\n",
    "    print(f\"DONE WITH RECOMMENDATIONS FOR BOOK: {book_title}\\n\")\n",
    "\n",
    "# Convert coverage data into DataFrame\n",
    "df_coverage = pd.DataFrame(coverage_scores, columns=[\"algorithm\", \"num_recommendations\", \"book_title\"])\n",
    "\n",
    "# Save the coverage results to a CSV\n",
    "df_coverage.to_csv(\"results/results_for_summaries/summaries_coverage_results.csv\", index=False)\n",
    "\n",
    "print(\"Coverage results saved to 'algorithm_coverage_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5175a4d6",
   "metadata": {},
   "source": [
    "### Run 10 times - Similarities(3) -> avg sim, confidence, diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce63ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# SETTINGS\n",
    "num_runs = 10\n",
    "top_n = 5\n",
    "all = False  \n",
    "\n",
    "# Define different thresholds for different algorithms\n",
    "thresholds = {\n",
    "    \"TF-IDF\": 0.4,\n",
    "    \"LSA\": 0.4,\n",
    "    \"BERT\": 0.5,\n",
    "    \"BoW\": 0.4,\n",
    "    \"FastText\": 0.9,\n",
    "    \"GloVe\": 0.95\n",
    "}\n",
    "\n",
    "# Ensure the catalog has enough books\n",
    "total_books = len(df_opensearch)\n",
    "if num_runs > total_books:\n",
    "    print(f\"Not enough books in the catalog! Reducing runs to {total_books}\")\n",
    "    num_runs = total_books\n",
    "\n",
    "# Generate random book indices\n",
    "random_book_indices = random.sample(range(total_books), num_runs)\n",
    "\n",
    "# Find book titles for selected indices\n",
    "random_book_titles = [df_opensearch.iloc[idx][\"book_title\"] for idx in random_book_indices]\n",
    "\n",
    "# Ensure combined feature exists (Only needs to be done ONCE)\n",
    "df_opensearch[\"combined\"] = df_opensearch[\"book_title\"] + \" \" + df_opensearch[\"summary\"]\n",
    "df_mtf[\"combined\"] = df_mtf[\"book_title\"] + \" \" + df_mtf[\"summary\"]\n",
    "\n",
    "# Use OpenSearch dataset\n",
    "data = df_opensearch\n",
    "\n",
    "# Store coverage scores and similarities\n",
    "results = []\n",
    "\n",
    "# Function to Print Recommendations and Store Coverage\n",
    "def show_rec(algo, recommendations, book_title):\n",
    "    print(f\"Book Title: {book_title} - Recommendations using: {algo}\")\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        if len(rec) == 3:\n",
    "            idx, rec_title, similarity = rec\n",
    "        elif len(rec) == 2:\n",
    "            idx, rec_title = rec\n",
    "            similarity = None \n",
    "\n",
    "        results.append({\n",
    "            \"algorithm\": algo,\n",
    "            \"book_title\": book_title,\n",
    "            \"recommended_title\": rec_title,\n",
    "            \"similarity\": similarity if similarity is not None else \"N/A\"\n",
    "        })\n",
    "        \n",
    "        # Print recommendation\n",
    "        if similarity is not None:\n",
    "            print(f\"{idx}: {rec_title} (Similarity: {similarity:.3f})\")\n",
    "        else:\n",
    "            print(f\"{idx}: {rec_title}\")\n",
    "    \n",
    "    print(f\"Num of RECOMMENDATIONS: {len(recommendations)}\\n\\n\")\n",
    "\n",
    "# LOOP OVER MULTIPLE RANDOM BOOKS\n",
    "for book_title in random_book_titles:\n",
    "    print(f\"🔹 Testing Book Title: {book_title}\\n\")\n",
    "\n",
    "    # Run all 10 algorithms with **individual thresholds**\n",
    "    similarity_metric = \"cosine\"\n",
    "\n",
    "    tfidf_rec = tfidf_summary(data, book_title, top_n, similarity_metric, thresholds[\"TF-IDF\"], all)\n",
    "    show_rec(f\"1. TF-IDF + {similarity_metric}\", tfidf_rec, book_title)\n",
    "\n",
    "    lsa_rec = lsa_summary(data, book_title, top_n, thresholds[\"LSA\"], all)\n",
    "    show_rec(\"2. LSA\", lsa_rec, book_title)\n",
    "\n",
    "    bow_rec = bow_summary(data, book_title, top_n, thresholds[\"BoW\"], all)\n",
    "    show_rec(\"3. BoW\", bow_rec, book_title)\n",
    "\n",
    "    fasttext_model = train_fasttext_summary(data)\n",
    "    fasttext_rec = fasttext_summary(data, book_title, fasttext_model, top_n, thresholds[\"FastText\"], all)\n",
    "    show_rec(\"4. FastText\", fasttext_rec, book_title)\n",
    "\n",
    "    glove_rec = glove_summary(data, book_title, top_n, thresholds[\"GloVe\"], all, embedding_dim=50)\n",
    "    show_rec(\"5. GloVe\", glove_rec, book_title)\n",
    "\n",
    "    bert_rec = bert_summary(data, book_title, top_n, thresholds[\"BERT\"], all)\n",
    "    show_rec(\"6. BERT\", bert_rec, book_title)\n",
    "    print(f\"DONE WITH RECOMMENDATIONS FOR BOOK: {book_title}\\n\")\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to CSV\n",
    "df_results.to_csv(\"results/results_for_summaries/summairies_similarity_results.csv\", index=False)\n",
    "\n",
    "print(\"Coverage and similarity results saved to 'algorithm_similarity_results.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
