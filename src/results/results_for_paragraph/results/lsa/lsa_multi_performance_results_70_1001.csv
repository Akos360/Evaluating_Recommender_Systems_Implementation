book_index,paragraph_index,similarity_score,recommended_book,recommended_text
213,13,0.629,Collider Physics Within The Standard Model : a Primer,"a field with suitable (depending on the particle spin) transformation properties under the Lorentz group (the relativistic spacetime coordinate transformations). It is remarkable that the description of all these particle interactions is based on a common principle: Ã¢Â€ÂœgaugeÃ¢Â€Â invariance. A Ã¢Â€ÂœgaugeÃ¢Â€Â symmetry is invariance under transformations that rotate the basic internal degrees of freedom, but with rotation angles that depend on the spacetime point. At the classical level, gauge invariance is a property of the Maxwell equations of electrodynamics, and it is in this context that the notion and the name of gauge invariance were introduced. The prototype of all quantum gauge field theories, with a single gauged charge, is quantum electrodynamics (QED), developed in the years from 1926 until about 1950, which is indeed the quantum version of MaxwellÃ¢Â€Â™s theory. Theories with gauge symmetry in four spacetime dimensions are renormalizable and are completely determined given the symmetry group and the representations of the interacting fields. The whole set of strong, electromagnetic, and weak interactions is described by a gauge theory with 12 gauged non-commuting charges. This is called the Ã¢Â€ÂœStandard ModelÃ¢Â€Â of particle interactions (SM). Actually, only a subgroup of the SM symmetry is directly reflected in the spectrum of physical states. A part of the electroweak symmetry is hidden by the Higgs mechanism for spontaneous symmetry breaking of the gauge symmetry. The theory of general relativity is a classical description of gravity (in the sense that it is non-quantum mechanical). It goes beyond the static approximation described by NewtonÃ¢Â€Â™s law and includes dynamical phenomena like, for example, gravitational waves. The problem of formulating a quantum theory of gravitational interactions is one of the central challenges of contemporary theoretical physics. But quantum effects in gravity only become important for energy concentrations in spacetime which are not in practice accessible to experimentation in the laboratory. Thus the search for the correct theory can only be done by a purely speculative approach. All attempts at a description of quantum gravity in terms of a well defined and computable local field theory along similar lines to those used for the SM have so far failed to lead to a satisfactory framework. Rather, at present, the most complete and plausible description of quantum gravity is a theory formulated in terms of non-pointlike basic objects, the so-called Ã¢Â€ÂœstringsÃ¢Â€Â, extended over much shorter distances than those experimentally accessible and which live in a spacetime with 10 or 11 dimensions. The additional dimensions beyond the familiar 4 are, typically, compactified, which means that they are curled up with a curvature radius of the order of the string dimensions. Present string theory is an all-comprehensive framework that suggests a unified description of all interactions including gravity, in which the SM would be only a low energy or large distance approximation. A fundamental principle of quantum mechanics, the Heisenberg uncertainty principle, implies that, when studying particles with spatial dimensions of order Ã‚Âx or interactions taking place at distances of order Ã‚Âx, one needs as a probe a beam of particles (typically produced by an accelerator) with impulse p & Ã¢Â€Â=Ã‚Âx, where Ã¢Â€Â is the reduced Planck constant (Ã¢Â€Â D h=2). Accelerators presently in operation, like the Large Hadron Collider (LHC) at CERN near Geneva, allow us to study collisions"
305,249,0.608,Quantum Computing for Everyone,"Feynman thought that one of the main applications of quantum computers would be to simulate quantum systems. Using quantum computers to study chemistry that belongs to the quantum world is a natural idea that has great potential. There are a number of areas where it is hoped that quantum computing will make important contributions. One of these is to understand how an enzyme, nitrogenase, used to make fertilizers actually works. The current method of producing fertilizers releases a significant amount of greenhouse gases and consumes considerable energy. Quantum computers could play a major role in understanding this and other catalytic reactions. There is a group at the University of Chicago that is looking into photosynthesis. The transfer of sunlight to chemical energy is a process that happens quickly and very efficiently. It is a quantum mechanical process. The long-term goal is to understand this process and then use it in photovoltaic cells. Superconductivity and magnetism are quantum mechanical phenomena. Quantum computers may help us understand them better. One goal is to develop superconductors that donÃ¢Â€Â™t need to be cooled to near absolute zero. The actual construction of quantum computers is in its infancy, but even with a few qubits it is possible to begin studying chemistry. IBM recently simulated the molecule beryllium hydride (BeH2) on a seven-qubit quantum processor. This is a relatively small molecule with just three atoms. The simulation does not use the approximations that are used in the classical computational approach. However, since IBMÃ¢Â€Â™s processor uses just a few qubits, it is possible to simulate the quantum processor using a classical computer. Consequently, everything that can be done on this quantum processor can be done classically. However, as processors incorporate more qubits we get to the point where it is no longer possible to simulate them classically. We will soon be entering a new era when quantum simulations are beyond the power of any classical computer. Now that we have seen some of the possible applications, we will briefly survey some of the ways that are being used to build quantum computers. Hardware To actually make practical quantum computers you need to solve a number of problems, the most serious being decoherenceÃ¢Â€Â”the problem of your"
235,126,0.604,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","12.9 Quantum Probabilities So far, quantum theory lacks probabilities. These will be introduced and compared to classical probabilities next. Indeed, for the sake of appreciating the novel features of quantum probabilities and correlations, as well as the (joint) expectations of quantum observables, a short excursion into classical probability theory is useful."
305,176,0.597,Quantum Computing for Everyone,"The inability to clone a qubit has many important consequences. We want to be able to back up files and send copies of files to other people. Copying is ubiquitous. Our everyday computers are based on von Neumann architecture, which is heavily based on the ability to copy. When we run a program we are always copying bits from one place to another. In quantum computing this is not possible for general qubits. So, if programmable quantum computers are designed they will not be based on our current architecture. At first, the fact that we cannot clone qubits seems like a serious drawback, but there are a couple of important comments that need to be made. Often we want to prevent copying. We want to secure our dataÃ¢Â€Â”we donÃ¢Â€Â™t want our communications to be tapped. Here, as we saw with Eve, the fact that we cannot clone qubits can be used to our advantage, preventing unwanted copies from being made. The second comment is so important it deserves its own section. Quantum Computation versus Classical Computation The qubits 0 and 1 correspond to the bits 0 and 1. If we run our quantum CNOT gate just using the qubits 0 and 1 , and not any superpositions, then the computation is exactly the same as running a classical CNOT gate with 0 and 1. The same is true of the quantum version of the Fredkin gate. Since the classical Fredkin gate is universal and the quantum Fredkin gate using just 0 and 1 is equivalent to the classical gate, we can see that a quantum circuit can calculate anything that can be calculated by a classical circuit. The no-cloning property may seem worrisome, but it doesnÃ¢Â€Â™t restrict us from doing classical computations in any way. This is a deep result. It shows that if we compare classical and quantum computation, we shouldnÃ¢Â€Â™t think of them as different types of computation. Quantum computation includes all of classical computation. It is the more general form of computation. The qubit is the basic unit of computation, not the bit. Now that we have seen some basic gates, we will start to connect them together to form circuits."
249,215,0.596,Advances in Proof-Theoretic Semantics (Volume 43.0),"For one thing, Ã¢ÂŠÂ— is presumably grounded upon a sort of our epistemic capacity to put symbols in parallel (inside and outside sequents) as discussed above. The epistemic capacity may be so fundamental that it plays fundamental rÃƒÂ´les in symbolic reasoning as well as many other cognitive practices; this will lead to a sort of epistemic account of admissibility of Ã¢ÂŠÂ— in the principle of categorical harmony. Another Ã¢Â€ÂœinformationalÃ¢Â€Â account of it seems possible as well. There are three fundamental questions: What propositions hold? Why do they hold? How do they hold? The first one is about truth and falsity, the second one about proofs, and the last one about the mechanisms of proofs. An answer to the last question must presumably include an account of the way how resources or assumptions for inference are used in proofs, or how relevant inferential information is used in proofs. And Ã¢ÂŠÂ— may be seen as a means to address that particular part of the third question. This is the informational account, which has some affinities with the view of linear logic as the logic of resources. Yet another Ã¢Â€ÂœphysicalÃ¢Â€Â account may be came up with. In recent developments of categorical quantum mechanics by Abramsky and Coecke (see Abramsky [1] and references therein), the capacities to put things in parallel as well as in sequence play vital rÃƒÂ´les in their so-called graphical calculus for quantum mechanics and computation, where parallel composition represents the composition of quantum systems (resp. processes), i.e., the tensor product of Hilbert spaces (resp. morphisms), which is crucial in quantum phenomena involving entanglement, such as the EinsteinPodolsky-Rosen paradox and the violation of the Bell inequality. In general, Ã¢ÂŠÂ— lacks diagonals and projections, unlike cartesian ÃƒÂ—, and this corresponds to the No-Cloning and No-Deleting theorems in quantum computation stating that quantum information can neither be copied nor deleted (note that diagonals Ã¢ÂˆÂ† : X Ã¢Â†Â’ X Ã¢ÂŠÂ— X copy information X , and projections p : X Ã¢ÂŠÂ— Y Ã¢Â†Â’ X delete information Y ). On the other hand, classical information can be copied and deleted as you like. So, the monoidal feature of Ã¢ÂŠÂ— witnesses a crucial border between classical and quantum information. To account for such quantum features of the microscopic world, we do need Ã¢ÂŠÂ— in the logic of quantum mechanics, and this would justify to add Ã¢ÂŠÂ— to primitive vocabularies. The physical account seems relevant to the well-known question Ã¢Â€ÂœIs logic empirical?Ã¢Â€Â, which was originally posed in the context of quantum logic, and has been discussed by Quine, Putnam, Dummett, and actually Kripke (see Stairs [24]). The need of multiplicative Ã¢ÂŠÂ— in the Ã¢Â€ÂœtrueÃ¢Â€Â logic of quantum mechanics is quite a recent issue which has not been addressed in the philosophy community yet, and this may have some consequences to both the traditional question Ã¢Â€ÂœIs logic empirical?Ã¢Â€Â and the present question Ã¢Â€ÂœWhy are substructural logical constants are so special?Ã¢Â€Â, as partly argued above. A more detailed analysis of these issues will be given somewhere else. Sambin et al. [19] present a novel method to introduce logical constants by what they call the reflection principle and definitional equalities, some of which are as follows: Ã¢Â€Â¢ ÃÂ• Ã¢ÂˆÂ¨ ÃÂˆ Ã¢ÂŠÂ¢ ÃÂ¾ iff ÃÂ• Ã¢ÂŠÂ¢ ÃÂ¾ and ÃÂˆ Ã¢ÂŠÂ¢ ÃÂ¾ . Ã¢Â€Â¢ ÃÂ•, ÃÂˆ Ã¢ÂŠÂ¢ ÃÂ¾ iff ÃÂ• Ã¢ÂŠÂ— ÃÂˆ Ã¢ÂŠÂ¢ ÃÂ¾ . Ã¢Â€Â¢ ÃÂ“ Ã¢ÂŠÂ¢ ÃÂ• Ã¢Â†Â’ ÃÂˆ iff ÃÂ“ Ã¢ÂŠÂ¢ (ÃÂ• Ã¢ÂŠÂ¢ ÃÂˆ)."
305,7,0.579,Quantum Computing for Everyone,"solve but also for the new ideas they introduce. These underlying ideas have been and are being incorporated into a new generation of algorithms. After looking at algorithms, we switch gears and briefly look at how quantum computation can be used to simulate quantum processes. Chemistry, at its most basic level, is quantum mechanical. Classical computational chemistry works by taking quantum mechanical equations and simulating them using classical computers. These simulations are approximations and ignore the fine details. This works well in many cases, but in some cases it doesnÃ¢Â€Â™t. In these cases you need the fine details, and quantum computers should be able to give them. This chapter also briefly looks at building actual machines. This is a very fast-growing area. The first machines are being offered for sale. There is even one machine available on the cloud that everyone can use for free. It looks likely that we will soon enter the age of quantum supremacy. (We explain what this means.) The book concludes with the realization that quantum computation is not a new type of computation but is the discovery of the true nature of computation."
26,31,0.552,Cognitive Supervision for Robot-Assisted Minimally Invasive Laser Surgery,"2.1 Physical Properties of Light Our understanding of the nature of light is based on the fact that it exhibits properties of both electromagnetic (EM) waves and elementary particles, this characteristic is known as the wave-particle duality [1]. First, we consider the description of light as EM waves; the terms light and EM radiation are used interchangeably throughout this dissertation. Light can be regarded as the perturbation produced by the interplay of mutually related electric and magnetic fields. Each pair of electric/magnetic fields is characterized by a common wavelength ÃÂ» and oscillate perpendicular with each other and at right angle to the direction of propagation, as shown in Fig. 2.1. In general, EM radiation is classified according to the range of wavelengths it contains. The EM spectrum covers all the possible wavelengths of EM radiation: a limited interval is shown in Fig. 2.2, ranging from longer wavelengths (Microwaves) to shorter (XRays). A fundamental physical property of EM waves is the frequency ÃÂ½, which relates to the wavelength through the relation c = ÃÂ½ Ã‚Â· ÃÂ», where c is the speed of EM waves in vacuum. The classic picture of light as EM waves can be revisited in the perspective of the quantum theory. In its simplest form, the theory describes light as the"
305,251,0.551,Quantum Computing for Everyone,"you obtain a Josephson junction.** These junctions are now used in physics and engineering to create sensitive instruments for measuring magnetic fields. For our purposes, the important fact is that the energy levels of the Cooper pairs in a superconducting loop that contains a Josephson junction are discrete and can be used to encode qubits. IBM uses superconducting qubits in its quantum computers. In 2016, IBM introduced a five-qubit processor that they have made available to everyone for free on the cloud. Anyone can design their own quantum circuit, as long as it uses five or fewer qubits, and run it on this computer. IBMÃ¢Â€Â™s aim is to introduce quantum computing to a wide audienceÃ¢Â€Â”circuits for superdense coding, for BellÃ¢Â€Â™s inequality, and a model of the hydrogen atom have all been run on this machine. A primitive version of Battleships has also been run, giving the coder the claim of constructing the first quantum computer multiplayer game. At the end of 2017, IBM connected a twenty-qubit computer to the cloud. This time it is not for education, but it is a commercial venture where companies can buy access. Google is working on its quantum computer. It also uses superconducting qubits. Google is expected to announce in the near future that it has a computer that uses 72 qubits. What is special about this number? Classical computers can simulate quantum computers if the quantum computer doesnÃ¢Â€Â™t have too many qubits, but as the number of qubits increases we reach the point where that is no longer possible. Google is expected to announce that it has reached or exceeded this number, giving them the right to claim quantum supremacyÃ¢Â€Â”the first time an algorithm has been run on a quantum computer that is impossible to run, or simulate, on a classical computer. IBM, however, is not giving up without a fight. Its team, using some innovative ideas, has recently found a way to simulate a 56-qubit system classically, increasing the lower bound on the number of qubits needed for quantum supremacy. As work continues on building quantum computers, we are likely to see spinoffs into other areas. Qubits, however we encode them, are sensitive to interactions with their surroundings. As we understand these interactions better we will be able to build better shields to protect our qubits, but we will also be able to design ways our qubits can measure their surroundings. ** Brian David Josephson received the Nobel Prize in physics for his work on how Cooper pairs can flow through a Josephson junction by quantum tunneling."
305,253,0.547,Quantum Computing for Everyone,"of C, but instead it might end up at the bottom of valley at A. The important observation in annealing is that the energy required to push the ball bearing up the hill and let it drop into valley B is much less than the energy needed to push the ball bearing up from B and let it drop into A. So, we shake the bucket with an energy level between these two values. The ball can move from A to B, but it cannot move back. After a while of shaking at this level, it will end up either at the bottom of A or B. But shaking at this level can send the ball from C to B. The next step is to shake it again, but less energetically, with enough energy to get it up the peak from B to C, but not enough to let it get back from C to B. In practice, you start shaking and gradually reduce the energy. This corresponds to gradually cooling your piece of metal in traditional annealing. The result is that the ball bearing ends up at the lowest point. You have found the absolute minimum of the function. Quantum annealing adds quantum tunneling. This is a quantum effect where the ball bearing can just appear on the other side of a hill. Instead of going over, it can go through. Instead of reducing the heights of hills the ball can climb, you reduce the length of the tunnels it can tunnel through. D-Wave has produced a number of commercially available computers that use quantum annealing for optimization problems. Initially, they were met with some skepticism about whether the computers actually used quantum tunneling, but now it is generally agreed that they do. There is still some question of whether the computers are faster than classical ones, but people are buying. Volkswagen, Google, and Lockheed Martin, among others, have all bought D-Wave machines. After this brief look at hardware, we turn to deeper questions. What does quantum computation tell us about us, the universe, and what computation is at its most fundamental level? Quantum Supremacy and Parallel Universes There are 8 possible three-bit combinations: 000, 001, 010, 011, 100, 101, 110, 111. The number 8 comes from 2 3 . There are two choices for the first bit, two for the second and two for the third, and we multiply these three 2s together. If instead of bits we switch to qubits, each of these 8 three-bit strings is associated with a basis vector, so the vector space is 8-dimensional. Exactly the same analysis tells us that if we have n qubits, then we will have"
305,21,0.534,Quantum Computing for Everyone,"not acting in the conventional ways that filters work. More light comes through three filters than comes through two! We will give a brief description of what is happening. Later we will see the mathematical model that describes both spin and polarization. Recall our quantum clock. We can ask if the hand is pointing at twelve, or we can ask if the hand is pointing at six. The information we gain from either question tells us which of the numbers 12 or 6 the hand is pointing to, but the Yes/No answers are reversed. For the polarized squares the analogous questions are asked by rotating the square by ninety degreesÃ¢Â€Â”not one hundred and eighty. The information we obtain is the same. The difference is that if the answer is yes, the photon passes through the filter and we can perform more measurements on it, but if the answer is no, the filter absorbs the photon, so we cannot ask it further questions. The first two experiments involved just two sheets and are telling us exactly the same thing: When we repeat a measurement, we get the same result. In both experiments we are measuring the polarization in the vertical and horizontal directions two times. In these experiments, the photons that pass through the first filter have vertical orientations. The first experiment, where the second filter also has vertical orientation, we are asking the question, Ã¢Â€ÂœIs the photon vertically polarized?Ã¢Â€Â twice and we receive the answer Ã¢Â€ÂœYesÃ¢Â€Â twice. In the second experiment, the second question is changed to Ã¢Â€ÂœIs the photon horizontally polarized?Ã¢Â€Â and receives the answer Ã¢Â€ÂœNo.Ã¢Â€Â Both experiments give us the same information, but the negative answer for the second question in the second experiment means that the photon is absorbed and so, unlike the first experiment, it is not available for further questioning. In the third experiment, the filter that has been rotated through fortyfive degrees is now measuring the polarization at angles of 45Ã‚Â° and 135Ã‚Â°. We"
235,96,0.531,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","11.2.6 Roadmap to Quantum Computing Quantum computing is about generalized states, which can be in a superposition of classical states; and about generalized permutations; that is, about bijections in complex vector spaces. For this it is sufficient to consider classical reversible computation, Ã¢Â€ÂœaugmentedÃ¢Â€Â with gates producing coherent superpositions of a classical bit (such as the Hadamard gate or quantum Fourier transforms) [371, 466]."
305,18,0.525,Quantum Computing for Everyone,"each time we do it the initial conditions vary slightly. These slight variations can change the outcome from heads to tails and vice versa. There is no real randomness in classical mechanics, just what is often called sensitive dependence to initial conditionsÃ¢Â€Â”a small change in the input can get amplified and produce an entirely different outcome. The underlying idea concerning randomness in quantum mechanics is different. The randomness is true randomness. The sequence NSSNNNSS Ã¢Â€Â¦ that we obtained from measuring spin in two directions is considered to be truly random, as we shall see. The sequence of coin tosses, HTTHHHTT Ã¢Â€Â¦ appears random, but the classical laws of physics are deterministic and this apparent randomness would disappear if we could make our measurements with infinite accuracy. At this stage it is natural to question this. Einstein certainly did not like this interpretation, famously saying that God does not play dice. CouldnÃ¢Â€Â™t there be a deeper theory? If we knew more information about the initial configurations of our electrons, couldnÃ¢Â€Â™t it be the case that the final results would no longer be random but completely determined? CouldnÃ¢Â€Â™t there be hidden variablesÃ¢Â€Â”once we know the values of these variables, the apparent randomness disappears? In what follows we will present the mathematical theory in which true randomness is used. Later we will return to these questions. We will describe a clever experiment to distinguish between the hidden variable and the true randomness hypotheses. This experiment has been performed several times. The outcomes have always shown that the randomness is real and that there is no simple hidden variable theory that can eliminate it. We started this chapter by saying that a qubit can be represented by the spin of an electron or the polarization of a photon. We will show how the models for spin and polarization are related. Photons and Polarization It is often said that we are not aware of the strange quantum phenomena because they only occur at incredibly small scales and are not apparent at the scales of our everyday life. There is some truth to this, but there is an experiment that is completely analogous to measuring spin of electrons that can be performed with very little apparatus. It concerns polarized light."
235,97,0.512,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","12.1 The Quantum Canon At the moment, there exists a loosely bundled canon of quantum rules subsumed under the term quantum mechanics or quantum theory. It includes reversible as well as irreversible processes, and is prima facie inconsistent. As already von Neumann [552, 554] and later Everett [30, 206, 545] noted, there cannot be any irreversible measurement process nested in a ubiquitous uniformly reversible evolution of the quantum state. Both von Neumann and Everett called the former, irreversible, discontinuous change the Ã¢Â€Âœprocess 1Ã¢Â€Â; and the latter, reversible, continuous, deterministic change the Ã¢Â€Âœprocess 2,Ã¢Â€Â respectively. Stated differently, there cannot exist any irreversible many-to-one measurement scenario (other than pragmatic fappness) in a reversible one-to-one environment. Hence, if one wants to maintain irreversible measurements, then (at least within the quantum formalism) one is faced with the following dilemma: either quantum mechanics must be augmented with some irreversible, many-to-one state evolution, thereby spoiling the ubiquitous, universal reversible one-to-one state evolution; or the assumption of the co-existence of a ubiquitous, uniform reversible one-to-one state evolution on the one hand with some irreversible many-to-one Ã¢Â€Âœwave function collapse,Ã¢Â€Â (by another wording, Ã¢Â€Âœreduction of the state vectorÃ¢Â€Â) throughout measurement on the other hand, yields a complete contradiction. How is such a situation handled in other areas? Every system of logic which is self-contradictory (inconsistent) Ã¢Â€Â“ such that a proposition as well as its negation is postulated; or can be derived from the postulates Ã¢Â€Â“ in particular, in a formal axiomatic system, is detrimental and disastrous. Because by the principle of explosion (Latin: ex falso quodlibet) any invocation of a statement as well as of its negation yields every proposition true. This can be motivated by supposing that both Ã¢Â€ÂœPÃ¢Â€Â as well as Ã¢Â€Âœnot PÃ¢Â€Â are true. Then the proposition Ã¢Â€ÂœP or anythingÃ¢Â€Â is true (because at least Ã¢Â€ÂœPÃ¢Â€Â is true). Now suppose that also Ã¢Â€Âœnot PÃ¢Â€Â holds. But then, in order for Ã¢Â€ÂœP or anythingÃ¢Â€Â to be true, Ã¢Â€ÂœanythingÃ¢Â€Â needs to be true. However, if anything is derivable, then such a system lacks any descriptive or predictive capacity. In this Ã‚Â© The Author(s) 2018 K. Svozil, Physical (A)Causality, Fundamental Theories of Physics 192, https://doi.org/10.1007/978-3-319-70815-7_12"
235,80,0.505,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","Indeed, already Sommerfeld had warned his students not to get into these issues, and Feynman [211, p. 129] predicted the Ã¢Â€Âœperpetual torment that results from [[the question]], Ã¢Â€Â˜But how can it be like that?Ã¢Â€Â™ which is a reflection of uncontrolled but utterly vain desire to see [[quantum mechanics]] in terms of an analogy with something familiar.Ã¢Â€Â Therefore he advised his audience, Ã¢Â€ÂœDo not keep saying to yourself, if you can possibly avoid it, Ã¢Â€Â˜But how can it be like that?Ã¢Â€Â™ because you will get Ã¢Â€Â˜down the drainÃ¢Â€Â™, into a blind alley from which nobody has yet escaped.Ã¢Â€Â But heresy has continued. Clauser [of the ClauserÃ¢Â€Â“HorneÃ¢Â€Â“ShimonyÃ¢Â€Â“Holt (CHSH) inequalities [145]], in a noteworthy paper [144], pointed out the dogmatism of Ã¢Â€Âœevangelical theoreticians . . . their ecumenical leadership, and especially given BohrÃ¢Â€Â™s strong leadership, the net legacy of their arguments is that the overwhelming majority of the physics community accepted BohrÃ¢Â€Â™s Ã¢Â€ÂœCopenhagenÃ¢Â€Â interpretation as gospel, and totally rejected EinsteinÃ¢Â€Â™s viewpoint.Ã¢Â€Â At some point Clauser got thrown out of the office by the impatient Feynman (who often liked to market himself as Ã¢Â€ÂœcoolÃ¢Â€Â). Ã¢Â€ÂœA very powerful . . . stigma began to develop within the physics community towards anyone who sacrilegiously was critical of quantum theoryÃ¢Â€Â™s fundamentals. . . . The net impact of this stigma was that any physicist who openly criticized or even seriously questioned these foundations (or predictions) was immediately branded as a Ã¢Â€Â˜quack.Ã¢Â€Â™ Ã¢Â€Â Clauser continues by noticing, Ã¢Â€ÂœTo be sure, there remained alive a minority of the theoryÃ¢Â€Â™s founders (notably Einstein, SchrÃƒÂ¶dinger, and de Broglie) who were still critical of the theoryÃ¢Â€Â™s foundations. These men were obviously not quacks. Indeed, they all had Nobel Prizes! Instead, gossip among physicists branded these men Ã¢Â€Â˜senile.Ã¢Â€Â™ Ã¢Â€Â As time passed by, another, more optimistic phase of the perception of quantum foundations followed, which, however, might not have sufficiently and critically reflected the previous evangelical theoreticiansÃ¢Â€Â™ orthodoxy. On the contrary, quantum mechanics has been marketed to the public and to policy makers alike as a hocuspocus type capacity [522]. This author believes [504] that interpretation is to the formalism what a scaffolding in architecture and building construction is to the completed building. Very often the scaffolding has to be erected because it is an indispensable part of the building process. Once the completed building is in place, the scaffolding is torn down and the opus stands in its own full glory. No need for auxiliary scaffold any more. But beware of those technicians who claim to be able to erect skyscrapers without any of those poles and planks! In addition, when it comes to claims of applicability of the formalism, and its ontological commitments, the suppression of semantic content in favour of mere syntax makes us vulnerable: in many ways the formalism could be extended to domains in which it cannot be applied safely and properly. Thereby, the resulting certifications, alleged capacities and predictions could be wrong. Hence, if it comes to utilize the formalism, interpretation serves not only as scaffolding, but also provides guiding principles and precautionary methods of evaluation and application."
305,94,0.497,Quantum Computing for Everyone,"The easiest way to remember this is by the following construction. Ã¯Â£Â® Ã¯Â£Â®b0 Ã¯Â£Â¹ Ã¯Â£Â¹ Ã¯Â£Â®a0 b0 Ã¯Â£Â¹ Ã¯Â£Â¯a0 Ã¯Â£Â¯ Ã¯Â£Âº Ã¯Â£Âº Ã¯Â£Â¯ Ã¯Â£Â® Ã¯Â£Â¹ Ã¯Â£Â® Ã¯Â£Â¹ Ã¯Â£Â¯ Ã¯Â£Â° b1 Ã¯Â£Â» Ã¯Â£Âº Ã¯Â£Â¯ a0 b1 Ã¯Â£Âº Ã¯Â£Â¯a Ã¯Â£Âº Ã¯Â£Â¯b Ã¯Â£Âº Ã¯Â£Â¯ Ã¯Â£Â®b0 Ã¯Â£Â¹ Ã¯Â£Âº Ã¯Â£Â¯ a1b0 Ã¯Â£Âº Ã¯Â£Â° 1Ã¯Â£Â» Ã¯Â£Â° 1Ã¯Â£Â» Ã¯Â£Â¯ 1 Ã¯Â£Â¯ Ã¯Â£ÂºÃ¯Â£Âº Ã¯Â£Â¯ Ã¯Â£Â° Ã¯Â£Â° b1 Ã¯Â£Â» Ã¯Â£Â» Ã¯Â£Â° a1b1 Ã¯Â£Â» Notice also that the subscripts follow the standard binary ordering: 00, 01, 10, 11. How Do You Entangle Qubits? This book is about the mathematics that underlies quantum computing. It is not about how to physically create a quantum computer. We are not going to spend much time on the details of physical experiments, but the question of how physicists create entangled particles is such an important one that we will briefly address it. We can represent entangled qubits by either entangled photons or electrons. Though we often say the particles are entangled, what we really mean is that the vector describing their states, a tensor in Ã¯ÂÂ’2 Ã¢ÂŠÂ— Ã¯ÂÂ’2 , is entangled. The actual particles are separate and, as we have just noted, can be very far apart. That said, the question remains: How do you go about creating a pair of particles whose state vector is entangled? First, we look at how physical experiments create entangled particles. Then we look at how quantum gates create entangled qubits. The most commonly used method at this time involves photons. The process is called spontaneous parametric down-conversion. A laser beam sends photons through a special crystal. Most of the photons just pass through, but some photons split into two. Energy and momentum must be conservedÃ¢Â€Â”the total energy and momentum of the two resulting photons must equal the energy and momentum of the initial photon. The conservation laws guarantee that the state describing the polarization of the two photons is entangled. In the universe, electrons are often entangled. At the start of the book we described Stern and GerlachÃ¢Â€Â™s experiment on silver atoms. Recall that"
213,360,0.494,Collider Physics Within The Standard Model : a Primer,"3.17 Limitations of the Standard Model No signal of new physics has been found, either by direct production of new particles at the LHC, or in the electroweak precision tests, or in flavour physics. Given the success of the SM, why are we not satisfied with this theory? Once the Higgs particle has been found, why donÃ¢Â€Â™t we declare particle physics closed? The reason is that there are both conceptual problems and phenomenological indications for physics beyond the SM. On the conceptual side the most obvious problems are that quantum gravity is not included in the SM and that the famous hierarchy (or naturalness or fine-tuning) problem remains open. Among the main phenomenological hints for new physics we can list coupling unification, dark matter, neutrino masses (discussed in Sect. 3.7), baryogenesis, and the cosmological vacuum energy. At accelerator experiments, the most plausible departure from the SM is the muon anomalous magnetic moment which, as discussed in Sect. 3.9, shows a deviation by about 3 , but some caution should be applied since a large fraction of the uncertainty is of theoretical origin, in particular that due to the hadronic contribution to lightÃ¢Â€Â“light scattering [245]. The computed evolution with energy of the effective SM gauge couplings clearly points towards the unification of the electroweak and strong forces (GUTs) at scales of energy MGUT  1015 Ã¢Â€Â“1016 GeV [315], which are close to the scale of quantum gravity, MPlanck  1019 GeV. The crossing of the three gauge couplings at a single"
235,105,0.493,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","12.4 Representation of Observables A non-degenerate quantum observable is identified with all properties of a state, less the two-valued measure, and formalized by (i) an orthonormal basis of Hilbert space; (ii) a set of mutually orthogonal projection operators corresponding to an orthonormal basis called context; (iii) a maximal observable, or maximal operator, or maximal transformation whose spectral sum contains the set of mutual orthogonal projection operators from the aforementioned basis; (iv) a maximal Boolean subalgebra [249, 300, 376, 420] of the quantum logic also called block. This correspondence (ex measure) between a quantum state and a quantum observable is reflected in the formalism itself: Any maximal observable can be decomposed into a spectral sum, with the orthogonal projection operators forming a corresponding orthonormal basis, or, synonymously, by a context or a block."
192,144,0.481,Tales of Research Misconduct : a Lacanian Diagnostics of integrity Challenges in Science Novels,"Oppenheimer was born in New York in 1904, but studied in Europe, where he became a Ã¢Â€Âœsecond waveÃ¢Â€Â quantum physicist, following in the footsteps of Ã¢Â€Âœquantum giantsÃ¢Â€Â of the first generation such as Bohr, Heisenberg, SchrÃƒÂ¶dinger, Pauli and Dirac (Bird and Sherwin 2005/2006, p. 78). Eventually, he achieved iconic status as the most famous scientist of his era, due to his leading role in the Manhattan project,"
235,10,0.48,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)",What if There Are No Laws? Emergence of Laws . . . . . . . . . . . . . Mythological Roots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Physical Indeterminism in Vienna at the Dawn of Quantum Mechanics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contemporary Representations . . . . . . . . . . . . . . . . . . . . . . . . Provable Impossibility to Prove (In)Determinism . . . . . . . . . . Potential Misperceptions by Over-interpretation . . . . . . . . . . .
305,8,0.477,Quantum Computing for Everyone,"All computations involve inputting data, manipulating it according to certain rules, and then outputting the final answer. For classical computations, the bit is the basic unit of data. For quantum computations, this unit is the quantum bitÃ¢Â€Â”usually shortened to qubit. A classical bit corresponds to one of two alternatives. Anything that can be in exactly one of two states can represent a bit. Later we will see various examples, which include the truth or falsity of a logical statement, a switch being in the on or off position, and even the presence or absence of a billiard ball. A qubit, like a bit, includes these two alternatives, butÃ¢Â€Â”quite unlike a bitÃ¢Â€Â”it can also be in a combination of these two states. What does this mean? What exactly is a combination of two states, and what are physical objects that can represent qubits? What is the quantum computation analog to the switch? A qubit can be represented by the spin of an electron or the polarization of a photon. This, though true, does not seem particularly helpful as spins of electrons and polarizations of photons are not things that most of us have knowledge about, let alone experience with. LetÃ¢Â€Â™s start with a basic introduction to describe spin and polarization. To do this we describe the foundational experiment performed by Otto Stern and Walther Gerlach on the spin of silver atoms. In 1922, Niels BohrÃ¢Â€Â™s planetary model described the current understanding of atoms. In this model an atom consisted of a positive nucleus orbited by negative electrons. These orbits were circular and were constrained to certain radii. The innermost orbit could contain at most two electrons. Once this was filled, electrons would start filling the next level, where at most eight electrons could be held. Silver atoms have 47 electrons. Two of"
311,2853,0.47,The Physics of the B Factories,"three-body BB Ã¢ÂˆÂ— ÃÂ€+B Ã¢ÂˆÂ— BÃÂ€ channel was not predicted theoretically and is not yet understood. The channel BBÃÂ€ was not observed and its production is probably suppressed due to the 0Ã¢ÂˆÂ’ quantum numbers of all three final particles produced from the 1Ã¢ÂˆÂ’ initial state, which results in two P -wave amplitudes."
249,216,0.465,Advances in Proof-Theoretic Semantics (Volume 43.0),"As these cases show, definitional equalities are quite similar to adjointness conditions in categorical harmony (when they are formulated as bi-directional rules), even though Sambin et al. do not mention category theory at all. Especially, in the case of additive connectives, their definitional equivalences are exactly the same as the bi-directional rules induced by the corresponding adjunctions. There are crucial differences, however. Among them, the following fact should be emphasised: Ã¢Â€Â¢ Definitional equalities do not always imply adjointness, partly due to what they call the Ã¢Â€ÂœvisibilityÃ¢Â€Â condition, which requires us to restrict context formulae in sequent-style rules of inference (categorically, this amounts to restricting so-called Frobenius reciprocity conditions). Ã¢Â€Â“ For example, implication is not necessarily a right adjoint of conjunction in the system of Ã¢Â€Âœbasic logicÃ¢Â€Â derived via their guiding principles. This deviation from adjointness actually seems to be inevitable for Sambin et al., because they want to include Birkhoff-von NeumannÃ¢Â€Â™s quantum logic with some concept of implication as a structural extension of their basic logic; however, quantum implication (if any) cannot be a right adjoint of conjunction, due to the nondistributive nature of it, which is essential in Birkhoff-von NeumannÃ¢Â€Â™s quantum logic to account for superposition states in quantum systems. In contrast, categorical harmony cannot allow for any sort of non-adjoint implication. Is this a good feature or not? It depends on whether such implication counts as genuine implication, and so on our very conception of logical constants. The categorical logicianÃ¢Â€Â™s answer would be no: for example, Abramsky [1] asserts that Birkhoff-von NeumannÃ¢Â€Â™s quantum logic is considered to be Ã¢Â€Âœnon-logicÃ¢Â€Â because it does not have any adequate concept of implication (on the other hand, categorical quantum logic is said to be Ã¢Â€Âœhyper-logicÃ¢Â€Â). Finally, it should be noted that Schroeder-Heister [21] compares the framework of Sambin et al. [19] with his framework of definitional reflection, and that Bonnay and Simmenauer [4] proposes to exploit the idea of Sambin et al. [19] in order to remedy the aforementioned defect (the Ã¢Â€ÂœblonkÃ¢Â€Â problem) of DoÃ…Â¡enÃ¢Â€Â™s double-line approach in [8, 9]."
305,241,0.461,Quantum Computing for Everyone,"can factor a product of two large primes in polynomial time. But, on the other hand, nobody has a proof that such an algorithm doesnÃ¢Â€Â™t exist. This is where Shor enters the picture. He constructed a quantum algorithm that does factor a product of large prime numbers. The algorithm belongs to class BQP, which means that it works with bounded error in polynomial time. One thing that needs to be emphasized is that we are no longer talking about query complexity. We are not assuming that we can ask questions of an oracle. We are counting the total number of steps or, equivalently, the time needed to get from the beginning to the end of the computation. Shor is giving a concrete algorithm for each step. The fact that the algorithm belongs to BQP means that if it is implemented it becomes feasible to factor large numbers, and, more important, it means that if the quantum circuit can be actually constructed, then RSA encryption is no longer secure. ShorÃ¢Â€Â™s Algorithm ShorÃ¢Â€Â™s algorithm involves a significant amount of mathematics. We will just give a short and somewhat vague description of the quantum part. An important part of the algorithm is a gate that is called the quantum Fourier transform gate. This can be thought of as a generalization of the Hadamard gate. In fact, for one qubit the quantum Fourier transform gate is exactly H. Recall that we used a recursive formula that told us how to get from the matrix for H Ã¢ÂŠÂ— nÃ¢ÂˆÂ’1 to the matrix for H Ã¢ÂŠÂ— n . Similarly, we can give a recursive formula for the quantum Fourier transform matrix. The major difference between H Ã¢ÂŠÂ— n and the quantum Fourier matrix is that the entries in the latter case are generally complex numbersÃ¢Â€Â”more specifically, they are complex roots of unity. Recall that the entries for H Ã¢ÂŠÂ— n are either 1 or Ã¢ÂˆÂ’1. These are the two possible square roots of 1. When we look for fourth roots of 1 we again just get Ã‚Â±1 if we are using real numbers, but we get two other roots if we use the complex numbers. In general, 1 has n complex nth roots. The quantum Fourier transform matrix on n qubits involves all the 2 n th complex roots of unity. SimonÃ¢Â€Â™s algorithm was based on the properties of H Ã¢ÂŠÂ— n . It used interference, the amplitudes were either 1 or Ã¢ÂˆÂ’1, which meant that when we added terms, the kets either canceled or reinforced one another. Shor realized that a similar idea applied to the quantum Fourier matrix, only now the amplitudes are given not just by 1 and Ã¢ÂˆÂ’1, but also by all the 2 n th complex roots"
8,219,0.457,"Melting Hadrons, Boiling Quarks: From Hagedorn Temperature to Ultra-Relativistic Heavy-Ion Collisions at CERN: With a Tribute to Rolf Hagedorn","11.2 Discovery of the Onset of Deconfinement The quark model of hadron classification proposed by Gell-Mann and Zweig in 1964 starts a 15 years-long period in which sub-hadronic particles, quarks and gluons, were discovered and a theory of their interactions, quantum chromodynamics (QCD) was established. In parallel, conjectures were formulated concerning the existence and properties of matter consisting of sub-hadronic particles, soon called the QGP and studied in detail within the QCD [7]. Ivanenko and Kurdgelaidze [8], Itoh [9] and Collins and Perry [10] suggested that quasi-free quarks may exist in the centre of neutron stars. Many physicists started to speculate that the QGP can be formed in nucleusÃ¢Â€Â“nucleus collisions at high energies and thus it may be discovered in laboratory experiments. Questions"
235,139,0.457,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","12.9.5 Why Classical Correlation Polytopes? A caveat seems to be in order from the very beginning: in what follows correlation polytopes arise from classical (and quasi-classical) situations. The considerations are relevant for quantum mechanics only insofar as the quantum probabilities could violate classical bounds; that is, if the quantum tests violote those bounds by Ã¢Â€Âœlying outsideÃ¢Â€Â of the classical correlation polytope. There exist at least two good reasons to consider (correlation) polytopes for bounds on classical probabilities, correlations and expectation values: 1. they represent a systematic way of enumerating the probability distributions and deriving constraints Ã¢Â€Â“ BooleÃ¢Â€Â™s conditions of possible experience Ã¢Â€Â“ on them; 2. one can be sure that these constraints and bounds are optimal in the sense that they are guaranteed to yield inequalities which are best criteria for classicality. It is not evident to see why, with the methods by which they have been obtained, BellÃ¢Â€Â™s original inequality [41, 42] or the ClauserÃ¢Â€Â“HorneÃ¢Â€Â“ShimonyÃ¢Â€Â“Holt inequality [145] should be Ã¢Â€ÂœoptimalÃ¢Â€Â at the time they were presented. Their derivation involve estimates which appear ad hoc; and it is not immediately obvious that bounds based on these estimates could not be improved. The correlation polytope method, on the other hand, offers a conceptually clear framework for a derivation of all classical bounds on higher-order distributions."
311,2756,0.453,The Physics of the B Factories,"the incident photon and ensures the processes originates from real photon collisions. Similar requirements are also useful in the single-tag cases described below to ensure a small Q2 for the untagged photon. 22.1.4 Single-tag measurements When one of the scattered electrons is detected, we refer to these two-photon processes as single-tag modes. In the single-tag process, we can probe the structure of the real photon or a hadron with a high-Q2 photon; this process is very useful for studies of hadron and QCD physics such as meson transition form factors (Brodsky and Lepage, 1981). The Q2 of the virtual photon is determined by measuring the scattering angle and energy of the recoil electron with the following Lorentz-invariant formula: Q2 = 4Eb E Ã¢Â€Â² sin2 ,"
372,1582,0.452,Interferometry and Synthesis in Radio Astronomy : Third Edition (Edition 3),"This classical model predicts neither the resonance frequency nor the absolute amplitude of the oscillation. A full treatment of the problem requires the application of quantum mechanics. The proper quantum-mechanical calculation for a system with many resonances yields a result that closely resembles Eq. (13.60) [e.g., Loudon (1983)]: n m e2 X 4"" 2 m(0 i # 2 ! #0i2 C j#'i"
305,238,0.449,Quantum Computing for Everyone,"It is, of course, impossible to predict the long-term impact of quantum computing with any accuracy. If we look back at the birth of the modern computer in the 1950s, nobody could have predicted how much computers would change society and how dependent we would become on them. There are well-known quotes from computer pioneers proclaiming that the world would only need a handful of computers and that nobody would ever need a computer in their home. These quotes are out of context. The authors were generally referring to specific types of computers, but the impression they give, though exaggerated, is true. Initially computers were massive, had to be in air-conditioned rooms, and were not very reliable. Today, I have a laptop, a smartphone, and a tablet. All three are far more powerful than the first computers. I think that even visionaries like Alan Turing would be amazed at the extent to which computers have thoroughly permeated all levels of society. Turing did discuss chess playing and artificial intelligence, but nobody predicted that the rise of e-commerce and social media would come to dominate so much of our lives. Quantum computing is now in its infancy, and the comparison to the first computers seems apt. The machines that have been constructed so far tend to be large and not very powerful, and they often involve superconductors that need to be cooled to extremely low temperatures. Already there are some people saying that there will be no need for many quantum computers to be built and that their impact on society will be minimal. But, in my opinion, these views are extremely shortsighted. Although it is impossible to predict what the world will be like in fifty years time, we can look at the dramatic changes in quantum computing over the last few years and see the direction in which it is heading. It might be some time before we get powerful universal quantum computers, but even before we"
8,406,0.449,"Melting Hadrons, Boiling Quarks: From Hagedorn Temperature to Ultra-Relativistic Heavy-Ion Collisions at CERN: With a Tribute to Rolf Hagedorn","18.3 From Distinguishable Hadrons to SBM The beginning of a new idea in physics often seems to hang on a very fine thread: was anything lost when Ã¢Â€Â˜Thermodynamics of Distinguishable ParticlesÃ¢Â€Â™ remained unpublished? And what would Hagedorn do after withdrawing his first limitingtemperature paper? My discussion of the matter with Hagedorn suggests that his vision at the time of how limiting temperature could be justified evolved very rapidly. Presenting his final insight was what interested Hagedorn and motivated his work. Therefore, he opted to work on the more complete theoretical model. While the withdrawal of the old, and the preparation of an entirely new paper seemed to be the right path to properly represent the evolving scientific understanding, todayÃ¢Â€Â™s perspective is different. In particular the insight that the appearance of a large number of different hadronic states allows to effectively side-step the quantum physics nature of particles within statistical physics became essentially invisible in the ensuing work. Few scientists realize that this is a key property in the SBM, and the fundamental cause allowing the energy content to increase without an increase in temperature, as Hagedorn explains in the withdrawal note, see also the end of Sects. 17.2 and 19.1. The loss of relevance of quantum physics in hot hadronic matter is the scientific fact that we lost sight of after Ã¢Â€Â˜Distinguishable ParticlesÃ¢Â€Â™ was withdrawn. To the best of my knowledge the dense, strongly interacting hadronic gas is the only physical system where this happens. Normally, the greater the density of particles, the greater the role of quantum physics. After surfacing briefly in HagedornÃ¢Â€Â™s withdrawn Ã¢Â€Â˜Thermodynamics of Distinguishable ParticlesÃ¢Â€Â™ paper, this finding faded from view. This indeed was a new idea in physics hanging on a very fine thread which ripped. On the other hand, the Hagedorn limiting temperature lived on. Within a span of only 90 days between the withdrawal of his manuscript, and the date of his new CERN-TH preprint, Hagedorn formulated the Statistical Bootstrap Model. Its salient feature is that the exponential mass spectrum arises from the principle that"
305,98,0.449,Quantum Computing for Everyone,"1 Ã¯Â£Â®1 Ã¯Â£Â¹ Ã¯Â£Â®1 Ã¯Â£Â¹ 1 Ã¯Â£Â® 0 Ã¯Â£Â¹ Ã¯Â£Â® 0 Ã¯Â£Â¹ 2 Ã¯Â£Â¯Ã¯Â£Â°1 Ã¯Â£ÂºÃ¯Â£Â» Ã¯Â£Â¯Ã¯Â£Â°1 Ã¯Â£ÂºÃ¯Â£Â» 2 Ã¯Â£Â¯Ã¯Â£Â°0 Ã¯Â£ÂºÃ¯Â£Â» Ã¯Â£Â¯Ã¯Â£Â°0 Ã¯Â£ÂºÃ¯Â£Â» We will often use entangled qubits in this state. It has the very nice property that if Alice and Bob measure in the standard basis, they will both get Ã¯Â£Â®1 Ã¯Â£Â¹ Ã¯Â£Â®0 Ã¯Â£Â¹ Ã¯Â£Â¯0 Ã¯Â£Âº , corresponding to 0, or they will both get Ã¯Â£Â¯1 Ã¯Â£Âº , corresponding to 1. The Ã¯Â£Â° Ã¯Â£Â» Ã¯Â£Â° Ã¯Â£Â» two cases are equally probable.** We examine this further with a quantum clock analogy. Entangled Quantum Clocks Recall the quantum clock metaphor. We can ask only about whether the hand is pointing in a certain direction, and the clock will answer either that it is or that it is pointing in the opposite direction. Ã¯Â£Â®1 Ã¯Â£Â¹ Ã¯Â£Â®0 Ã¯Â£Â¹ We let the vector Ã¯Â£Â¯ Ã¯Â£Âº correspond to pointing to twelve, and Ã¯Â£Â¯ Ã¯Â£Âº Ã¯Â£Â°0 Ã¯Â£Â» Ã¯Â£Â°1 Ã¯Â£Â» to pointing to six. Consider a pair of clocks in the entangled state 1 Ã¯Â£Â®1 Ã¯Â£Â¹ Ã¯Â£Â®1 Ã¯Â£Â¹ 1 Ã¯Â£Â® 0 Ã¯Â£Â¹ Ã¯Â£Â® 0 Ã¯Â£Â¹ . In fact, consider one hundred pairs of clocks, 2 Ã¯Â£Â¯Ã¯Â£Â°1 Ã¯Â£ÂºÃ¯Â£Â» Ã¯Â£Â¯Ã¯Â£Â°1 Ã¯Â£ÂºÃ¯Â£Â» 2 Ã¯Â£Â¯Ã¯Â£Â°0 Ã¯Â£ÂºÃ¯Â£Â» Ã¯Â£Â¯Ã¯Â£Â°0 Ã¯Â£ÂºÃ¯Â£Â» each pair of which is in this state. Suppose that you have one hundred of these clocks, and I have the hundred partners. We are both going to ask the same question repeatedly: Is the hand pointing toward twelve? In the first scenario, we donÃ¢Â€Â™t contact one another. We just go through the clocks one at a time and ask the question. Each time the clock will answer either yes or no. We will write 1 if it is yes, and 0 if it is no. After we have finished asking questions, we have a string of 0s and 1s. I analyze my string and you analyze yours. Both strings are a random sequence of 0s and 1s. Both digits occur about the same number of times. We now contact one another and compare strings. Both your string and my string are identical. In all one hundred places the strings agree. In the second scenario, we again each have one hundred clocks. This time we make an agreement that you will measure first. You will ask your question on the hour, and I will ask mine half an hour later. During these halfhours between our questions you will call me and tell me what my clockÃ¢Â€Â™s ** In the next chapter, we will see that Alice and Bob donÃ¢Â€Â™t need to stick to the standard basis. If they both use the same orthonormal basis, no matter which one, they will still get exactly the same results."
65,130,0.443,Handbook of Ocean Wave Energy,"Diffraction occurs when waves meet a surface-piercing obstacle such as an island, headland or breakwater. Without diffraction the waves would continue to travel in the same direction leaving a region of calm water in the lee of the obstacle. However, diffraction means that the waves will bend so that there are waves behind the obstacle. The amount of diffraction depends on the wavelength, with the longer waves diffracting to a greater extent than the shorter waves. If there is more than one source of diffraction, e.g. either side of an island, then a diffraction pattern may form where there are areas of increased and decreased wave height due to constructive and destructive interference. Although diffraction means that waves will occur on the leeward side of an obstacle, generally these waves will be smaller than the incident waves (except in the special case of constructive interference) so the wave resource behind an obstacle, is likely to be smaller than the seaward wave resource."
213,14,0.44,Collider Physics Within The Standard Model : a Primer,"between two particles with total center of mass energy up to 2E  2pc . 7Ã¢Â€Â“14 TeV. These machines can, in principle, study physics down to distances Ã‚Âx & 10 18 cm. Thus, on the basis of results from experiments at existing accelerators, we can indeed confirm that, down to distances of that order of magnitude, electrons, quarks, and all the fundamental SM particles do not show an appreciable internal structure, and look elementary and pointlike. We certainly expect quantum effects in gravity to become important at distances Ã‚Âx  10 33 cm, corresponding to energies up to E  MPlanck c2  1019 GeV, where MPlanck is the Planck mass, related to NewtonÃ¢Â€Â™s gravitational constant by GN D Ã¢Â€Âc=MPlanck . At such short distances the particles that so far appeared as pointlike may well reveal an extended structure, as would strings, and they may be described by a more detailed theoretical framework for which the local quantum field theory description of the SM would be just a low energy/large distance limit. From the first few moments of the Universe, just after the Big Bang, the temperature of the cosmic background gradually went down, starting from kT  MPlanck c2 , where k D 8:617  10 5 eV K 1 is the Boltzmann constant, down to the present situation where T  2:725 K. Then all stages of high energy physics from string theory, which is a purely speculative framework, down to the SM phenomenology, which is directly accessible to experiment and well tested, are essential for the reconstruction of the evolution of the Universe starting from the Big Bang. This is the basis for the ever increasing connection between high energy physics and cosmology."
305,208,0.44,Quantum Computing for Everyone,"know: If i = 0, the qubit is 0 . If i = 1, the qubit is 1 . If i = 2, the qubit is Ã¢ÂˆÂ’ 1 . If i = 3, the qubit is Ã¢ÂˆÂ’ 0 . If we now measure the qubit in the standard basis, we will get 0 if i is either 0 or 3, and we will get 1 if i is either 1 or 2. Of course, f 0 and f 3 are the constant functions and f1 and f 2 are the balanced. So, if after measuring we get 0, we know with certainty that the original function was constant. If we get 1, we know that the original function was balanced. Consequently, we need to ask the oracle only one question versus two. For DeutschÃ¢Â€Â™s problem there is therefore a slight speedup using a quantum algorithm. This algorithm has no real practical applications, but, as we noted earlier, it was the first example of proving that there are quantum algorithms faster than classical ones. We will look at two other quantum algorithms in detail. They both involve inputting a number of qubits and then sending each one through a Hadamard gate. We introduce a little more mathematics to help keep the description of many qubits in superposition from becoming too unwieldy. The Kronecker Product of Hadamard Matrices We know that the matrix for the Hadamard gate is given by Ã¯Â£Â® 1 Ã¯Â£Â¯ 2 Ã¯Â£Â¯ 1 Ã¯Â£Â°Ã¯Â£Â¯ 2"
311,1752,0.433,The Physics of the B Factories,"For years the most favored option has been to assume that the X has J P C = 1++ ; a DÃ¢ÂˆÂ—0 D molecule with L = 0 would have these quantum numbers. Such a deuteron-like state, bound by pion exchange, was discussed by Tornqvist (1994), and proposed as a model of the X(3872) structure by Swanson (2004b), and many subsequent investigators. However, definitive arguments against the 2Ã¢ÂˆÂ’+ assignment have been lacking. The spin-2 hypothesis has been considered implausible from early studies onwards: the 2Ã¢ÂˆÂ’+ decay to ÃÂ³J/ÃÂˆ is not an electric dipole transition, and so should be suppressed;110 for the charmonium state with these quantum numbers, the 1 1D2 or ÃÂ·c2 , the isospin-violating transition ÃÂ·c2 Ã¢Â†Â’ ÃÂ€ + ÃÂ€ Ã¢ÂˆÂ’ J/ÃÂˆ would be expected to have a small rate, relative to isospin-conserving ÃÂ·c2 Ã¢Â†Â’ ÃÂ€ + ÃÂ€ Ã¢ÂˆÂ’ ÃÂ·c (Olsen, 2005). However the BABAR study of X(3872) Ã¢Â†Â’ J/ÃÂˆÃÂ‰ (del Amo Sanchez, 2010c) reported a (relatively weak) preference for J P C = 2Ã¢ÂˆÂ’+ , and there has since been a renewed discussion of this possibility (e.g. Burns, Piccinini, Polosa, and Sabelli, 2010; Faccini, Pilloni, and Polosa, 2012; Hanhart, Kalashnikova, Kudryavtsev, and Nefediev, 2012). If the X(3872) has quantum numbers J P C = 2Ã¢ÂˆÂ’+ , it should be produced by two-photon fusion (see Chapter 22)."
65,156,0.43,Handbook of Ocean Wave Energy,"couplings between wave components, but in this case they are between sets of three wave components that cause energy transfer via non-linear interactions. When the waves are dispersive these interactions cannot be created, which is why they only occur in very shallow water. The effect of triad wave-wave interactions is to generate a second peak in the wave spectrum at twice the frequency of the original spectrum, which is bound to the main frequency peak in the sense that it travels with the same phase velocity. Unfortunately, currently third generation wave models are unable to correctly model these bound waves, and the triad wave-wave interaction source term is estimated based on the wave spectrum and water depth; however, these source terms have been found to be reasonable approximations in most cases. Ã¢Â€Â¢ The Ã¯Â¬Ânal source term typically included in wave models is the depth-induced wave breaking (surf-breaking) source term. This source term typically assumes that a Ã¯Â¬Âxed proportion of the energy in any wave is lost when it breaks. Thus it is necessary to make an estimate on the proportion of waves that break at any particular water depth for any particular wave spectrum. This may be done by making some assumptions about the distribution of wave heights and the relative water depth in which these waves will break. Perhaps surprisingly, laboratory observations suggest that the spectral shape is not affected by wave breaking and so the energy removed due to wave breaking, and thus the strength of the depth-induced wave breaking source term, is typically assumed to be proportional to the wave energy spectrum, with the coefÃ¯Â¬Âcient of proportionality dependent on the proportion of breaking waves."
103,122,0.429,Solar Particle Radiation Storms Forecasting and Analysis : The Hesperia Horizon 2020 Project and Beyond (Volume 444.0),"For simplicity, the turbulence in the vicinity of the shock is often assumed to be magnetostatic, but the DSA theory can be formulated assuming that the scattering centers are propagating AlfvÃƒÂ©n waves. This simply modifies the velocities of the scattering centers."
217,478,0.429,Finite Difference Computing With Pdes : a Modern Software Approach,"2.14 Applications of Wave Equations This section presents a range of wave equation models for different physical phenomena. Although many wave motion problems in physics can be modeled by the standard linear wave equation, or a similar formulation with a system of first-order equations, there are some exceptions. Perhaps the most important is water waves: these are modeled by the Laplace equation with time-dependent boundary conditions at the water surface (long water waves, however, can be approximated by a standard wave equation, see Sect. 2.14.7). Quantum mechanical waves constitute another example where the waves are governed by the SchrÃƒÂ¶dinger equation, i.e., not by a standard wave equation. Many wave phenomena also need to take nonlinear effects into account when the wave amplitude is significant. Shock waves in the air is a primary example. The derivations in the following are very brief. Those with a firm background in continuum mechanics will probably have enough knowledge to fill in the details, while other readers will hopefully get some impression of the physics and approximations involved when establishing wave equation models."
235,102,0.424,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","consisting perhaps in passing it through various kinds of sorting apparatus, such as slits and polarimeters, the system being left undisturbed after the preparation.Ã¢Â€Â SchrÃƒÂ¶dinger, in his Generalbeichte [452, Footnote 1, p. 845] (general confession) of 1935, pointed out that [539, Sect. 6, p. 328] Ã¢Â€ÂœActually [[in truth]]Ã¢Â€Â”so they sayÃ¢Â€Â” there is intrinsically only awareness, observation, measurement. If through them I have procured at a given moment the best knowledge of the state of the physical object that is possibly attainable in accord with natural laws, then I can turn aside as meaningless any further questioning about the Ã¢Â€Âœactual state,Ã¢Â€Â inasmuch as I am convinced that no further observation can extend my knowledge of itÃ¢Â€Â”at least, not without an equivalent diminution in some other respect (namely by changing the state, see below).Ã¢Â€Â1 No further justification is given here. A quantum state is thus identified with a maximal co-measurable (or co-preparable) entity. This is based on complementarity: not all conceivable quantum physical properties are co-measurable. (For classical models of complementarity, see, for instance, MooreÃ¢Â€Â™s discrete-valued automaton analogue of the Heisenberg uncertainty principle [373, 446, 499], as well as WrightÃ¢Â€Â™s generalized urn model [578], and partition logics in general [511].) In the Hilbert space formulation of quantum mechanics a state is thus formalized by two entities; some structural elements, and a measure on these elements [520]: (I) equivalently, (i) an orthonormal basis of Hilbert space; (ii) a set of mutually orthogonal projection operators corresponding to an orthonormal basis called context; (iii) a maximal observable, or maximal operator, or maximal transformation whose spectral sum contains the set of mutual orthogonal projection operators from the aforementioned basis; (iv) a maximal Boolean subalgebra [249, 300, 376, 420] of the quantum logic also called a block; (II) as well as a two-valued (0-1) measure (or, used synonymously, valuation, or truth assignment) on all the aforementioned entities, singling out or selecting one of them such that this measure is one on exactly one of them, and zero on all the others."
65,496,0.42,Handbook of Ocean Wave Energy,"To begin with, a general appreciation of the hydrodynamic behaviour of the device should be made. This can in practice be done in regular waves and without any PTO loading, by making various short tests (0.5Ã¢Â€Â“2 min each) where the wave height is maintained constant and the wave periods are each time incremented. This should be repeated for constant wave periods and increasing wave heights, and it could for example be used to identify the resonance frequency of the structure or of the wave activated body and show the range of effect of the wave conditions. A similar approach could possibly be used to investigate the influence of different conÃ¯Â¬Âgurations, for example if the device has an adaptable geometry, weight or floating level. After the hydrodynamic behaviour, the sensitivity and relevant working range of the PTO loading adjustment system have to be assessed. In this case, the load should be increased again in batches (0.5Ã¢Â€Â“2 min each) for a couple of the tested wave conditions. In practice, this can be done by incrementing the load between each batch by 10 % of its full range and repeated for the smallest, one or two medium and the largest sea states. Although these tests are not crucial, they often lead to a signiÃ¯Â¬Âcant gain in time. Note that in order to maintain the same wave energy content in between regular and irregular waves, the signiÃ¯Â¬Âcant wave height (Hm0) from the irregular waves has to be divided by Ã¢ÂˆÂš2 to obtain the wave height for the regular waves, while maintaining the same wave period (T = Te). However, in the case that the response or performance of the device is mostly dependent on the wave period, it might be beneÃ¯Â¬Âcial to match the wave period in regular waves with Tp, as this is the dominant wave period in irregular waves. The actual performance assessment is based on long-crested irregular waves, having a speciÃ¯Â¬Âc wave spectral shape (e.g. JONSWAP spectrum with Ã‰Â£ = 3.3). Each individual IW lab test should have a length of 1000 peak wave periods (for statistical robustness), which should take about 20Ã¢Â€Â“30 min, depending on the scale. Moreover, in each wave condition the PTO load needs to be optimised for optimal energy production (as presented in Fig. 9.12). Ideally, an exact reproduction of the waves should be performed in between those tests. Depending on the complexity"
65,516,0.418,Handbook of Ocean Wave Energy,"Note that the surge excursion of the WEC will be strongly affected by wave groups, even more than from one large individual wave. It is therefore important to repeat the same design wave conditions with different wave trains."
8,166,0.413,"Melting Hadrons, Boiling Quarks: From Hagedorn Temperature to Ultra-Relativistic Heavy-Ion Collisions at CERN: With a Tribute to Rolf Hagedorn","Abstract In this contribution I recall how people working in the late 1960s on the dual resonance model came to the surprising discovery of a Hagedorn-like spectrum, and why they should not have been surprised. I will then turn to discussing the Hagedorn spectrum from a string theory viewpoint (which adds a huge degeneracy to the exponential spectrum). Finally, I will discuss how all this can be reinterpreted in the new incarnation of string theory through the properties of quantum black holes."
391,277,0.411,Ocean-Atmosphere Interactions of Gases and Particles,"of the IR and wave slope imagery data should clarify   the relationship between microbreaking and S2 . The correlation of kw with wave slope has shown results similar to the correlation of kw with AB. JaÃŒÂˆhne   et al. (1987) observed a correlation of kw with S2 for both fetch-limited and unlimited fetch cases, and Frew (1997) and Bock et al. (1999) showed the correlation was independent of surfactant for the unlimited fetch case. Zappa et al. (2004) suggest that the reason kw correlates with wave slope is that microbreaking is the wave-related mechanism controlling gas transfer and   contributes to S2 .   The greatest contribution of microbreaking to S2 occurs in areas not directly affected by active microbreaking. The density of capillary waves present during the microscale wave breaking process is less than for non-breaking waves. Specifically, the capillary waves on the forward face of the bore-like crest become extremely short during the most intense initiation of microscale breaking when steep slopes occupy the dimpled bore-like crest. The wave field slope characteristics are constantly evolving throughout the growth process of the wave packet from the moment capillary waves are formed to the moment that microscale wave breaking occurs. The wave evolution up to microbreaking incorporates contributions of slopes from waves of all scales. Microscale wave breaking is of short duration and merely one component of this wind-wave cycle. Dense packets of capillary-gravity waves ubiquitous in regions not affected by microbreaking dominate the contribution to the total mean-square wave slope. Since the bore-like crest produces the signature of breaking detected as AB in the infrared imagery, only the steep slopes associated with the front of the actively breaking crest and the wake of a microscale breaker   influence S2 . Capillary waves have been shown to   contribute significantly to S2 (Bock et al. 1999) and are observed to be transient during the microscale breaking process. The fact that capillary waves are damped by surfactants, coupled with the fact that the smallest scale waves have been shown to correlate with the gas transfer velocity, suggests that capillary waves characterise the importance of the wave field to gas transfer. The potential for capillary waves as a direct mechanism for gas transfer has been demonstrated both experimentally (Saylor and Handler 1997) and theoretically (Coantic 1986; Szeri 1997; Witting 1971). However,"
213,16,0.409,Collider Physics Within The Standard Model : a Primer,"one (or occasionally more than one) photon emitted by one electron and reabsorbed by the other. Similarly, in theN SM there are 8 gluons associated with the SU.3/ colour generators, while for SU.2/ U.1/ there are four gauge bosons W C , W , Z 0 , and Ã¢Â€Â. Of these, only the gluons and the photon Ã¢Â€Â are massless, because the symmetry induced by the other three generators is actually spontaneously broken. The masses of W C , W , and Z 0 are very large indeed on the scale of elementary particles, with values mW  80:4 GeV and mZ  91:2 GeV, whence they are as heavy as atoms of intermediate size, like rubidium and molybdenum, respectively. In the electroweak theory, the breaking of the symmetry is of a particular type, referred to as spontaneous symmetry breaking. In this case, charges and currents are as dictated by the symmetry, but the fundamental state of minimum energy, the vacuum, is not unique and there is a continuum of degenerate states that all respect the symmetry (in the sense that the whole vacuum orbit is spanned by applying the symmetry transformations). The symmetry breaking is due to the fact that the system (with infinite volume and an infinite number of degrees of freedom) is found in one particular vacuum state, and this choice, which for the SM occurred in the first instants of the life of the Universe, means that the symmetry is violated in the spectrum of states. In a gauge theory like the SM, the spontaneous symmetry breaking is realized by the Higgs mechanism [189, 236, 243, 261] (described in detail in Sect. 1.7): there are a number of scalar (i.e., zero spin) Higgs bosons with a potential that produces an orbit of degenerate vacuum states. One or more of these scalar Higgs particles must necessarily be present in the spectrum of physical states with masses very close to the range so far explored. The Higgs particle has now been found at the LHC with mH  126 GeV [341, 345], thus making a big step towards completing the experimental verification of the SM. The Higgs boson acts as the mediator of a new class of interactions which, at the tree level, are coupled in proportion to the particle masses and thus have a very different strength for, say, an electron and a top quark. The fermionic matter fields of the SM are quarks and leptons (all of spin 1/2). Each type of quark is a colour triplet (i.e., each quark flavour comes in three colours) and also carries electroweak charges, in particular electric charges C2=3 for up-type quarks and 1=3 for down-type quarks. So quarks are subject to all SM interactions. Leptons are colourless and thus do not interact strongly (they are not hadrons) but have electroweak charges, in particular electric charges 1 for charged leptons (e ,  and Ã‚Â£ ) and charge 0 for neutrinos (Ã„Âe , Ã„Â and Ã„ÂÃ‚Â£ ). Quarks and leptons are grouped in 3 Ã¢Â€ÂœfamiliesÃ¢Â€Â or Ã¢Â€ÂœgenerationsÃ¢Â€Â with equal quantum numbers but different masses. At present we do not have an explanation for this triple repetition of fermion families: t t t Ã„ÂÃ‚Â£ c c c Ã„Â u u u Ã„Âe (1.1) b b b Ã‚Â£ s s s  d d d e The QCD sector of the SM (see Chap. 2) has a simple structure but a very rich dynamical content, including the observed complex spectroscopy with a large"
305,235,0.406,Quantum Computing for Everyone,"We can now state SimonÃ¢Â€Â™s algorithm. First we decide on a bound on the probability of error and calculate the value N. Again, the number N does not depend on n. We can use the same value of N in each case. We run SimonÃ¢Â€Â™s circuit n + N times. The number of queries is n + N , which, since N is fixed, is a linear function of n. We make the assumption that our system of n + N equations contains n Ã¢ÂˆÂ’ 1 independent vectors. We could be wrong, but the probability of being wrong is less than the bound that we chose. Then we solve the system of n + N equations using a classical algorithm. The time taken will be quadratic in n + N , but because N is a constant, this can be expressed as a quadratic in n. The algorithm as a whole contains the quantum part that takes linear time added to the classical part that takes quadratic time, giving quadratic time overall. Problems that quantum algorithms can solve in polynomial time with the probability of error within some bound are denoted BQP (for bounded-error quantum polynomial time). SimonÃ¢Â€Â™s algorithm shows the problem belongs to BQP for query complexity. We showed that the classical algorithm, in the worst case, took 2 nÃ¢ÂˆÂ’1 + 1 function evaluationsÃ¢Â€Â”this is exponential in n, not polynomial, so the problem definitely does not belong to P. It can also be shown that even if we allow a bound on the probability of error the algorithm is still exponential, so the problem does not belong to BPP. We say that SimonÃ¢Â€Â™s problem separates BPP and BQP for query complexity. Quantum Algorithms We started this chapter by describing how in many popular descriptions the speedup provided by quantum algorithms is said to come solely from quantum parallelismÃ¢Â€Â”the fact that we can put the input into a superposition"
65,109,0.403,Handbook of Ocean Wave Energy,"which can have a signiÃ¯Â¬Âcant impact on the power generation of a WEC as discussed above. This second issue is sometimes reduced by producing multiple scatter diagrams for a particular site, which are used to separate the wave climate by peak wave direction or season, but there is clearly a practical limit to the number and range of scatter diagrams that can be produced and used effectively. Another representation of the wave climate that is often used is the wave rose as shown in Fig. 3.10. A wave rose is a graphical representation of the average wave power or SigniÃ¯Â¬Âcant Wave Height from different directional sectors. Similar to a set of wave roses may be produced based on season in order to provide additional information that may be useful in understanding the wave climate, especially where different meteorological conditions are responsible for different wave conditions at different times of the year."
389,147,0.401,Impacts of the Fukushima Nuclear Accident on Fish and Fishing Grounds,"Fig. 6.5 (a) Relationship between wave direction, significant wave heights, and wave periods for autumn 2012. (b) Weather map by the JMA for two high wave periods: left, high wave period HW2 (type 1); right, high wave period HW5 (type 2). Wave directions are illustrated based on the wave map by the JMA"
372,1955,0.395,Interferometry and Synthesis in Radio Astronomy : Third Edition (Edition 3),"17.6.3 Optical Intensity Interferometer The use of the intensity interferometer for optical measurements on stars was demonstrated by Hanbury Brown and Twiss (1956a), shortly after the success of the radio intensity interferometer described in Sects. 1.3.7 and 17.1. At that time, the possibility of coherence between photons in different light rays from the same source was questioned, and the physical basis and consistency with quantum mechanics is explained by Hanbury Brown and Twiss (1956c) and Purcell (1956). The laboratory demonstration of the correlation of intensity fluctuations of light by Hanbury Brown and Twiss (1956b) led to the appreciation of the phenomenon of photon bunching and to the broader development of quantum statistical studies and to their application to particle beams as well as electromagnetic radiation (Henny et al. 1999). In the optical intensity interferometer, a photomultiplier tube at the focus of each telescope mirror replaces the RF and IF stages and the detectors of the radio instrument. The photomultiplier outputs are amplified and fed to the inputs of the correlator. The optical intensity interferometer is largely insensitive to atmospheric phase fluctuations, as explained for the radio case in Sect. 17.1. The size of the lightgathering apertures is therefore unrestricted by the scale size of the irregularities. Also, it is not necessary that the reflecting mirrors produce a diffraction-limited image, and their accuracy need only be sufficient to deliver all the light to the photomultiplier cathodes. This is fortunate since the low sensitivity mentioned earlier for the radio case necessitates the use of large light-gathering areas. Hanbury Brown (1974) gave an analysis of the response of the optical instrument and showed that it is proportional to the square of the visibility modulus as in the radio case. Either a correlator or a photon coincidence counter can be used to combine the photomultiplier outputs. The intensity interferometer constructed at Narrabri, Australia (Hanbury Brown et al. 1967; Hanbury Brown 1974), used two 6.5-m-diameter reflectors and a bandwidth of 60 MHz for the signals at the correlator inputs. The resulting limiting magnitude of +2.5 enabled measurements of 32 stars to be made. Davis (1976) has discussed the relative merits of the intensity interferometer and modern implementations of the Michelson interferometer for development of more sensitive instruments."
65,305,0.393,Handbook of Ocean Wave Energy,"Wave drift forces are due to non-symmetric wave loading on bodies, to interaction between waves of different wave period and to interaction between the wave oscillation and oscillation of the body itself. These effects give a constant or low-frequent excitation of the system. This excitation may become important if the waves are large, or if its period of oscillation coincides with resonance frequencies introduced by the mooring system. In some locations, tidal and ocean currents give signiÃ¯Â¬Âcant forces on the wave energy converters. Slack-line mooring systems are usually designed to provide a positioning force to counteract the horizontal wave drift and current forces, whereas taut-line systems may additionally counteract wave-frequent excitation in one or more modes. Unless the mooring lines are used as force reference for the energy conversion, the mooring system is usually designed to give as little influence on the wave absorption process as possible. Low-frequent resonance in the mooring system may be detrimental for the lines in storm conditions or even in normal operating conditions if not properly designed. (See Chap. 7 on mooring)"
391,271,0.391,Ocean-Atmosphere Interactions of Gases and Particles,"tension has a significant impact on the breaking of waves shorter than 1 m (Tulin and Landrini 2001). Instead, the bore-like crest of the microbreaker can propagate for a considerable distance without significant change of shape. Microbreakers inherently lose a significant portion of their height and dissipate their energy during the breaking. Laboratory experiments in wind-wave tunnels provide a growing body of evidence that turbulence generated by microscale wave breaking is the dominant mechanism for air-water gas transfer at low to moderate wind speeds. Laboratory measurements indicate that a wave-related mechanism regulates gas transfer because the transfer velocity correlates with   the total mean-square wave slope, S2 (JaÃŒÂˆhne et al. 1987). Wave slope characterises the stability of water waves (e.g. Longuet-Higgins et al. 1994) and certain limiting values of slope are typically used to detect and define wave breaking (e.g. Banner 1990). Therefore, JaÃŒÂˆhne et al. (1987) have argued that wave slope is representative of the near-surface turbulence produced by microscale wave breaking. Microbreaking is widespread over the oceans, and Csanady (1990) has proposed that the specific manner by which it affects kw is the thinning of the aqueous mass boundary layer (MBL) by the intense surface divergence generated during the breaking process. Infrared (IR) techniques have been successfully implemented in the laboratory to detect this visually"
305,23,0.391,Quantum Computing for Everyone,"random. They are computed by some deterministic function, and if you know the function and the initial seed input, you can calculate exactly the same string. There are no classical computer algorithms that generate truly random strings. Thus, already we can see that quantum computations have some advantages over classical ones. Before we start to describe other quantum computations we need to develop a precise mathematical model that describes what happens when we measure spin in various directions. This is started in the next chapter where we study linear algebraÃ¢Â€Â”the study of the algebra associated with vectors."
65,111,0.39,Handbook of Ocean Wave Energy,"In the preceding sections, the wave spectra has been discussed without any clear deÃ¯Â¬Ânition of exactly what it represents. Representation of the ocean using a wave spectrum assumes that it is possible to represent the water surface as the sum of sinusoidal waves with a range of frequencies, amplitudes and directions. The variation of the wave energy with frequency (and direction) is called the wave spectrum. Figure 3.11 shows an illustration of this super-positioning of waves, together with an example of a typical wave spectrum."
8,307,0.388,"Melting Hadrons, Boiling Quarks: From Hagedorn Temperature to Ultra-Relativistic Heavy-Ion Collisions at CERN: With a Tribute to Rolf Hagedorn","technical defect, so far not functioned quite right: one has usually introduced only the few lowest mass particles in self-consistent bootstrap circles; the more stable particles one takes, the better the particle bootstrap should function, so all stable particles need to be included, after this is done there can no longer be an objection. On the lighter side, we recall that only when MÃƒÂ¼nchhausen has yanked very strongly at his hair, was he able to move, and then not only himself, but taking with him the swamp, and the EarthÃ¢Â€Â”the whole world. (c) It is noteworthy that in the realm of todayÃ¢Â€Â™s particle physics (or High Energy PhysicsÃ¢Â€Â”we have seen that these two terms mean the same) no evidence is found that the existing principles of relativity and of quantum theory need to be corrected or extended in any way; even though we are in a new situation. (d) After my report, it might seem as if the end of elementary particle physics has come. However, what I have presented arises from speculative hypothesis. And even if everything were correct, we would not come to an end, but find ourselves at a new beginning: in all the above considerations only strong interactions were considered, and not in terms of particular form of forces, but only in terms of the ever-changing composition of the Ã¢Â€Âœelementary particles,Ã¢Â€Â and we have never spoken about their individual characteristicsÃ¢Â€Â”therefore our conclusions were completely independent of all these additional known particle properties. Thus we have described the average behavior, the statistical behavior. But the main focus of high energy physics is precisely on all these more detailed individual properties of the new particles and the forces acting between them. And there is the question, why these forces? In this regard we stand at a new beginning. (e) Many physicists still believe in the possibility of exploring deeper and further to ever more elementary building blocks. One must follow this line experimentally and cannot be misled by intellectually satisfying speculation into believing that the scientific question is settled. (f) I have tried to describe everything in everyday language, in words, that we physicists use, when we talk about such things at tea. To you, the reader, everything must look very mysterious, especially the claim that each Ã¢Â€Âœelementary particleÃ¢Â€Â in different ways has been created from all the others. Take it to be Ã¢Â€Â˜asif-speechÃ¢Â€Â™, as a blurry image of what can be formulated much more precisely with the help of mathematics or technical jargon. With this report I also, as an aside, hope I have made you understand why we high energy physicists yearn so much for the next European 300-GeV accelerator, which will now probably be built."
275,348,0.386,Foundations of Trusted Autonomy,"12.2 Compatible and Incompatible States The conjunction fallacy does not mean that people always judge the probability of a conjunction as higher than each of its conjuncts. That would indeed be counter to probability theory. Just imagine that the choice between (a) and (b) was presented without the story about Linda. Then one would expect everyone with some notion of probability to choose (a) over (b), as confirmed in [35]. But when asked the question after first hearing the story, even people schooled in statistics fall victim to the conjunction fallacy. Why is this? The question generated a host of publications with possible explanations over the last several decades (see [19] for an overview). Among the many kinds of explanations offered, two stand out in particular. One assumes that words such as Ã¢Â€Â˜andÃ¢Â€Â™ and Ã¢Â€Â˜probabilityÃ¢Â€Â™ are misunderstood by the participants, or at least not understood in their formal interpretation. The other assumes a reasoning bias. A recent overview [30] concludes that the latter has the best support of the two. But this answer begs the question: if there is a reasoning bias, where does that reasoning bias originate? Indeed, we are not satisfied with just knowing there is such a bias, rather we would like to describe how that bias unfolds as a cognitive process. To do so, let us formulate the participantsÃ¢Â€Â™ judgements as the outcome of a decision process. The explanations in the literature almost invariably involve two competing states, one in which Linda is a bankteller, and another where she is a feminist. To most participants in the experiment these states are not compatible, and whether bias or reasoning, each can in principle tip the scale in favor of one state or the other. In order to make headway, we have to take a closer look at the notion of compatible and incompatible states. In this presentation we will formulate states in the language of quantum cognition. Especially for the reader who is not already familiar with this approach, we will first recall some concepts from quantum mechanics. One such concept is the (formal) notion of compatible and incompatible states. Incompatibility lies at the heart of HeisenbergÃ¢Â€Â™s famous uncertainty principle. It holds that when we are certain about a quantum particleÃ¢Â€Â™s momentum, we are necessarily uncertain about its position, and vice versa. Position and momentum are therefore called incompatible states. On the other hand, again given the momentum of that particle, we can still measure its kinetic energy with certainty, momentum and kinetic energy thus being compatible states."
235,49,0.384,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","m = m 1 = m 2 , we would obtain h(m, m) = ÃÂ´(h(m, m)), thereby again clearly contradicting our definition of ÃÂ´. In summary, there is a limit to self-inspection, as long as one deals with systems of sufficiently rich phenomenology. One of the assumptions has been that there is no empirical self-exploration and self-examination without changing the sub-system to be measured. Because in order to measure a subsystem, one has to interact with it; thereby destroying at least partly its original state. This has been formalized by the introduction of a Ã¢Â€Âœdiagonal-switchÃ¢Â€Â function ÃÂ´ : P Ã¢ÂˆÂ’Ã¢Â†Â’ P without a fixed point. In classical physics one could argue that, at least in principle, it would be possible to push this kind of disturbance to arbitrary low levels, thereby effectively and for all practical purposes (fapp) eliminating the constraints on, and limits from, self-observation. One way of modelling this would be a double pendulum; that is, two coupled oscillators, one of them (the subsystem associated with the Ã¢Â€Âœobserved objectÃ¢Â€Â) with a Ã¢Â€Âœvery largeÃ¢Â€Â mass, and the other one of them (the subsystem associated with the Ã¢Â€ÂœobserverÃ¢Â€Â or the Ã¢Â€Âœmeasurement apparatusÃ¢Â€Â) with a Ã¢Â€Âœvery smallÃ¢Â€Â mass. In quantum mechanics, unless the measurement is a perfect replica of the preparation, or unless the measurement is not eventually erased, this possibility is blocked by the discreteness of the exchange of at least one single quantum of action. Thus there is an insurmountable quantum limit to the resolution of measurements, originating in self-inspection."
65,140,0.382,Handbook of Ocean Wave Energy,The Ã¯Â¬Ârst three wave measuring instruments described above are deployed at the location of interest and use a time-series analysis to produce the wave spectrum. The duration used to deÃ¯Â¬Âne the wave spectrum depends on a number of competing
65,465,0.382,Handbook of Ocean Wave Energy,"Note that all the tank tests related to power performance and structural and mooring loads need to be performed in irregular waves. Regular waves should only be used to characterise the device or to calibrate the system or numerical model (see Chap. 10), as it does not represent a realistic marine environment. In order to have a decent statistical ground, the duration of a test in irregular waves should include a minimum of 1000 waves (of the predominant wave period Tp). The environmental parameters that can have an influence on the power performance and on the maximal structural and mooring forces can be of many kinds, for example (non-exhaustive) (see Chap. 3): Ã¢Â€Â¢ Water depth, as it has a strong influence on the wave steepens, wave celerity and wave direction Ã¢Â€Â¢ The wave spectrum, which can be composed of different wave components coming from different storms (this deÃ¯Â¬Ânes the content of the irregular waves) Ã¢Â€Â¢ Directional spreading (deÃ¯Â¬Ânes the direction related to the wave spectrum) Ã¢Â€Â¢ Water currents (which can result e.g. from the wind, tides or near-shore effects and can have an influence on the motion, directionality and loads on the WEC) Ã¢Â€Â¢ Wind (can have an influence on the motion, directionality and loads on the Besides the environmental parameters, other parameters might have an influence on the wave conditions such as the disposition of the wave energy converters array."
372,1737,0.377,Interferometry and Synthesis in Radio Astronomy : Third Edition (Edition 3),"The wave emerging from the screen is crinkled; that is, the amplitude is unchanged, but the phase is no longer constant and has random fluctuations with rms deviation '). The wave can therefore be decomposed into an angular spectrum of waves propagating with a variety of angles. The full width of the angular spectrum, &s , can be estimated by imagining that the random medium consists of refracting wedges that tilt the wavefront by the amount Ã‹Â™')(=2# over a distance a. Thus, &s D re (2 'ne"
311,2417,0.376,The Physics of the B Factories,"Ã¢Â€Â“ The ÃÂ›c (2625) does not decay to the kinematicallyallowed ÃÂ£c (2455)0 ÃÂ€ + final state, since this would require a D-wave decay: (1Ã¢ÂˆÂ’ , 3/2Ã¢ÂˆÂ’ ) Ã¢Â†Â’ (1+ , 3/2+ )(0Ã¢ÂˆÂ’ ). + Ã¢ÂˆÂ’ Instead, it decays to the 3-body final state ÃÂ›+ c ÃÂ€ ÃÂ€ via a P -wave transition: (1 , 3/2 ) Ã¢Â†Â’ (0 , 1/2 )(0Ã¢ÂˆÂ’ )(0Ã¢ÂˆÂ’ ). Table 19.4.3. Possible low-lying excited states in HQET, classiÃ¯Â¬Âed according to the spin-alignment of the two light quarks, the spin-parity of the light degrees of freedom j p , and the spinparity of the baryon J P . Diquark spin"
65,379,0.374,Handbook of Ocean Wave Energy,"In Table 7.7 there is a summary of results from the gradually more sophisticated calculations. First one can note thatÃ¢Â€Â”in this caseÃ¢Â€Â”the simplest wave-drift estimate gives 40 times as large value as the one founded on diffraction theory. This is important in relation to the wind and current force. The Morison wave force for a regular sinusoidal wave is very dependent on the assumed wave period, while the Morison approach for irregular waves gives some better signiÃ¯Â¬Âcance, however some 20 % overestimation. Shaded values will be used in the design as they are considered as most realistic."
65,95,0.373,Handbook of Ocean Wave Energy,"Figure 3.3 shows the global variation in the annual average omni-directional wave power density. This Ã¯Â¬Âgure shows that the main areas of wave energy resource occur in bands across the Northern and Southern hemispheres, with less energetic regions close to the equator and poles. However, as discussed in more depth in Sect. 3.3, the annual average omni-directional wave power density does not include signiÃ¯Â¬Âcant amounts of information that are vital to determining the utility of a particular wave energy resource for a particular wave energy converter. It is possible to produce a range of other Ã¯Â¬Âgures that show how other important factors vary across the globe, and some of these factors have been reported by others [3, 4]; however, the speciÃ¯Â¬Âcity of individual wave energy converters means that it is not possible to be highly prescriptive regarding the appropriate important factors. Indeed, as discussed in Sect. 3.3, particular care must be taken when reducing the wave climate"
65,568,0.372,Handbook of Ocean Wave Energy,"is not a common approach. Wave-to-wire tools are designed to model the operational regime of WECs (i.e. during power production) where a linear (or partially non-linear) wave/device hydrodynamic interaction is fairly valid. In general, the nonlinear behaviour of WECs under extreme wave conditions is not properly represented in wave-to-wire tools. Therefore, combining wave-to-wire and dynamic mooring models does not allow the full capabilities of the dynamic model to be exploited. Moreover, usually most WECs need to enter a survival mode (with no energy production) in extreme wave conditions in order to avoid structural damage which, to some extent, decreases the usefulness of wave-to-wire models since their main feature is to assess the energy conversion efÃ¯Â¬Âciency."
65,357,0.371,Handbook of Ocean Wave Energy,"This is the largest possible mean wave drift force on a floating body per unit width of structure. For a floating 2D body, however, not all the energy will be reflected and the body will be set in motion and radiate energy up-wave and down-wave. If we denote the amplitude of the combined reflected and back-radiated wave by r and the amplitude of the combined transmitted and down-wave radiated wave by t, then a momentum approach will give Fd Ã‚Â¼"
8,204,0.37,"Melting Hadrons, Boiling Quarks: From Hagedorn Temperature to Ultra-Relativistic Heavy-Ion Collisions at CERN: With a Tribute to Rolf Hagedorn","10.2 Critical Behavior of Hadronic Matter Quantum chromodynamics (QCD) gauge theory is an excellent tool for description of single hadronic events in vacuum. However, for the dense and hot hadronic matter the most reliable theoretical results, based on first principles, can be obtained only through lattice gauge theory calculations. In particular, a phase transition or crossover phenomena are expected. This critical behavior is related to peculiarities in standard lattice QCD quantities as the Polyakov loop or susceptibilities. From the other side, a surprisingly simple resonance gas model provides a good description of particle yields in the relativistic heavy ion collisions in the broad energy range [2, 3]. The clue to this result is in the exponential-like behavior of the"
372,83,0.367,Interferometry and Synthesis in Radio Astronomy : Third Edition (Edition 3),"and optical experience has provided valuable precedents to the theory of radio interferometry. As shown in Fig. 1.4, beams of light from a star fall upon two apertures and are combined in a telescope. The resulting stellar image has a finite width and is shaped by effects that include atmospheric turbulence, diffraction at the mirrors, and the bandwidth of the radiation. Maxima in the light intensity resulting from interference occur at angles & for which the difference "" in the path lengths from the star to the point at which the light waves are combined is an integral number of wavelengths at the effective center of the optical passband. If the angular width of the star is"
65,106,0.367,Handbook of Ocean Wave Energy,"To understand how the ocean waves may influence the performance of a wave energy converter, it is useful to consider the temporal, directional and spectral characteristics of the ocean waves and how these may influence the relationship between the average omni-directional wave power and the average power generation. Firstly, the temporal characteristic of a wave climate is how the sea-states that make up a wave climate vary in time as illustrated in Fig. 3.7 for the signiÃ¯Â¬Âcant wave height. In general, the more consistent the wave climate is, the more attractive it becomes (for a particular average wave power) because the WEC and power generating plant can remain closest to its optimal operating conditions and thus maximise the system efÃ¯Â¬Âciency. However, the sea-states will vary due to changes in the metrological conditions that generate the winds and associated waves. Not surprisingly, the stability of metrological conditions varies across the world so that the wave climate is more consistent in some locations than others. This variability may be primarily associated with daily, seasonal and/or annual variations in the sea-states, each of which will have a slightly different impact on the power generation and its utility. Thus, it is clear that for all locations the temporal characteristics are an important element of the wave climate, which can result in different power generations for the same average incident wave power."
65,160,0.366,Handbook of Ocean Wave Energy,"3. Barstow, S., et al.: WorldWaves wave energy resource assessments from the deep ocean to the coast. In: 8th European Wave and Tidal Energy Conference Uppsala, Sweden (2009) 4. SI Ocean: Resource MappingÃ¢Â€Â”Work Package 2. DHI (2014) 5. Gunn, K., Stock-Williams, C.: Quantifying the global wave power resource. Renew. Energy 44(0), 296Ã¢Â€Â“304 (2012) 6. Dean, R.G., Dalrymple, R.: Water Wave Mechanics for Engineers and Scientists. World ScientiÃ¯Â¬Âc Publishing Ltd., Singapore (1991) 7. Le MÃƒÂ©hautÃƒÂ©, B.: Introduction to Hydrodynamics and Water Waves. Springer, New York (1976) 8. Whittaker, T., Folley, M.: Nearshore oscillating wave surge converters and the development of oyster. Philos. Trans. R. Soc. A 370, 345Ã¢Â€Â“364 (2012) 9. Folley, M., Whittaker, T.J.T., Henry, A.: The effect of water depth on the performance of a small surging wave energy converter. Ocean Eng. 34(8Ã¢Â€Â“9), 1265Ã¢Â€Â“1274 (2007) 10. IEC/TS 62600-101: Wave energy resource assessment and characterisation, Marine EnergyÃ¢Â€Â” Wave, tidal and other water current converters (2015) 11. Massel, S.R.: Ocean Surface Waves: Their Physics and Prediction, 2nd edn. World ScientiÃ¯Â¬Âc Publishing, Singapore (2013) 12. Pierson, W., Moskowitz, L.: A proposed spectral form for fully developed wind seas based on the similarity theory of S.A. Kitaigorodskii. J. Geophys. Res. 69, 5181Ã¢Â€Â“5203 (1964) 13. Hasselmann, K., et al.: Measurement of wind-wave growth and swell decay during the joint North Sea wave project (JONSWAP). Dtsch. Hydrogr. (1973) 14. Battjes, J.A.: Surf similarity. In: 14th International Conference on Coastal Engineering. Copenhagen, Denmark (1974) 15. Komar, P.D.: Beach Processes and Sedimentation, 2nd edn. Prentice-hall (1998) 16. Folley, M., Whittaker, T.J.T.: Analysis of the nearshore wave energy resource. Renew. Energy 34(7), 1709Ã¢Â€Â“1715 (2009) 17. Folley, M., Elsaesser, B., Whittaker, T.: Analysis of the wave energy resource at the European Marine Energy Centre. In: Coasts, Marine Structures and Breakwaters Conference. ICE, Edinburgh (2009) 18. Tucker, M.J., Pitt, E.G.: Waves in Ocean Engineering. Elsevier (2001) 19. Datawell: Datawell Waverider Reference Manual (2009) 20. Howell, G.L.: Shallow water directional wave gages using short baseline pressure arrays. Coast. Eng. 35, 85Ã¢Â€Â“102 (1998) 21. Work, P.A.: Nearshore directional wave measurements by surface-following buoy and acoustic Doppler current proÃ¯Â¬Âler. Ocean Eng. 35(8Ã¢Â€Â“9), 727Ã¢Â€Â“737 (2008) 22. Wyatt, L.R.: High frequency radar applicatoins in coastal monitoring, planning and engineering. Aust. J. Civil Eng. 12(1), 1Ã¢Â€Â“15 (2014) 23. Siddons, L.A., Wyatt, L.R., Wolf, J.: Assimilation of HF radar data into the SWAN wave model. J. Mar. Syst. 77(3), 312Ã¢Â€Â“324 (2009) 24. Mackay, E.B.L., Retzler, C.: Wave energy resource assessment using satellite altimeter data. In: 27th International Conference on Offshore Mechanics and Arctic Engineering. Estoril, Portugal (2008) 25. Bayram, A., Larson, M.: Wave transformation in the nearshore zone: comparison between a boussineq model and Ã¯Â¬Âeld data. Coast. Eng. 39, 149Ã¢Â€Â“171 (1999) 26. Porter, D.: The mild-slope equations. J. Fluid Mech. 494, 51Ã¢Â€Â“63 (2003) 27. Holthuijsen, L.H.: Waves in Oceanic and Coastal Waters. Cambridge University Press, Cambridge (2007)"
65,292,0.365,Handbook of Ocean Wave Energy,"interference between the reflected and the generated wave, it is important that both the phase (timing) and the amplitude (strength) of the generated wave are chosen properly. This is crucial for any wave energy device, but the phase and amplitude may not always be easily controllable. See Sect. 6.1.8 for further treatment of this issue."
65,356,0.365,Handbook of Ocean Wave Energy,"If this wave is blocked by a vertical wall, a wave with the same amplitude, r = a, will be reflected in the opposite direction and the momentum acting on the wall, or mean drift force will become Fd Ã‚Â¼ Iin"
65,104,0.364,Handbook of Ocean Wave Energy,"Traditionally, sea-states have been characterised using a representative wave height, which before any method for recording waves existed was based solely on observation. That is, the representative wave height was deÃ¯Â¬Âned as the wave height as reported by an Ã¢Â€Âœexperienced observerÃ¢Â€Â, whom we must assume had spent many years listening to the estimates of other experienced observers so that a relatively consistent estimate of the wave height could be made. This was called the SigniÃ¯Â¬Âcant Wave Height, symbolized by Hs. However, it is clear that the accuracy of this method is highly dependent on the experience of the observer and as such subject to signiÃ¯Â¬Âcant error. When it became possible to record the variation in the water surface elevation, an alternative method of deÃ¯Â¬Âning wave height was developed. With a record of the variation in the water surface elevation, it is possible to measure the height of individual waves and thus produce a more reliable estimate of the wave height. In order to be consistent with historical reports, it was decided that the new records of surface elevation should be analysed so as to produce an estimate equivalent to the Hs. It was found that a good estimate of Hs was given using the average height of the third highest waves. In modern times, the variation in wave surface elevation is typically recorded digitally, which provides the potential for signiÃ¯Â¬Âcant analysis of the wave record. The most signiÃ¯Â¬Âcant development in the representation of the sea is the deÃ¯Â¬Ânition of the sea using a spectrum. To understand the concept of the wave spectrum, it is Ã¯Â¬Ârst necessary to accept that the variation in water surface can be represented as the linear super-position of sinusoidal waves of different frequencies, amplitudes, directions and"
65,324,0.361,Handbook of Ocean Wave Energy,"  J d. This expression implies proportionality to wave (ii) Terminator body: P period wave height squared. Here, J [W/m] is the wave energy transport, k is the wave length and d is the width of the terminator body or device. As mentioned, small bodies behave as axisymmetric bodies over the range of wave periods where the size is small compared to the wavelength. Secondly, there will always be limits on the available stroke. These can be caused by the Ã¯Â¬Ânite volume of the buoys used, or by limits on the stroke of the machinery, often referred to as amplitude restrictions. The stroke limitation leads to an upper bound on the average absorbed that is proportional to the wave height H. The bound further depends on the mode of oscillation [12]: Ã¢Â€Â¢ For heave mode, P\ p4 qg Vs HT , often referred to as BudalÃ¢Â€Â™s upper bound. Ã¢Â€Â¢ For surge mode, P\2 p3 q Vs TH3 l Ã¢Â€Â¢ For pitch mode, P\ 23 p3 q Vs TH3 l Here Vs is the available volume stroke (illustrated in Fig. 6.11), T is the wave"
249,58,0.36,Advances in Proof-Theoretic Semantics (Volume 43.0),"Abstract The goal of this paper is to consider the prospects for developing a consistent variant of the Theory of Constructions originally proposed by Georg Kreisel and Nicolas Goodman in light of two developments which have been traditionally associated with the theoryÃ¢Â€Â”i.e. KreiselÃ¢Â€Â™s second clause interpretation of the intuitionistic connectives, and an antinomy about constructive provability sometimes referred to as the Kreisel-Goodman paradox. After discussing the formulation of the theory itself, we then discuss how it can be used to formalize the BHK interpretation in light of concerns about the impredicativity of intuitionistic implication and KreiselÃ¢Â€Â™s proposed amendments to overcome this. We next reconstruct GoodmanÃ¢Â€Â™s presentation of a paradox pertaining to a Ã¢Â€ÂœnaiveÃ¢Â€Â variant of the theory and discuss the influence this had on its subsequent reception. We conclude by considering various means of responding to this result. Contrary to the received view that the second clause interpretation itself contributes to the paradox, we argue that the inconsistency arises in virtue of an interaction between reflection and internalization principles similar to those employed in ArtemovÃ¢Â€Â™s Logic of Proofs. Keywords BHK interpretation Ã‚Â· Intuitionistic logic Ã‚Â· Theory of Constructions Ã‚Â· the Kreisel-Goodman paradox Ã‚Â· Logic of Proofs"
8,58,0.359,"Melting Hadrons, Boiling Quarks: From Hagedorn Temperature to Ultra-Relativistic Heavy-Ion Collisions at CERN: With a Tribute to Rolf Hagedorn","work on the theory of Lamb-shift in nonrelativistic Quantum electrodynamics (not published). This was followed by a paper in the theory of Barium-titanate as a thesis in spring 1952. Since June 1952 I have been working at the Max-Planck-Institute fÃƒÂ¼r Physik, GÃƒÂ¶ttingen, on nuclear physics, especially on the evaporation stars in nuclear emulsions."
353,221,0.356,"Disability, Health and Human Development",Uganda 50 & older/ Severe/ func. diff. both waves 50 & older/ Severe/ func. diff. one wave 50 & older/ Women/ func. diff. both waves Under 50/ Severe/ func. diff. both waves 50 & older/ Men/ func. diff. both waves 50 & older/ Moderate/ func. diff. one wave Under 50/ Women/ func. diff. both waves 50 & older/ Women/ func. diff. one wave 50 & older/ Moderate func. diff. both waves Under 50/ Women/ func. diff. one wave Under 50/ Severe func. diff. one wave 50 & older/ Men/ func. diff. one wave Under 50/ Moderate func. diff. one wave Under 50/ Moderate func. diff. both waves Under 50/ Men/ func. diff. both waves Under 50/ Men/ func. diff. one wave
8,191,0.356,"Melting Hadrons, Boiling Quarks: From Hagedorn Temperature to Ultra-Relativistic Heavy-Ion Collisions at CERN: With a Tribute to Rolf Hagedorn","9.2 Hot Hadron Matter Photons and Leptons E.L. Feinberg actively promoted the statistical and hydrodynamical concepts and at the 1970 Kiev conference he first proposed [5] the photon and dilepton signatures (the so-called direct photons and dileptons) of the early stage of the quarkgluon matter (see his summary of 1976 [6]). Namely, these particles could escape from hadronic medium being in comparison almost non-interacting and, therefore, provide important information about its properties. Many experimental papers aiming to detect such radiation and to confront its properties with theoretical prediction appeared afterwards. The theory was extended to include parton based processes and production of psions (cNc D  ) [7]. E.L. (as we called him) often corresponded with Rolf Hagedorn, and also with Peter Carruthers, discussing with them statistical and hydrodynamic approaches which were out of the mainstream of theory research at that time. One had to wait long for experimental data on AA collisions before this approach to strong interactions was recognized."
372,1834,0.353,Interferometry and Synthesis in Radio Astronomy : Third Edition (Edition 3),"Now because the incident wavefronts are plane, the amplitude of the wave does not change over the distance AA0 . However, the phase changes by $"" D ul, so for the wave from S0 at A, we have E.l; t ! ""/ D E.l; t/ e!j2#ul :"
133,253,0.352,"A Demographic Perspective on Gender, Family and Health in Europe","Gender Women Total 18Ã¢Â€Â“19 20Ã¢Â€Â“24 25Ã¢Â€Â“29 30Ã¢Â€Â“34 35Ã¢Â€Â“39 40Ã¢Â€Â“44 Patchwork in wave 1 and low or middle level of education Patchwork in wave 1 and high level of education Source Austrian GGS 2008/9 and 2012/13, wave 1 and wave 2"
235,89,0.35,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","to some permutation group. In particular, every finite group G of order n can be imbedded as Ã¢Â€Â“ equivalently, is isomorphic to Ã¢Â€Â“ a subgroup of the symmetric group S(n). Stated pointedly: permutations exhaust the possible structures of (finite) groups. The study of subgroups of the symmetric groups is no less general than the study of all groups. A particular case where the codomain needs not to be finite is quantum mechanics. In quantum mechanics, the (co)domain will be identified with the Hilbert spaces. We will restrict our attention to complex finite dimensional Hilbert spaces Cn with the Euclidean scalar product. In one of the axioms of quantum mechanics the evolution is identified with some isometric permutation preserving the scalar product (or, equivalently, a mapping of one orthomodular basis into another one); that is, with unitary transformations U, for which the adjoint (the conjugate transpose) is the inverse; that is, UÃ¢ÂˆÂ— = UÃ¢Â€Â  = UÃ¢ÂˆÂ’1 . We shall now turn our attention to an even more restricted type of universe whose evolution is based upon permutations [193] on countable or even finite (co)domains [368]. Thereby we shall identify these (co)domains with very particular sets of unit vectors in Rn : the Cartesian standard bases; namely all those ket (that is, column) vectors |x with a single coordinate being one, and all other components zero. Suppose further that elements of the set {1, 2, . . . , n} of natural numbers are identified with the elements of the Cartesian standard bases B = {|e1 , |e2 , . . . , |en } by i Ã¢Â‰Â¡ |ei . The symmetric group S(n) of all permutations of n basis elements of B can then be represented by the set of all (n ÃƒÂ— n) permutation matrices carrying only a single Ã¢Â€Âœ1Ã¢Â€Â in all rows and columns; all other entries vanish."
124,17,0.35,Nuel Belnap on Indeterminism and Free Action : Volume 2 of Outstanding Contributions to Logic (Volume 2),"a single history is however typically Hausdorff. This makes good sense given indeterminism: If different possibilities exist for the same position in space-time, the corresponding possible point events may be topologically inseparable in the full indeterministic model. Ã¢Â€Â¢ These topological observations are linked to the question whether BST can be viewed as a space-time theory. Earman (2008) has asked a pointed question about the tenability of BST as a space-time theory, sharply criticizing McCallÃ¢Â€Â™s (1994) version of BST and raising doubts about BelnapÃ¢Â€Â™s framework. His main challenge is to clarify the meaning of non-Hausdorffness that occurs in BST, since in space-time theories this is a highly unwelcome feature. Some recent literature, including Tomasz PlacekÃ¢Â€Â™s contribution to this volume, has clarified the situation considerably, highlighting the difference between branching within a space-time, which indeed has unwelcome effects well known to general relativists, and the BST notion of branching histories, in which the histories are individually nonbranching space-times. The connection between BST and general relativity is only beginning to be made, and a revision of BelnapÃ¢Â€Â™s prior choice principle may be in order to move the two theories closer to each other. (Technically, the issue is that the prior choice principle typically leads to a violation of local Euclidicity, which is, however, presupposed even for generalized, non-Hausdorff manifolds.) Apart from PlacekÃ¢Â€Â™s contribution, see also Sect. 6 of the contribution by Pleitz and Strobach, and MÃƒÂ¼ller (2013b). Ã¢Â€Â¢ Another area of physics that may be able to interact fruitfully with the BST framework is quantum mechanics. As BST incorporates both indeterminism and spacelike separation, it seems to be especially well suited for clarifying the issue of space-like correlations in multi-particle quantum systems, pointed out in a famous"
65,135,0.349,Handbook of Ocean Wave Energy,"of Orkney, Scotland, the waves travelling away from the shore typically account for about 15 % of the average omni-directional wave power, which is not an insigniÃ¯Â¬Âcant proportion of the total wave power. The key to assessing whether this 15 % of wave power should or should not be included depends on whether or not the WEC can capture energy travelling in the opposite direction to the majority of the waves. For example, a heaving buoy, such as the Wavebob, may be expected to exploit this wave power, but an overtopping device, such as the WaveDragon, is less likely to be able to exploit it so that the omni-directional wave power is less appropriate as a proxy for power generation in this case."
352,442,0.348,Interface Oral Health Science 2014,"21.2.4 Shear Wave Measurement By comparing an acceleration at reference depth with an acceleration at interest depth, a velocity of shear wave propagating from an artery toward a skin surface can be calculated from a relationship between the depth and the arrival time of shear wave at the depth. The relationship ÃÂ†(z) can be expressed as XtÃ‚Â¼NÃÂ±"
311,2749,0.348,The Physics of the B Factories,"22.1 Descriptions of two-photon topics to be covered 22.1.1 Introduction for two-photon physics An electron-positron collider is also a photon-photon collider. Since the photon couples directly to the electric charge of quarks, we can study hadron structures and QCD physics, eÃ¯Â¬Â€ectively, in hadron production induced by two-photon collisions. The even C-parity of the twophoton system is complementary with the odd C-parity in e+ eÃ¢ÂˆÂ’ collisions. In an e+ eÃ¢ÂˆÂ’ collider, a virtual photon is emitted from each lepton; a collision of these photons produces final-state particles as shown in Figure 22.1.1. The two-photon center-of-mass (CM) energy, W , which is the same as the invariant mass of the final-state system, is continuously distributed between zero and just below the e+ eÃ¢ÂˆÂ’ CM energy. For practical purposes, the usable range is between a few 100 MeV and Ã¢ÂˆÂ¼ 4.5 GeV. The lower side is limited by experimental trigger conditions and the upper by the luminosity and backgrounds from e+ eÃ¢ÂˆÂ’ annihilation events."
65,513,0.347,Handbook of Ocean Wave Energy,"The objective of structural and mooring load tests is to obtain a good sense of the maximum loads that can be expected on these parts of the system. These tests need therefore to be executed on a very representative model and in the wave conditions resulting in these maximum loads (design wave conditions), which usually correspond to the extreme wave conditions. A set of extreme wave conditions, combining wave, current and wind speciÃ¯Â¬Âcations are provided in relevant design standards, such as the DNV standards on offshore wave and wind energy [10, 12, 15]. Before being able to obtain these resulting loads, usually the mooring conÃ¯Â¬Âguration needs to be optimised. This will physically correspond to adapting the"
192,186,0.347,Tales of Research Misconduct : a Lacanian Diagnostics of integrity Challenges in Science Novels,"The novel is a discursive clinic, enabling a diagnostics of modes of discourse. To bring these discourses and their contradictions to the fore, the novel is a stage, a BÃƒÂ¼hne, where various types of discourse can be fleshed out and mutually exposed to one another. To achieve this, the novel adopts a psychoanalytical perspective. Quantum physics gives way to psychoanalysis and self-analysis.11"
103,136,0.346,Solar Particle Radiation Storms Forecasting and Analysis : The Hesperia Horizon 2020 Project and Beyond (Volume 444.0),"The situation is illustrated in Fig. 3.6, right panel, where energetic protons can interact with two AlfvÃƒÂ©n waves propagating in opposite directions, when the proton velocity is situated in the region jvk j & 2VA . Scatterings off waves with positive (negative) phase speed will result in motion along the red (green) semi-circles showing that the particle energy in the plasma frame can change in a random fashion, i.e., increase or decrease. As this diffusive process spreads the distribution of protons in energy, the net effect will be acceleration. This is an example of stochastic acceleration, but other types of waves as well as randomly moving coherent structures interacting with the particles can lead to a similar situation of particles diffusing in momentum when interacting with the structures. Figure 3.6, left panel also shows the resonant interaction of low-energy minor ions (3 He and iron) with higher-frequency left-handed wave modes. The figure shows that while thermal protons and alpha particles would typically resonate with heavily damped wave modes (and their resonant wave acceleration should, therefore, be somewhat inefficient), minor ions not only resonate with much less damped waves but also simultaneously with several waves propagating at different phase speeds. Especially 3 He can be very efficiently accelerated stochastically in this process, starting already from thermal energies. Stochastic acceleration"
217,1104,0.345,Finite Difference Computing With Pdes : a Modern Software Approach,"B.5.4 Linear Wave Equation in 2D/3D The two-dimensional extension of (B.68) takes the form  2 @2 u @2 u 2 @ u C f .x; y; t/; .x; y/ 2 .0; L/  .0; H /; t 2 .0; T Ã‚Â; @t 2 @x 2 @y 2 (B.79) where now c.x; y/ is the constant wave velocity of the physical medium Ã…Â’0; LÃ‚Â  Ã…Â’0; H Ã‚Â. In compact notation, the PDE (B.79) can be written u t t D c 2 .uxx C uyy / C f .x; y; t/;"
391,294,0.345,Ocean-Atmosphere Interactions of Gases and Particles,"Wind-generated waves affect processes at the air-sea interface in several ways. In the form of variable roughness elements and group speeds, they interact with and modify the wind field above the sea surface (c.f. Sects. 2.2.9 and 2.4.1). The StokeÃ¢Â€Â™s drift caused by the waves is involved in the generation of the Langmuir circulation which, in turn, is one of the mixing processes of the surface layer of the ocean (Sect. 2.2.5) and affects the distribution of surfactants (Sect. 2.2.7). Breaking waves inject bubbles (Sect. 2.2.3) and cause turbulence in the surface waters contributing to the surface processes and to the mixing of the surface layer. Another source of turbulence is the microscale breaking of short waves (Sect. 2.2.1). The properties of the irregular wave field cannot be parameterised by wind speed alone. For example, wave breaking depends on the wave steepness and not on the wind speed. In addition to the wind speed, the development of waves depends also on wind duration, fetch, the shape of the basin, water depth and atmospheric stratification. Typically, the wave field consists of one or several wave systems, e.g. locally generated waves and a swell originating from a distant storm. Their influence on the interaction with the atmosphere varies with state of development, the relative dominance of the wave systems and the difference of their directions (e.g. Donelan et al. 1997; Drennan et al. 1999; Veron et al. 2008). The properties of the wave field can be quite different in the oceans to that in marginal seas. While in the oceans the waves more often reach full development, in areas closer to the shore waves are typically strongly forced due to the limited fetch and are thus steeper. Depending on the fetch geometry, the direction of the waves can differ from the wind direction (Pettersson et al. 2010). If the sea is shallow enough for the waves to Ã¢Â€Â˜feelÃ¢Â€Â™ the bottom, there will be further changes in the steepness of the waves and changes in wave directions leading to areas of wave energy convergence and divergence. In high latitudes the seasonal ice cover forms a changing fetch and fetch geometry affecting the properties of the wave field adjacent to the ice edge. For transfer across the air-sea interface the turbulence in the subsurface layer is one of the key factors. When present, the breaking waves contribute strongly to the subsurface turbulence. Babanin (2006) has"
217,416,0.344,Finite Difference Computing With Pdes : a Modern Software Approach,"to work with wave components e i kx for very large k, because the shortest possible sine or cosine wave that can be represented uniquely on a mesh with spacing Ã‚Âx is the wave with wavelength 2Ã‚Âx. This wave has its peaks and throughs at every two mesh points. That is, the wave Ã¢Â€Âœjumps up and downÃ¢Â€Â between the mesh points. The corresponding k value for the shortest possible wave in the mesh is k D 2=.2Ã‚Âx/ D =Ã‚Âx. This maximum frequency is known as the Nyquist frequency. Within the range of relevant frequencies .0; =Ã‚ÂxÃ‚Â one defines the discrete Fourier transform11 , using Nx C 1 discrete frequencies:"
235,208,0.342,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","The quantum expectation can be directly computed from spin state operators. For spin- 21 particles, the relevant operator, normalized to eigenvalues Ã‚Â±1, is "" ! T(ÃÂ¸1 , ÃÂ•1 ; ÃÂ¸2 , ÃÂ•2 ) = 2S 21 (ÃÂ¸1 , ÃÂ•1 ) Ã¢ÂŠÂ— 2S 21 (ÃÂ¸2 , ÃÂ•2 ) ."
204,27,0.342,Iutam : a Short History,"B. Examples of the Applications of Mechanics 1. Applied Mechanics and its Growing Utilisation of Theoretical Mechanics The applications of mechanics are found in many scientiÃ¯Â¬Âc Ã¯Â¬Âelds, some of which (like astronomy, oceanography, and meteorology) have already been referred to; as well as in most of the principal subdivisions of engineering and technology. Into each particular scientiÃ¯Â¬Âc or technological Ã¯Â¬Âeld the process of penetration of any reÃ¯Â¬Âned ideas from theoretical mechanics has been slow, for a good reason: the scientiÃ¯Â¬Âc phenomena needing to be elucidated, or the technological objectives needing to be met, were in most cases much too complicated for effective treatment by the methods of theoretical mechanics during their early stages of development. In these circumstances, practitioners of the disciplines concerned needed to concentrate above all on devising ingenious measurement techniques appropriate to a particular area of application, and on amassing useful empirical rules for correlating data obtained with these techniques. Such rules might be expressed in phraseology using some of the simpler ideas from theoretical mechanics, but they were not based on detailed theoretical analysis. Great achievements were to result from applied mechanics development using these empirical methods. In each area the approach in question has, furthermore, continued to make good progress, especially during periods immediately following the introduction of a new measurement technique. At the same time the general progress in theoretical mechanics has successfully taken place, partly under its own momentum and partly under the stimulus of challenges posed by the complicated problems needing to be solved in particular areas of application. Gradually, within each Ã¯Â¬Âeld, theoretical analysis of Ã¢Â€Â˜model problemsÃ¢Â€Â™ has become recognized as making a truly valuable contribution to studies of the complicated Ã¢Â€Â˜real problemsÃ¢Â€Â™ which they were designed to model. Even when the agreement between experiment and theory was not very excellent such analysis might permit a most useful extrapolation of the available experimental data to other conditions for which additional experiments would be too difÃ¯Â¬Âcult or costly or time-consuming. In time, the models became more and more comprehensive, and correspondingly more valuable. These continuing processes, in which theoretical mechanics both makes valued contributions to, and is stimulated by challenges derived from, applied mechanics, have increasingly brought the two parts of mechanics much closer together in a fruitfully cooperative unity. Some examples of how this happened in particular areas of application are given in the rest of this note."
65,16,0.341,Handbook of Ocean Wave Energy,"Buoyancy force (N) Current force (N) Excitation force (N) Excitation impulse response function (Ã¢Â€Â“) Excitation force (N) Friction force (N) Hydrostatic force (N) The Mooring force (N) PTO force (N) Radiation force (N) Wave force ratio (Ã¢Â€Â“) Center of gravity (m) Gravitational acceleration (m/s2) Hydrostatic matrix (N/m) Peak enhancement factor (Ã¢Â€Â“) Constant (Ã¢Â€Â“) Righting arm (m) Water depth (m) Wave height (m), heaviside step function (Ã¢Â€Â“) or horizontal force (N) SigniÃ¯Â¬Âcant wave height (m) Max wave height within a given duration of a sea state (m) Horizontal pretension (N) SigniÃ¯Â¬Âcant wave height (m) Impulse-response function (Ã¢Â€Â“) SigniÃ¯Â¬Âcant Wave Height estimate from wave spectrum (m) Current density in the conductor (A) Incident momentum (Ã¢Â€Â“) Mode of motion (Ã¢Â€Â“). Translations: 1: Surge, 2: Sway, 3: Heave. Rotations: 4: Roll, 5: Pitch, 6: Yaw Wave power flux or wave power level (equal to Pwave) (kW/m) Roughness height (mm) Spring coefÃ¯Â¬Âcient or Stiffness (N/m) Wave number (mÃ¢ÂˆÂ’1) Relative roughness (Ã¢Â€Â“) KeuleganÃ¢Â€Â“Carpenter number (Ã¢Â€Â“) Spring constant for the end stop mechanism (N/m) Constant that depends only on turbine geometry (Ã¢Â€Â“) Length (m) Leakage inductance (H) Main inductance (H) Wave length based on peak wave period and deep water (m) Synchronous inductance (H) Body mass (kg) Mass (kg) Mass matrix (kg)"
305,22,0.338,Quantum Computing for Everyone,"know that the photons coming through the first filter are polarized vertically. When measured by the second filter, half of the photons are found to be polarized in the 45Ã‚Â° direction and half in the 135Ã‚Â° directions. The ones with 45Ã‚Â° polarization pass through the filter, and the others are absorbed. The third filter again measures the polarization in the vertical and horizontal directions. The photons entering have 45Ã‚Â° polarization, and when measured in the vertical and horizontal directions, half will have vertical polarization and half will have horizontal polarization. The filter absorbs the vertically polarized photons and lets through those that are polarized horizontally. Conclusions We started this chapter by saying that classical bits can be represented by everyday objects like switches in the on or off position, but that qubits are generally represented by the spin of electrons or the polarization of photons. Spin and polarization are not nearly so familiar to us and have properties that are quite unlike their classical counterparts. To measure spin, you first have to choose a direction and then measure it in that direction. Spin is quantized: When measured, it gives just two possible answersÃ¢Â€Â”not a continuous range of answers. We can assign classical bits to these results. For example, if we obtain an N we can consider it to be the binary digit 0, and if we obtain an S we can consider it to be the binary digit 1. This is exactly how we get answers from a quantum computation. The last stage of the computation is to take a measurement. The result will be one of two things, which will be interpreted as either 0 or 1. Although the actual computation will involve qubits, the final answer will be in terms of classical bits. We have only just started our study, so we are quite limited in what we can do. We can, however, generate random strings of binary digits. The experiment that generated random strings of Ns and Ss can be rewritten as a string of 0s and 1s. Consequently measuring spins of electrons first in the vertical and then in the horizontal direction gives a random string of 0s and 1s. This is probably the simplest thing that we can do with qubits, but surprisingly this is something that cannot be done with a classical computer. Classical computers are deterministic. They can compute strings that pass various tests for randomness, but these are pseudorandom, not"
192,337,0.335,Tales of Research Misconduct : a Lacanian Diagnostics of integrity Challenges in Science Novels,"Solar quite convincingly explains how, as a young researcher, Michael Beard had been an isolated, introverted, highly committed, hyper-individual quantum physicist. As an ageing scientist, however, his situation has completely changed. A new arena of Ã¢Â€Âœconverging researchÃ¢Â€Â has emerged, in the intermediate zone between nano-technology, photovoltaics and climate politics. From the 1950s onwards, physicists (with their high-tech contrivances and advanced mathematics) migrated towards the life sciences, employing their powerful physical technologies to understand and mimic the basic processes of life. Artificial photosynthesis, as a sub-field of biomimesis (i.e. the use of biotechnology to mimic living nature on the molecular level), is an exemplification of this trend. Thus, the epistemological backdrop of the narrative is a transformation that is actually taking place in laboratories world-wide, where biotechnology is evolving into bio-mimesis, i.e. mimicking (Ã¢Â€Â˜copy-pastingÃ¢Â€Â™) nature on a molecular scale (Church and Regis 2012; Zwart et al. 2015; Blok and Gremmen 2016). In principle, this biomimetic turn entails a positive ambition. The aim is to develop technologies which, although highly advanced, are nonetheless more sustainable and naturefriendly than the technologies which humankind managed to produce so far. Indeed, artificial photosynthesis basically aims to see plant leaves as biological factories from which human technology still has a lot to learn in terms of efficiency, sustainability and circularity. Nature is the paradigm, the teacher (natura artis magistra) for molecular life scientists and bioengineers, notably on the quantum or nanoscale. The down-side is that there is a lot of investment, prestige and politics involved in this type of research, so that it runs the risk of becoming tainted by privatisation, commercialisation and politicisation. This transformation (presented in Solar as an emerging scientific-industrial Ã¢Â€ÂœrevolutionÃ¢Â€Â, p. 36, p. 211, p. 336; as a Ã¢Â€Âœnew chapter in the history of industrial civilisationÃ¢Â€Â, p. 293) is quite credibly reflected in the novel, and it is clear that author Ian McEwan has conducted a considerable amount of preparatory research.1 Although Beard is said to hold Ã¢Â€Âœan irrational prejudice against physicists who defected to biology, SchrÃƒÂ¶dinger, Crick and the likeÃ¢Â€Â (p. 121), he basically follows in their footsteps, moving from Ã¢Â€Â˜pureÃ¢Â€Â™ quantum physics2 to Ã¢Â€Â˜appliedÃ¢Â€Â™ molecular life sciences research. Yet, the most dramatic discontinuity in his career is not the shift from basic physics (studying photons and electrons) to biomimesis, but from original research"
311,2036,0.334,The Physics of the B Factories,"P -wave/S-wave ratio in the ÃÂ†(1020) region The decay mode Ds+ Ã¢Â†Â’ ÃÂ†(1020)ÃÂ€ + is used often as the normalizing mode for Ds+ decay branching fractions, typically by selecting a K + K Ã¢ÂˆÂ’ invariant mass region around the ÃÂ†(1020) peak. The observation of a significant S-wave contribution in the threshold region means that this contribution must be taken into account in such a procedure. BABAR has estimated the P -wave/S-wave ratio in an almost model-independent Ã¢ÂˆÂš Integrating  the distributions of 4ÃÂ€pq Ã¢Â€Â² Y00 and 5ÃÂ€pq Ã¢Â€Â² Y20 (Fig. 19.1.32), where p is the K + momentum in the K + K Ã¢ÂˆÂ’ rest frame, and q Ã¢Â€Â² is the momentum of the bachelor ÃÂ€ + in the Ds+ in a region around the ÃÂ†(1020) peak yields"
65,33,0.334,Handbook of Ocean Wave Energy,"Ã¢Â€Â¢ The whole system can be commissioned at once, thereby sharing installation and servicing works and equipment, e.g. it only requires one vessel for handling one system. Ã¢Â€Â¢ Larger structures are more easily accessed as they are more stable, which enables easier inspection of the system and some maintenance could be done on board, without the need of retracting the system to a safe/controlled area. 5. There are various technical assessment ratios for a WEC: Ã¢Â€Â¢ The wave-to-wire efÃ¯Â¬Âciency (ÃÂ·w2w) is the overall efÃ¯Â¬Âciency of the system delivering the absorbed energy from the waves to the grid. This value is also based on many underlying speciÃ¯Â¬Âcations, such as the wave conditions, the availability of the system and the maximum power rating, and so needs to be taken very carefully. Ã¢Â€Â¢ The capture width ratio (CWR) describes the effectiveness of the converter to absorb the energy in the waves. This value is based on many underlying speciÃ¯Â¬Âcations, such as the wave conditions and the size of the wave activated body, and needs thereby to be handled very carefully. Ã¢Â€Â¢ The WEC weight/installed kW ratio is also often used to indicate how much material is used relative to the power rating of the WEC. This can be a bit misleading as it does not particularly show the type of material (e.g. steel or concrete). It should at least be divided between active structural (load carrying) material and ballast material, as their difference in cost can be as great as a factor 100. Ã¢Â€Â¢ The capacity factor (also called capacity factor) is the ratio between the average produced power and the installed power on the WEC. It describes the utility rate of the PTO system and is very interesting as it gives an idea of what the WEC delivers (average produced power) and what it costs (driven by installed power). However, this value is also wave condition dependant (location). Note that the overall efÃ¯Â¬Âciency of a WEC ÃÂ·w2w includes the efÃ¯Â¬Âciencies of each power conversion step, between wave and grid, together with the limitations of the system, such as the saturation of the generator. The complete power conversion train is, thereby, composed of at least: hydrodynamic conversion (wave to absorber described by CWR), PTO (absorber to generator), generator and electronics, substation and voltage increase, and grid connection. The availability of the system is not calculated in the overall efÃ¯Â¬Âciency as it is dependent on other aspects such as the maintenance possibilities of the system, but is included in the capacity factor. 6. A very important long-term economic aspect of a WEC is its capability of being scalable in size, even after it reaches commercial maturity. This can be compared with wind turbines, which keep on being increased in size in order to reduce their LCoE. Different wave-absorbing bodies have different optimal dimensions (see Table 1.2), e.g. the hydrodynamic optimal full-scale diameter of a point absorber will (normally) be between 15Ã¢Â€Â“20 m depending on the wave conditions. Large structures with multiple wave absorbing bodies could possibly increase their amount instead of enlarging them."
45,515,0.333,Measurement and Control of Charged Particle Beams,"capacitors in parallel with the charge line. Spark gaps and solid-state FETs, such as in Fig. 9.11, are thyratron alternatives with potentially shorter rise and fall times [21]. For many future applications with closely spaced bunch trains, shorter kicker time constants are desired. A very fast counter-travelling wave kicker was designed and built for the TESLA project [24]. This kicker scheme uses two parallel conducting plates or electrodes. These are excited by short pulses from a generator, generating an electromagnetic wave which travels in a direction opposite to the beam, and produces a horizontal kick. At the end of"
305,116,0.333,Quantum Computing for Everyone,"We do not know the probabilities that should be assigned to the configurations. There are eight possible configurations, so it might seem plausible that they each occur with probability 1/8, but they perhaps are not all equal. Our mathematical analysis will make no assumption about these probabilitiesÃ¢Â€Â™ values. We can, however, assign definite probabilities to the measurement directions. Both Bob and Alice are choosing each of their three bases with equal probability, so each of the nine possible pairs of bases occurs with probability 1/9. Notice that each row contains at least five As, telling us that given a pair of qubits with any configuration the probability of getting an A is at least 5/9. Since the probability of getting an A is at least 5/9 for each of the spin configurations, we can deduce that the probability overall must be at least 5/9, no matter what proportion of time we get any one configuration. We have now derived BellÃ¢Â€Â™s result. The quantum theory model tells us that AliceÃ¢Â€Â™s and BobÃ¢Â€Â™s sequences will agree exactly half the time. The classical model tells us that AliceÃ¢Â€Â™s and BobÃ¢Â€Â™s sequences will agree at least 5/9ths of the time. It gives us a test to distinguish between the two theories. Bell published his inequality in 1964. Sadly, this was after the death of both Einstein and Bohr, so neither ever realized that there would be an experimental way of deciding their debate. Actually carrying out the experiment is tricky. John Clauser and Stuart Freedman first performed it in 1972. It showed that the quantum mechanical predictions were correct. The experimenters, however, had to make some assumptions that could not be checked, leaving some chance that the classical view could still be correct. The experiment has since been repeated"
305,120,0.33,Quantum Computing for Everyone,"interpretation is a way of trying to explain how the mathematical theory relates to reality. Perhaps, at some point there will be an insightful genius like Bell who can show that the different interpretations lead to different conclusions that can be experimentally differentiated, and that experiments will then give us some reason for choosing one interpretation over another. But at this point, most physicists subscribe to the Copenhagen interpretation. There is no convincing reason not to use this interpretation, so we shall use it without further comment from now on. The final topic of this chapter shows that BellÃ¢Â€Â™s theorem is not just of academic interest. It can actually be used to give a secure way of sharing a key to be used in cryptography. The Ekert Protocol for Quantum Key Distribution In 1991, Artur Ekert proposed a method based on entangled qubits used in BellÃ¢Â€Â™s test. There are many slight variations. We will present a version that uses our presentation of BellÃ¢Â€Â™s result. Alice and Bob receive a stream of qubits. For each pair, Alice receives one and Bob receives the other. The spin states are entangled. They are always Ã¢Â†Â‘ Ã¢Â†Â‘ + Ã¢Â†Â“ Ã¢Â†Â“ . If Alice and Bob measure their respective qubit using the same orthonor-"
65,447,0.33,Handbook of Ocean Wave Energy,"In order to render the wave energy converter more efÃ¯Â¬Âcient by increasing the overlap between the (changing) ocean wave spectrum and the response of the converter, some tuning is necessary. The process of adapting the wave energy converter to behave as in resonance over a broad band of frequencies is referred to as control. The physical characteristics of the wave energy converter, like size, mass and shape, are often difÃ¯Â¬Âcult to vary according to the incoming waves, but the behaviour of the converter can be adjusted by acting on the stiffness and/or the damping of the system.2 These variables are accessible through the PTO system of a wave energy converter. By controlling the behaviour of wave energy converters through their PTO system, one can increase the efÃ¯Â¬Âciency of the system and hence its cost-effectiveness. Furthermore, in the event of extreme conditions, the wave energy converter should automatically switch to safe operation mode in order to insure its survivability. This implies a controlled system where the forces exerted on the system are monitored regularly. However necessary, control of the PTO system of wave energy converters introduces complexity to the system, which in turn lowers the reliability of the system and increases maintenance cost. The influence of the control strategy on the structural fatigue also needs to be considered [23]. Careful design of the control strategy is imperative in order to ensure cost-effective converters."
235,223,0.329,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","12.12 Metaphysical Status of Quantum Value Indefiniteness What does it mean that a particular (quantum) entity is value indefinite? It means that relative to, or with respect to, a particular physical resource or physical means, the respective entity cannot be entirely, that is, completely and totally, defined. In short: any proposition about physical value indefiniteness is means relative."
372,1742,0.329,Interferometry and Synthesis in Radio Astronomy : Third Edition (Edition 3),"with respect to the unscattered signal. The phase of the scattered wave is 2#!*c with respect to the direct (unscattered) wave, and interference between these two waves causes scintillation. The bandwidth over which the relative phase changes by 2# is called the correlation bandwidth, '!c . The correlation bandwidth is the reciprocal of *c , and for the case R D R0 is '!c '"
305,232,0.329,Quantum Computing for Everyone,"numerous applications. They are so commonly needed that they are programmed into most scientific calculators. We wonÃ¢Â€Â™t discuss them here apart from mentioning that the number of steps required to solve a system of n equations can be bounded above by a quadratic expression involving n. We say the system can be solved in quadratic time. The other question that we need to address is this: How many times do we need to run the quantum circuit? As we pointed out, in the worst-case scenario, we can keep running our qubits through the circuit and never get any useful information. However, this is extremely unlikely. We examine this idea in more detail in the next section. Complexity Classes In complexity theory, the main classification is between problems that take polynomial time to solve and those that need more than polynomial time. Polynomial time algorithms are regarded as being practical even for very large values of n, but non-polynomial time algorithms are regarded as being infeasible for large n. Problems that classical algorithms can solve in polynomial time are denoted by P. Problems that quantum algorithms can solve in polynomial time are denoted by QP (sometimes it is denoted by EQP, for exact quantum polynomial time). Usually when we use these terms we are referring to the number of steps that an algorithm takes, but, remember, we defined a new way of measuring complexityÃ¢Â€Â”query complexityÃ¢Â€Â”that counts the number of questions we need to ask an oracle. We saw that the Deutsch-Jozsa problem was not in the class P, but belonged to QP for query complexity. (The constant function is a degree 0 polynomial.) This is sometimes described as saying that the Deutsch-Jozsa problem separates P and QPÃ¢Â€Â”it is a problem that belongs to QP but not to P for query complexity. However, letÃ¢Â€Â™s recall the worst-case scenario for the classical algorithm. To make things more concrete, we will take n = 10. We are given a function that takes 10 inputs and told that it is either balanced or constant. We have to keep evaluating our function on specific inputs until we can deduce the answer. There are 210 = 1024 possible inputs. The worst-case scenario is when the function is balanced, but we get the same answer for the first 512 evaluations, and then on the 513th evaluation we get the other value. But how likely is this to happen?"
65,326,0.329,Handbook of Ocean Wave Energy,"period and l is the length of the device along the direction of wave propagation. As seen, this second upper bound is inversely proportional to the wave period for heave motion, and to the wave period cubed for surge and pitch motion. The graphs in Fig. 6.12 illustrate these limitations to the maximum absorbed power. We may refer to these as Ã¢Â€ÂœBudal diagramsÃ¢Â€Â."
65,338,0.329,Handbook of Ocean Wave Energy,"One may say that there are two fundamentally different ways to calculate wave-induced forces on structures in the sea. In one method one considers the structure as a whole and assesses the total wave force from empirical or computed coefÃ¯Â¬Âcients applied on water velocities and accelerations in the undistorted wave motion. This method may be used if the size of the structure is smaller than a quarter of the actual wavelength. In the other method the pressure distribution around the surface of the structure is computed taking into account the effect on the water motion distorted by the structure itself, and subsequently integrated around the structure. Both these approaches are used for the oscillating wave forces in Sect. 7.3.3.2 In both cases some mathematical model for describing the wave properties is necessary. For instance, by making the simpliÃ¯Â¬Âed assumption that the wave motion can be regarded as potential flow, velocities, accelerations and water motion can be computed in any point under a gravity surface wave by a scalar quantity, the velocity potential."
217,424,0.327,Finite Difference Computing With Pdes : a Modern Software Approach,"The relation between the numerical frequency !Q and the other parameters k, c, Ã‚Âx, and Ã‚Ât is called a numerical dispersion relation. Correspondingly, ! D kc is the analytical dispersion relation. In general, dispersion refers to the phenomenon where the wave velocity depends on the spatial frequency (k, or the wave length  D 2=k) of the wave. Since the wave velocity is !=k D c, we realize that the analytical dispersion relation reflects the fact that there is no dispersion. However, in a numerical scheme we have dispersive waves where the wave velocity depends on k. The special case C D 1 deserves attention since then the right-hand side of (2.90) reduces to 2 kÃ‚Âx 1 !Ã‚Âx Ã‚Ât 2 Ã‚Ât c That is, !Q D ! and the numerical solution is exact at all mesh points regardless of Ã‚Âx and Ã‚Ât! This implies that the numerical solution method is also an analytical solution method, at least for computing u at discrete points (the numerical method says nothing about the variation of u between the mesh points, and employing the common linear interpolation for extending the discrete solution gives a curve that in general deviates from the exact one). For a closer examination of the error in the numerical dispersion relation when C < 1, we can study !Q  !, !=!, or the similar error measures in wave velocity: cQ  c and c=c, where c D !=k and cQ D !=k. It appears that the most convenient expression to work with is c=c, since it can be written as a function of just two parameters: sin1 .C sin p/ ; with p D kÃ‚Âx=2 as a non-dimensional measure of the spatial frequency. In essence, p tells how many spatial mesh points we have per wave length in space for the wave component with frequency k (recall that the wave length is 2=k). That is, p reflects how well the spatial variation of the wave component is resolved in the mesh. Wave components with wave length less than 2Ã‚Âx (2=k < 2Ã‚Âx) are not visible in the mesh, so it does not make sense to have p > =2. We may introduce the function r.C; p/ D c=c Q for further investigation of numerical errors in the wave velocity: r.C; p/ D"
65,124,0.326,Handbook of Ocean Wave Energy,"signiÃ¯Â¬Âcant; without waves there is no wave power. Figure 3.3 shows an example of this characterisation illustrating the variation in the average omni-directional wave power around the world. As would be expected, the areas with higher average omni-directional wave power, such as the north-west coast of Europe, are also the areas with the most interest in the deployment of wave energy converters. The implicit assumption is that a wave energy converterÃ¢Â€Â™s power capture is proportional to the average omni-directional wave power thus a larger average omni-directional wave power equates to a larger power capture. However, whilst it may be reasonable to assume that a wave energy converter will produce more power at a site with an average omni-directional wave power of 40 kW/m compared to an alternative site with 2 kW/m, it is less clear that this will be true if the alternative site had an average omni-directional wave power of 30 kW/m. The key factor to consider is that when comparing potential sites the use of the average omni-directional wave power obscures information regarding the temporal, directional and spectral characteristics of the wave climate (see Sect. 3.2) that may be important to the average power capture. Of course, how these characteristics may affect the average power generation will vary with the WEC and so it is difÃ¯Â¬Âcult to be overly prescriptive regarding the extent of distortion that may be due to using average omni-directional wave power as a proxy for average power generation. One method to compensate for the potential distortion is to provide information on other aspects of the wave climate simultaneously with the average omni-directional wave power. Examples of this additional information could include the ratio of maximum wave power to average wave power, the average directionality coefÃ¯Â¬Âcient, the average spectral width, and/or the average energy period. Unfortunately, whilst this additional information does provide more details of the characteristics of the wave resource that may suggest the relative strengths and weaknesses of particular sites, it still does not provide a clear indication of how a WECÃ¢Â€Â™s power generation may differ between locations. Whilst it is frustrating that a single parameter, or even set of parameters, cannot be used to assess the suitability of a potential WEC deployment site, this is the state of the wave energy industry at the moment. The rich diversity of WEC concepts currently being developed means that there are a multiple of relationships between the wave resource and power generation. Moreover, it is possible that a particular WEC concept may be most suitable at one location, whilst another WEC concept is more suitable at another location. Thus, there may not be the complete convergence onto a single concept as in wind energy, with the three-bladed horizontal-axis turbine, due to the potentially greater diversity of wave resource characteristics compared to wind resource characteristics, which is generally successfully characterised simply by the average wind speed. Although not associated with a particular WEC concept, a useful illustration of the dangers of using the average omni-directional wave power as a proxy for power generation is in assessing the effect of water depth on the incident wave power. Off of the west coast of Scotland, the average omni-directional wave power decreases as it approaches the shore and the water depth reduces, so that in 10Ã¢Â€Â“20 m of water it is only typically 50 % of its offshore value. To assess the extent that this"
217,372,0.326,Finite Difference Computing With Pdes : a Modern Software Approach,"for i 2 Ixi and n  1. New equations must be derived for u1i , and for boundary points in case of Neumann conditions. The damping is very small in many wave phenomena and thus only evident for very long time simulations. This makes the standard wave equation without damping relevant for a lot of applications."
305,72,0.325,Quantum Computing for Everyone,"The basis associated with 0Ã‚Â° is the standard orthonormal basis. The basis associated with 90Ã‚Â° is the same, except the order of the elements has been changed. A photon that passes through the first filter has had a Ã¯Â£Â®1 Ã¯Â£Â¹ measurement madeÃ¢Â€Â”it is vertically polarizedÃ¢Â€Â”and so is now in state Ã¯Â£Â¯ Ã¯Â£Âº . Ã¯Â£Â°0 Ã¯Â£Â» We now measure it with the second filter. This lets through photons with Ã¯Â£Â®0 Ã¯Â£Â¹ Ã¯Â£Â®1 Ã¯Â£Â¹ state vector Ã¯Â£Â¯ Ã¯Â£Âº and absorbs photons with state vector Ã¯Â£Â¯ Ã¯Â£Âº . Consequently, Ã¯Â£Â°1 Ã¯Â£Â» Ã¯Â£Â°0 Ã¯Â£Â» any photon that passes through the first filter is absorbed by the second. In the three-filter experiment we have the two filters arranged as above. We take the third sheet and rotate it through 45Ã‚Â°, and slide this sheet between the other two. Some light comes through the region of overlap of all three squares. This is depicted in figure 3.5. Ã¯Â£Â« Ã¯Â£Â® 1 Ã¯Â£Â¹ Ã¯Â£Â® 1 Ã¯Â£Â¹Ã¯Â£Â¶ Ã¯Â£Â« Ã¯Â£Â® Ã¯Â£Â¹ Ã¯Â£Â® Ã¯Â£Â¹Ã¯Â£Â¶ Ã¯Â£Â¬ Ã¯Â£Â¯ 2 Ã¯Â£Âº Ã¯Â£Â¯ 2 Ã¯Â£ÂºÃ¯Â£Â· Ã¯Â£Âº, Ã¯Â£Â¯ Ã¯Â£ÂºÃ¯Â£Â· and The ordered bases for the three filters are Ã¯Â£Â¬ Ã¯Â£Â¯ Ã¯Â£Âº , Ã¯Â£Â¯ Ã¯Â£ÂºÃ¯Â£Â· , Ã¯Â£Â¬ Ã¯Â£Â¯ Ã¯Â£Â­ Ã¯Â£Â° 0 Ã¯Â£Â» Ã¯Â£Â° 1 Ã¯Â£Â» Ã¯Â£Â¸ Ã¯Â£Â¬ Ã¯Â£Â¯ Ã¢ÂˆÂ’1 Ã¯Â£Âº Ã¯Â£Â¯ 1 Ã¯Â£Âº Ã¯Â£Â· Ã¯Â£Â­ Ã¯Â£Â¯Ã¯Â£Â° 2 Ã¯Â£ÂºÃ¯Â£Â» Ã¯Â£Â¯Ã¯Â£Â° 2 Ã¯Â£ÂºÃ¯Â£Â»Ã¯Â£Â¸ Ã¯Â£Â« Ã¯Â£Â® 0 Ã¯Â£Â¹ Ã¯Â£Â®1 Ã¯Â£Â¹ Ã¯Â£Â¶ Ã¯Â£Â¬Ã¯Â£Â­ Ã¯Â£Â¯1 Ã¯Â£Âº , Ã¯Â£Â¯0 Ã¯Â£ÂºÃ¯Â£Â·Ã¯Â£Â¸ . A photon that passes through all three filters will have had Ã¯Â£Â° Ã¯Â£Â» Ã¯Â£Â° Ã¯Â£Â»"
65,47,0.324,Handbook of Ocean Wave Energy,"Ã¢Â€Â¢ South and West coasts below the tropic of Capricorn (e.g. Australia, New Zealand, South Africa and Chile): high average wave power and low seasonal variability and low 100-year wave to mean wave ratio. Ã¢Â€Â¢ East coasts below the tropic of Capricorn (e.g. Australia, New Zealand, South Africa, Argentina, Uruguay and South Brazil): medium average wave power, with low seasonal variability and low 100-year wave to mean wave ratio. Ã¢Â€Â¢ West coast of United States: medium average wave power, with low seasonal variability and low 100-year wave to mean wave ratio. Ã¢Â€Â¢ North Atlantic (Europe and East coast US): high average wave power and steep waves, but high seasonal variability and high 100-year wave to mean wave ratio."
65,589,0.324,Handbook of Ocean Wave Energy,"Among these types of linear generators longitudinal flux permanent magnet generators (LFPM) have been the most common choice [41Ã¢Â€Â“43] for wave energy conversion. Normally, LFPM machines are also called permanent-magnet synchronous generators, as the armature winding flux and the permanent magnet flux move synchronously in the air gap. These machines have been extensively investigated for wave energy applications by Polinder and Danielsson [43, 44] amongst other researchers."
65,8,0.324,Handbook of Ocean Wave Energy,Hydrodynamics of WECs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . JÃƒÂ¸rgen Hals Todalshaug 6.1 Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.1.1 Wave Energy Absorption is Wave Interference . . . . . . . 6.1.2 Hydrostatics: Buoyancy and Stability . . . . . . . . . . . . . . 6.1.3 Hydrodynamic Forces and Body Motions . . . . . . . . . . . 6.1.4 Resonance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.1.5 Oscillating Water ColumnsÃ¢Â€Â”Comments on Resonance Properties and Modelling . . . . . . . . . . . . . . . . . . . . . . 6.1.6 Hydrodynamic Design of a Wave Energy Converter. . . . . 6.1.7 Power Estimates and Limits to the Absorbed Power . . . . . 6.1.8 Controlled Motion and Maximisation of Output Power . . . . . . . . . . . . . . . . . . . . . . . . . . . . References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65,44,0.324,Handbook of Ocean Wave Energy,"1. The PTO of a wave-activated body is the most efÃ¯Â¬Âcient when its motion is restricted to only one degree of freedom. Otherwise, the wave-activated body will always chose to move in the direction of the least resistance and thereby avoid PTO interaction. Furthermore, limiting its motions to one degree of freedom; Ã¢Â€Â¢ Reduces the complexity of the PTO system and the possible amount of load cases. Ã¢Â€Â¢ Optimises its efÃ¯Â¬Âciency and facilitates its control as the exact motion of the wave activated body is known. 2. PTO systems for WECs are normally required to convert a slow oscillating movement combined with high forces (induced by the nature of the waves) to a fast rotation in one direction (required by an electrical motor). Thereby, there is a wide range of different types of PTO systems, which all present advantages and inconveniences in term of efÃ¯Â¬Âciency, control, complexity and cost (see Chap. 8). Indicative values of efÃ¯Â¬Âciencies for these different types of PTOs (from absorbed wave energy to generator) are [24] (Table 1.4). Note that other aspects of the PTO system can be as well of high importance, such as the ability to; Table 1.4 Overview of the indicative efÃ¯Â¬Âciency for different PTO systems (see more on Chap. 8)"
311,2757,0.323,The Physics of the B Factories,"where Eb and E Ã¢Â€Â² are the energies of the incident and recoiling (tagged) electrons and ÃÂ¸ is the scattering angle of the tagged electron. The formation of a resonance in the single-tag process is a fertile field of study at the B Factories, especially in the high-Q2 region where the production cross section is highly suppressed. We impose a kinematic requirement on the single-tag mode that all the final state particles be observed except for the non-tagged incident electron (which can be inferred from a missing-mass constraint). In the B Factory experiments, the pseudoscalar transition form factors have been measured in single-tag modes, and are discussed in section 22.7. It is also possible to produce spin-1 (axial-vector) mesons in the single-tag process, although such measurements have not been reported from the B Factories. 22.1.5 Monte-Carlo Techniques No general-purpose Monte-Carlo (MC) generator for twophoton processes was available during the running of the B Factories. For exclusive two-photon processes, we can explicitly specify the combination of the final-state particles exclusively as well as the W distribution used in the event generation. In addition, angular distributions must be specified in the event generation. For these purposes, several MC generators to simulate a resonance or an exclusive final-state system from two-photon collisions, such as TREPS (Uehara, 1996), GGRESRC (Druzhinin, Kardapoltsev, and Tayursky, 2010), Gamgam (Aubert, 2010g) etc., are prepared and are used in the analysis. In these generators, one can specify functional shapes of distributions for W , Q2 and angles of final-state particles, or they can be generated by built-in default functions. Usually, an equivalent-photon approximation is adopted for zero-tag event generation while a Q2 distribution not based on EPA is sometimes used for the single-tag cases. Even for the non-EPA cases, we can"
391,340,0.323,Ocean-Atmosphere Interactions of Gases and Particles,"the turbulent part (ÃÂ„t) depends on the wind shear, wave induced part (ÃÂ„w) generated by the waves; the viscous part (ÃÂ„ÃÂ½) is neglected from some millimetres above the surface. Since the contribution from the different components varies with height, it is possible that the vertical flux is not constant with height within the wave boundary layer (the layer directly influenced by the waves). This also means that the surface stress is highly wave dependent. The kinematic stress ÃÂ„ is directly related to the friction velocity u* by"
35,146,0.323,Aquaculture Perspective of Multi-Use Sites in The Open Ocean : The Untapped Potential For Marine Resources in The Anthropocene,"Fig. 3.11 a Schematic of the OWEC and cage arrangement. b Tripile model with cylindrical Ã¯Â¬Âsh cage, c tripile model with spherical Ã¯Â¬Âsh cage, and d longitudinal section of the wave flume with wave maker, position of wave gauges, sand pit and tripile model"
235,344,0.322,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","498. Svozil, K.: The quantum coin tossÃ¢Â€Â”testing microphysical undecidability. Phys. Lett. A 143, 433Ã¢Â€Â“437 (1990). https://doi.org/10.1016/0375-9601(90)90408-G 499. Svozil, K.: Randomness and Undecidability in Physics. World Scientific, Singapore (1993). https://doi.org/10.1142/1524 500. Svozil, K.: Extrinsic-intrinsic concept and complementarity. In: Atmanspacher, H., Dalenoort, G.J. (eds.) Inside Versus Outside. Springer Series in Synergetics, vol. 63, pp. 273Ã¢Â€Â“288. Springer, Berlin (1994). https://doi.org/10.1007/978-3-642-48647-0_15 501. Svozil, K.: Quantum Logic. Springer, Singapore (1998) 502. Svozil, K.: On generalized probabilities: correlation polytopes for automaton logic and generalized urn models, extensions of quantum mechanics and parameter cheats (2001). arXiv:quant-ph/0012066 503. Svozil, K.: Science at the crossroad between randomness and determinism. In: Calude, C., Svozil, K. (eds.) Millennium III, pp. 73Ã¢Â€Â“84. Black Sea University Foundation in colaboration with the Romanian Academy of Sciences, Bucharest, Romania (2002). https://researchspace. auckland.ac.nz/handle/2292/3646 504. Svozil, K.: What could be more practical than a good interpretation (2002) 505. Svozil, K.: Quantum information via state partitions and the context translation principle. J. Mod. Opt. 51, 811Ã¢Â€Â“819 (2004). https://doi.org/10.1080/09500340410001664179 506. Svozil, K.: Logical equivalence between generalized urn models and finite automata. Int. J. Theor. Phys. 44, 745Ã¢Â€Â“754 (2005). https://doi.org/10.1007/s10773-005-7052-0 507. Svozil, K.: On counterfactuals and contextuality. In: Khrennikov, A. (ed.) AIP Conference Proceedings 750. Foundations of Probability and Physics-3, pp. 351Ã¢Â€Â“360. American Institute of Physics, Melville (2005). https://doi.org/10.1063/1.1874586 508. Svozil, K.: Are simultaneous Bell measurements possible? New J. Phys. 8, 39, 1Ã¢Â€Â“8 (2006). https://doi.org/10.1088/1367-2630/8/3/039 509. Svozil, K.: Staging quantum cryptography with chocolate balls. Am. J. Phys. 74(9), 800Ã¢Â€Â“803 (2006). https://doi.org/10.1119/1.2205879 510. Svozil, K.: Omega and the time evolution of the n-body problem. In: Calude, C.S. (ed.) Randomness and Complexity, from Leibniz to Chaitin, pp. 231Ã¢Â€Â“236. World Scientific, Singapore (2007). https://doi.org/10.1142/9789812770837_0013 511. Svozil, K.: Contexts in quantum, classical and partition logic. In: Engesser, K., Gabbay, D.M., Lehmann, D. (eds.) Handbook of Quantum Logic and Quantum Structures, pp. 551Ã¢Â€Â“586. Elsevier, Amsterdam (2009). https://doi.org/10.1016/B978-0-444-52869-8.50015-3 512. Svozil, K.: On the brightness of the Thomson lamp: a prolegomenon to quantum recursion theory. In: Calude, C.S., Costa, J.F., Dershowitz, N., Freire, E., Rozenberg, G. (eds.) UCÃ¢Â€Â™09: Proceedings of the 8th International Conference on Unconventional Computation, pp. 236Ã¢Â€Â“ 246. Springer, Berlin (2009). https://doi.org/10.1007/978-3-642-03745-0_26 513. Svozil, K.: On the plasticity of nonlocal quantum correlations. Ukr. J. Phys. 55, 547Ã¢Â€Â“553 (2009). arXiv:quant-ph/0503229 514. Svozil, K.: Proposed direct test of a certain type of noncontextuality in quantum mechanics. Phys. Rev. A 80(4), 040102 (2009). https://doi.org/10.1103/PhysRevA.80.040102 515. Svozil, K.: Quantum scholasticism: on quantum contexts, counterfactuals, and the absurdities of quantum omniscience. Inf. Sci. 179, 535Ã¢Â€Â“541 (2009). https://doi.org/10.1016/j.ins.2008. 06.012 516. Svozil, K.: Physical unknowables. In: Baaz, M., Papadimitriou, C.H., Putnam, H.W., Scott, D.S. (eds.) Kurt GÃƒÂ¶del and the Foundations of Mathematics, pp. 213Ã¢Â€Â“251. Cambridge University Press, Cambridge (2011). arXiv:physics/0701163 517. Svozil, K.: Quantum value indefiniteness. Nat. Comput. 10(4), 1371Ã¢Â€Â“1382 (2011). https:// doi.org/10.1007/s11047-010-9241-x 518. Svozil, K.: How much contextuality? Nat. Comput. 11(2), 261Ã¢Â€Â“265 (2012). https://doi.org/ 10.1007/s11047-012-9318-9 519. Svozil, K.: Non-contextual chocolate ball versus value indefinite quantum cryptography. Theor. Comput. Sci. 560(Part 1), 82Ã¢Â€Â“90 (2014). https://doi.org/10.1016/j.tcs.2014.09.019"
235,115,0.322,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","Both von Neumann and SchrÃƒÂ¶dinger thought of this as a sort of a zero-sum game, very much like complementary observables: due to the scarcity and fixed amount of information which merely gets permuted during state evolution, one can either have total knowledge of the individual parts; with zero relational knowledge of the correlations and relations among the parts; or conversely one can have total knowledge of the correlation and relations among the parts; but know nothing about the properties of the individual parts. Stated differently, any kind of mixture between the two extremes can be realized for an ensemble of multiple particles or parts: (i) either the properties of the individual parts are totally determined; in this case the relations and correlations among the parts remain indeterminate, (ii) or the relations and correlations among the parts are totally determined; but then the properties of the individual parts remain indeterminate. For classical particles only the first case can be realized. The latter case is a genuine quantum mechanical feature. Everett expressed this by saying that, in general (that is, with the exception of quasi-classical states) [206], Ã¢Â€Âœa constituent subsystem cannot be said to be in any single well-defined state, independently of the remainder of the composite system.Ã¢Â€Â The entire state of multiple quanta can be expressed completely in terms of correlations or joint probability distributions [365, 576], or, by another term, relational properties [587, 588], among observables belonging to the subsystems. As pointedly stated by Bennett [287] in quantum physics the possibility exists Ã¢Â€Âœthat you have a complete knowledge of the whole without knowing the state of any one part. That a thing can be in a definite state, even though its parts were not. . . . ItÃ¢Â€Â™s not a complicated idea but itÃ¢Â€Â™s an idea that nobody would ever think of.Ã¢Â€Â SchrÃƒÂ¶dinger called such states in German verschrÃƒÂ¤nkt, and in English entangled. In the context of multiple particles the formal criterion for entanglement is that an entangled state of multiple particles (an entangled multipartite state) cannot be represented as a product of states of single particles."
65,1,0.322,Handbook of Ocean Wave Energy,"This Handbook for Ocean Wave Energy aims at providing a guide into the Ã¯Â¬Âeld of ocean wave energy utilization. The handbook offers a concise yet comprehensive overview of the main aspects and disciplines involved in the development of wave energy converters (WECs). The idea for the book has been shaped by the development, research, and teaching that we have carried out at the Wave Energy Research Group at Aalborg University over the past decades. It is our belief and experience that it would be useful writing and compiling such a handbook in order to enhance the understanding of the sector for a wide variety of potential readers, from investors and developers to students and academics. At the Wave Energy Research Group, we have a wide range of wave energy related activities ranging from teaching at master and Ph.D. level, undertaking generic research projects and participating in speciÃ¯Â¬Âc research and development projects together with WEC developers and other stakeholders. All these activities have created a solid background in terms of theoretical knowledge, experimental and numerical modeling skills as well as a scientiÃ¯Â¬Âc network, which is why we found that the idea of putting this book together seemed realistic. With this as a starting point, we gathered a group of authors, each an expert within their speciÃ¯Â¬Âc research topic. It was clear from the beginning that the ambition was to make a high-quality publication but still ensuring that it would have a high level of accessibility. Therefore, we wanted the book to be freely available in digital form. To make this happen, we sought and received funding from the Danish EUDP program (project no. 64015-0013), for which we are extreme thankful. The ten chapters of the handbook present a broad range of relevant rules of thumb and topics, such as the technical and economic development of a WEC, wave energy resource, wave energy economics, WEC hydrodynamics, power take-off systems, mooring systems as well as the experimental and numerical simulation of WECs. It covers the topic of wave energy conversion from different perspectives, providing the readers, who are experts in one particular topic, with a clear overview of the key aspects in other relevant topics in which they might be less specialized."
103,332,0.321,Solar Particle Radiation Storms Forecasting and Analysis : The Hesperia Horizon 2020 Project and Beyond (Volume 444.0),"variation of the magnetic field strength B with heliocentric distance r is implemented in CSA as  r 2 RÃ‹Â‡ 6 (9.1) 1 C brf B.r/ D B0 where RÃ‹Â‡ is the solar radius, rÃ‹Âš D 1 AU, and B0 and brf are free parameters. The parameter brf accounts for a super-radial expansion of the associated radial magnetic flux tube close to the solar surface. In HESPERIA, the free parameters were determined by fitting the analytic functions used to the data obtained by using techniques of semi-empirical modelling of the shock (see Rouillard et al. 2016). The treatment of wave-particle interactions in CSA is based on quasi-linear theory, assuming only outward-propagating AlfvÃƒÂ©n waves, i.e., waves propagating away from the Sun. Particles experience elastic pitch-angle scattering in the wave frame, which is governed by the quasi-linear pitch-angle diffusion coefficient: D D"
65,121,0.321,Handbook of Ocean Wave Energy,"For many devices, and for all wave farms, the directional characteristics of the sea-state will also be important. The directionally resolved wave power density J ÃƒÂ°hÃƒÂ is a key directional characteristic of the sea-state as it deÃ¯Â¬Ânes the wave power propagation in a particular direction. The directional wave spectrum can be used to calculate the variation in the directionally resolved wave power density J ÃƒÂ°hÃƒÂ as given by Z ÃƒÂ¾p Z 1 JÃƒÂ°hÃƒÂ Ã‚Â¼ qg SÃƒÂ°x; uÃƒÂCg ÃƒÂ°xÃƒÂ cosÃƒÂ°h  uÃƒÂd  dx  du d Ã‚Â¼ 1; cosÃƒÂ°h  uÃƒÂ  0 d Ã‚Â¼ 0; cosÃƒÂ°h  uÃƒÂ\0"
65,58,0.32,Handbook of Ocean Wave Energy,"The development of wave energy converters (WECÃ¢Â€Â™s) goes far back in timeÃ¢Â€Â”the Ã¯Â¬Ârst attempts are recorded to have taken place in the 1800s, see Fig. 2.4 and [14]. Actually, the Ã¯Â¬Ârst patent for a wave energy converter dates back the year 1799. In"
65,74,0.32,Handbook of Ocean Wave Energy,"are therefore above normal seawater level. The device is installed with the structural bridge supporting the floats directed towards the dominant wave direction. When the wave passes, the floats move up and down driven by the passing waves, thereby pumping hydraulic fluid into a common hydraulic manifold system which produces a flow of high pressure oil into a hydraulic motor that directly drives an electric generator. A prototype with a total of two floaters (diameter of 5 m) has been undergoing sea trials at DanWEC, Hanstholm, Denmark."
235,308,0.32,"Physical (A)Causality : Determinism, Randomness and Uncaused Events (Volume 192.0)","The two spin one-half particle case is one of the standard quantum mechanical exercises, although it is seldom computed explicitly. For the sake of completeness and with the prospect to generalize the results to more particles of higher spin, this case will be enumerated explicitly. In what follows, we shall use the following notation: Let |+ denote the pure state corresponding to (1, 0)Ã¢ÂŠÂº , and |Ã¢ÂˆÂ’ denote the orthogonal pure state corresponding to (0, 1)Ã¢ÂŠÂº ."
311,2978,0.32,The Physics of the B Factories,"24.2.6 Summary In summary, the final result of the high statistics searches at the B Factories summarized above is that no experiment has yielded any evidence for the production of the ÃÂ˜(1540)+ or other members of the pentaquark family. Furthermore, a comparison of the BABAR results on electroproduction in Be to those from the HERMES (e+ D) and ZEUS (e+ p) experiments leads to the conclusion that prior claims for the observation of ÃÂ˜(1540)+ in electroproduction are not convincing. The inclusive and exclusive K + p interaction searches from Belle also result in the conclusion that claims for the observation of ÃÂ˜(1540)+ are unconvincing. In light of these results it would seem clear that the only way to clarify the issue brought about by the experiments which still claim a signal is for those experiments to collect and analyse significantly more data. However, many of the analyses have been carried out in experiments which are now decommissioned. Nevertheless, for those which can be repeated, there is a clear need for new high statistics data to be collected with well-calibrated, large-acceptance detectors. Proof of principle has been amply provided by the results from CLAS (DeVita, 2005), which so convincingly refute the earlier claim of ÃÂ˜(1540)+ observation from SAPHIR (Barth et al., 2003). The whole saga is succinctly summed up by the 2006 and 2008 PDG reports as given below. The 2006 Review of Particle Physics concluded (Yao et al., 2006): . . . there has not been a high-statistics conÃ¯Â¬Ârmation of any of the original experiments that claimed to see the ÃÂ˜(1540)+ ; there have been two high-statistics repeats from Jefferson Lab that have clearly shown the original positive claims in those two cases to be wrong; there have been a number of other highstatistics experiments, none of which have found any evidence for the ÃÂ˜(1540)+ ; and all attempts to conÃ¯Â¬Ârm the two other claimed pentaquark states have led to negative results. The conclusion that pentaquarks in general, and the ÃÂ˜(1540)+ , in particular, do not exist, appears compelling. The 2008 Review of Particle Physics went even further (Amsler et al., 2008): There are two or three recent experiments that Ã¯Â¬Ând weak evidence for signals near the nominal masses, but there is simply no point in tabulating them in view of the overwhelming evidence that the claimed pentaquarks do not exist. The only advance in particle physics thought worthy of mention in the American Institute of Physics Ã¢Â€ÂœPhysics News in 2003Ã¢Â€Â was a false alarm. The whole story Ã¢Â€Â” the discoveries themselves, the tidal wave of papers by theorists and phenomenologists that followed, and the eventual Ã¢Â€ÂœundiscoveryÃ¢Â€Â Ã¢Â€Â” is a curious episode in the history of science. Despite these null results, LEPS results as of 2009 continue to claim the existence of a narrow state with a mass of 1524 Ã‚Â± 4 MeV/c2 , with a statistical significance of 5.1 ÃÂƒ (Nakano et al., 2009)."
213,338,0.319,Collider Physics Within The Standard Model : a Primer,"masses. Not only do the W and the Z have large masses, but the large splitting of, for example, the tÃ¢Â€Â“b doublet shows that even a global weak SU.2/ is not at all respected by the fermion spectrum. This is a clear signal of spontaneous symmetry breaking and the implementation of spontaneous symmetry breaking in a gauge theory is via the Higgs mechanism. The big questions are about the nature and the properties of the Higgs particle(s). The search for the Higgs boson and for possible new physics that could accompany it was the main goal of the LHC from the start. On the Higgs the LHC should answer the following questions: do some Higgs particles exist? And if so, which ones: a single doublet, more doublets, additional singlets? SM Higgs or SUSY Higgses? Fundamental or composite (of fermions, of WW, or other)? Pseudo-Goldstone bosons of an enlarged symmetry? A manifestation of large extra dimensions (fifth component of a gauge boson, an effect of orbifolding or of boundary conditions, or other)? Or some combination of the above, or something so far unthought of? By now we have a candidate Higgs boson that really looks like the simplest realization of the Higgs mechanism, as described by the minimal SM Higgs. In the following we first consider the a priori expectations for the Higgs sector and then the profile of the Higgs candidate discovered at the LHC."
311,2407,0.318,The Physics of the B Factories,"In the constituent quark model (Gell-Mann, 1964; Zweig, 1964a,b), baryons composed of u, d, s, c quarks can be classified into SU (4) multiplets according to the symmetry of their flavor, spin, and spatial wavefunctions. All states in a given SU (4) multiplet have the same angular momentum J, and parity P , but can have diÃ¯Â¬Â€erent quark flavors. For excited states with multiple units of orbital angular momentum the number of possible multiplets becomes large, but for the ground states the picture is much simpler. This SU (4) symmetry is badly broken due to the large charm mass. and thus diÃ¯Â¬Â€erent states with the same conserved quantum numbers will mix, and baryons are not pure three-quark objectsÃ¢Â€Â”but it works remarkably well for the ground states. Quarks are fermions, so the baryon wavefunction must be overall antisymmetric under quark interchange.148 Baryons are color singlets, and so have an antisymmetric color wavefunction. In the ground state, the orbital angular momentum L is zero (S-wave) and the spatial wavefunction is symmetric. Therefore, the product of the spin and flavor wavefunctions must also be symmetric for ground-state baryons. There are two ways this can be accomplished: both wavefunctions can be fully symmetric, or both can have mixed symmetry with the product being symmetric. In concrete terms, we can consider a singly-charmed baryon to consist of a heavy c quark and a light diquark with spin-parity j p . Assuming isospin symmetry and letting q denote a u or d quark, there are four possibilities for the flavor content of the diquark: Ã¢Â€Â“ qq with isospin 0 (flavor antisymmetric); Ã¢Â€Â“ qq with isospin 1 (flavor symmetric); Ã¢Â€Â“ sq with isospin 1/2 (either); Ã¢Â€Â“ ss with isospin 0 (flavor symmetric). These correspond to the ÃÂ›c , ÃÂ£c , ÃÂc , and ÃÂ©c states, respectively. The diquark wavefunction must be antisymmetric under quark interchange. Its color wavefunction is antisymmetric and in the ground state its spatial wavefunction is symmetric, so it may be either flavor-symmetric and spin-symmetric (j p = 1+ ) or flavor-antisymmetric and spin-antisymmetric (j p = 0+ ). Combining the diquark with the charm quark gives rise to the possible states set out in Table 19.4.2 and illustrated in Fig. 19.4.2, where the multiplets of the full SU (3) symmetry (formed by the u, d, and s quarks) are shown. Those with J P = 1/2+ are all members of the same multiplet as the proton, and those with J P = 3/2+ are all members of the same multiplet as the ÃÂ” and ÃÂ© (Fig. 19.4.3). Note that there is a second isospin doublet of ÃÂc states with J P = 1/2+ , denoted ÃÂcÃ¢Â€Â² . The constituent quark model predicts relations between the masses of these states as well as their existence and quantum numbers. These were expressed for the light baryons as sum rules (see Gell-Mann (1962); Okubo"
65,142,0.318,Handbook of Ocean Wave Energy,"Currently, the most common way of measuring ocean waves is with a surface-following buoy that is slackly moored to the seabed as shown in Fig. 3.17. In these buoys, the vertical motion is typically measured using an accelerometer (although GPS systems are now becoming more common), which can then be double integrated to provide a time-series of the water surface elevation [19]. The recorded surface elevation is then used to estimate the wave spectrum and from that the sea-state parameters. Wave measurement buoys may also contain instruments to measure the inclination of the buoy so that the direction of the waves can be inferred and used to produce a directional wave spectrum, with associated directional sea-state parameters. A major beneÃ¯Â¬Ât of using wave measuring buoys is that they have been used for a long time and thus their accuracy is well established. Their limitations are also relatively well recognised in that strong currents and steep Fig. 3.17 A surface-following wave measurement buoy"
179,743,0.317,"Habitats and Biota of the Gulf of Mexico: Before the Deepwater Horizon Oil Spill: Volume 1: Water Quality, Sediments, Sediment Contaminants, Oil and Gas Seeps, Coastal Habitats, Offshore Plankton and Benthos, and Shellfish","6.3.3.4 Wind Waves Wave climate is one of the primary factors controlling sediment transport, deposition, and erosion in coastal habitats, and is defined as the average wave condition over a period of years based on wave height, period, direction, and energy. In coastal and nearshore environments, wind speed and direction, and nearshore bathymetry, are the primary forcing mechanisms of wave climate. Changing geomorphic characteristics of coastal habitats are dependent upon short-term fluctuations in wave climate, long-term cycles of wind and wave activity (including the effects of frontal passages and hurricanes), and the availability of sediment and fresh water to deltaic, estuarine, and marine coastal settings. Wind directions and intensities vary seasonally with southerly winds prevailing most of the year. During winter months, wind-circulation patterns and low barometric pressures preceding the passage of cold fronts can cause strong onshore winds and increased wave heights that typically erode beaches. After frontal system passage, wind direction shifts and northerly winds can generate waves that erode north-facing shorelines at many locations. Various moored buoys and coastal wave gauges are situated throughout the GoM (Figure 6.18). Average deep-water wave heights range from 0.5 m (1.6 ft) in summer months to 1.5 m (4.9 ft) in winter months (NDBC 2012). However, most fair-weather average significant wave heights in Gulf coastal environments are less than 0.6 m (2.0 ft) high (Li 2012; BOEM 2011). Average fair-weather wave periods are on the order of 3.5 to 4 s. Although fair-weather waves contribute to coastal habitat evolution throughout the Gulf, greatest sediment redistribution along the coast occurs during tropical cyclones and winter cold fronts for this stormdominated region."
213,135,0.315,Collider Physics Within The Standard Model : a Primer,"which we have alreadyP introduced. R is dimensionless and is given in perturbation theory by1 R D NC i Q2i F.t; Ã‹Â›s /, where F D 1 C O.Ã‹Â›s /. We have already mentioned that for this process the Ã¢Â€Âœanomalous dimensionÃ¢Â€Â function vanishes, i.e., .Ã‹Â›s / D 0, because of electric charge non-renormalization by strong interactions. Let us recall how this happens in detail. The diagrams that are relevant for charge renormalization in QED at 1-loop are shown in Fig. 2.12. The Ward identity that follows from gauge invariance in QED requires the vertex (ZV ) and the self-energy (Zf ) renormalization factors to cancel, and the only divergence remains in Z , the vacuum polarization of the photon. Hence, the charge is only renormalized by the photon vacuum polarization blob, and it is thus universal (the same factor for all fermions, independent of their charge) and not affected by QCD at 1-loop. It is true that at higher orders the photon vacuum polarization diagram is affected by QCD (for example, at 2-loops we can exchange a gluon between the quarks in the loop), but the renormalization induced by the divergent logs from the vacuum polarization diagram remain independent of the nature of the fermion to which the photon line is attached. The gluon contributions to the vertex (ZV ) and to the self-energy (Zf ) cancel, because they have exactly the same structure as in QED, and there is no gluon contribution to the photon blob at 1-loop, so that .Ã‹Â›s / D 0. At the 1-loop level, the diagrams relevant for the computation of R are shown in Fig. 2.13. There are virtual diagrams and also real diagrams with one additional gluon in the final state. Infrared divergences cancel between the interference term of the virtual diagrams and the absolute square of the real diagrams, according to the"
